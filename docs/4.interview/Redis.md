# ---------------------------------------------------------------------------------------------

# 1.缓存

## 1-1：缓存思想

我们为了避免用户在请求数据的时候获取速度过于缓慢，
所以我们在数据库之上增加了缓存这一层来弥补。

## 1-2：使用缓存为系统带来了什么问题

1. 系统复杂性增加：引入缓存之后，
   你要维护缓存和数据库的数据一致性、维护热点缓存等等。
2. 系统开发成本增加：引入缓存意味着系统需要一个单独的缓存服务，
   这是需要花费相应的成本的，并且这个成本还是很贵的，
   毕竟耗费的是宝贵的内存。
   如果你只是简单的使用一下本地缓存
   存储一下简单的数据，
   并且数据量不大的话，
   那么就不需要单独去弄一个缓存服务。

## 1-3：本地缓存解决方案

一：JDK 自带的 HashMap 和 ConcurrentHashMap 了。

ConcurrentHashMap 可以看作是线程安全版本的 HashMap ，
两者都是存放 key/value 形式的键值对。
但是，大部分场景来说不会使用这两者当做缓存，
因为只提供了缓存的功能，并没有提供其他诸如过期时间之类的功能。

二：Spring Cache

使用 Spring Cache 的注解实现缓存的话，
代码会看着很干净和优雅，
但是很容易出现问题比如缓存穿透、内存溢出。

## 1-4：为什么要有分布式缓存?/为什么不直接用本地缓存?

其实分布式缓存类似于一种内存数据库的服务，
它的最终作用就是提供缓存数据的服务。
本地的缓存的优势是低依赖，
比较轻量并且通常相比于使用分布式缓存要更加简单。
本地缓存对分布式架构支持不友好，
比如同一个相同的服务部署在多台机器上的时候，
各个服务之间的缓存是无法共享的，
因为本地缓存只在当前机器上有。
本地缓存容量受服务部署所在的机器限制明显。
如果当前系统服务所耗费的内存多，
那么本地缓存可用的容量就很少。
使用分布式缓存之后，
缓存部署在一台单独的服务器上，
即使同一个相同的服务部署在再多机器上，
也是使用的同一份缓存。 
并且，单独的分布式缓存服务的性能、
容量和提供的功能都要更强。
使用分布式缓存的缺点呢，
也很显而易见，
那就是你需要为分布式缓存引入额外的服务
比如Redis或Memcached，
你需要单独保证 Redis 或 Memcached 服务的高可用。

## 1-5：缓存读写模式/更新策略

1. Cache Aside Pattern（旁路缓存模式）
   写：更新 DB，然后直接删除 cache 。
   读：从 cache 中读取数据，读取到就直接返回，
      读取不到的话，就从 DB 中取数据返回，
      然后再把数据放到 cache 中。
   Cache Aside Pattern 中服务端需要同时维系 DB 和 cache，
   并且是以 DB 的结果为准。
   另外，Cache Aside Pattern 
   有首次请求数据一定不在 cache 的问题，
   对于热点数据可以提前放入缓存中。
   比较适合读请求比较多的场景。

2. Read/Write Through Pattern（读写穿透）
   写：先查 cache，cache 中不存在，
       直接更新 DB。 cache 中存在，
       则先更新 cache，
       然后 cache 服务自己更新 DB（同步更新 cache 和 DB）。
  读： 从 cache 中读取数据，读取到就直接返回 。
      读取不到的话，先从 DB 加载，
      写入到 cache 后返回响应。

Read-Through Pattern 实际只是在 Cache-Aside Pattern 之上进行了封装。
在 Cache-Aside Pattern 下，发生读请求的时候，
如果 cache 中不存在对应的数据，
是由客户端自己负责把数据写入 cache，
而 Read Through Pattern 则
是 cache 服务自己来写入缓存的，
这对客户端是透明的。
服务端把 cache 视为主要数据存储，
从中读取数据并将数据写入其中。
cache 服务负责将此数据读取和写入 DB，
从而减轻了应用程序的职责。

3. Write Behind Pattern（异步缓存写入）
由 cache 服务来负责 cache 和 DB 的读写。
Write Behind Caching 则是只更新缓存，
不直接更新 DB，而是改为异步批量的方式来更新 DB。
Write Behind Pattern 下 DB 的写性能非常高，
尤其适合一些数据经常变化的业务场景
比如说一篇文章的点赞数量、阅读数量。
往常一篇文章被点赞 500 次的话，
需要重复修改 500 次 DB，
但是在 Write Behind Pattern 下可能
只需要修改一次 DB 就可以了。
但是，这种模式同样也给 DB 和 Cache 一致性带来了新的考验，
很多时候如果数据还没异步更新到 DB 的话，Cache 服务宕机了。

## 1-6：缓存数据的处理流程是怎样的

1. 如果用户请求的数据在缓存中就直接返回。
2. 缓存中不存在的话就看数据库中是否存在。
3. 数据库中存在的话就更新缓存中的数据。
4. 数据库中不存在的话就返回空数据。

# 2.Redis

## 2-1：为什么要⽤ redis/为什么要⽤缓存

1. 高性能方面，假如⽤户第⼀次访问数据库中的某些数据。
   这个过程会⽐较慢，因为是从硬盘上读取的。
   将该⽤户访问的数据存在缓存中，
   这样下⼀次再访问这些数据的时候
   就可以直接从缓存中获取了。
   操作缓存就是直接操作内存，
   所以速度相当快。
   如果数据库中的对应数据改变的之后，
   同步改变缓存中相应的数据即可！
2. ⾼并发：直接操作缓存能够承受的请求
   是远远⼤于直接访问数据库的，
   所以我们可以考虑把数据库中的
   部分数据转移到缓存中去，
   这样⽤户的⼀部分请求会
   直接到缓存这⾥⽽不⽤经过数据库。

## 2-2：为什么要⽤ redis ⽽不⽤ map/guava 做缓存

缓存分为本地缓存和分布式缓存。
以 Java 为例，使⽤⾃带的 map 或者 guava 实现的是本地缓存，
最主要的特点是轻量以及快速，
⽣命周期随着 jvm 的销毁⽽结束，
并且在多实例的情况下，
每个实例都需要各⾃保存⼀份缓存，
缓存不具有⼀致性。

使⽤ redis 或 memcached 之类的称为分布式缓存，
在多实例的情况下，各实例共⽤⼀份缓存数据，
缓存具有⼀致性。
缺点是需要保持 redis 或 memcached服务的⾼可⽤，
整个程序架构上较为复杂。

## 2-3：说一下 Redis 和 Memcached 的区别和共同点

共同点 ：

都是基于内存的数据库，一般都用来当做缓存使用。
都有过期策略。
两者的性能都非常高。

区别 ：

1. Redis支持更丰富的数据类型（支持更复杂的应用场景）。
   Redis 不仅仅支持简单的 k/v 类型的数据，
   同时还提供 list，set，zset，hash 等数据结构的存储。
   Memcached 只支持最简单的 k/v 数据类型。
2. Redis支持数据的持久化，
   可以将内存中的数据保持在磁盘中，
   重启的时候可以再次加载进行使用,
   而 Memecache 把数据全部存在内存之中。
3. Redis 有灾难恢复机制。
   因为可以把缓存中的数据持久化到磁盘上。
4. Redis 在服务器内存使用完之后，
   可以将不用的数据放到磁盘上。
   但是，Memcached 在服务器内存使用完之后，
   就会直接报异常。
5. Memcached 没有原生的集群模式，
   需要依靠客户端来实现往集群中分片写入数据；
   但是 Redis 目前是原生支持 cluster 模式的.
6. Memcached 是多线程，
   非阻塞 IO 复用的网络模型；
   Redis 使用单线程的多路 IO 复用模型。
7. Redis 支持发布订阅模型、Lua 脚本、事务等功能，
   而 Memcached 不支持。
   并且，Redis 支持更多的编程语言。
8. Memcached过期数据的删除策略
   只用了惰性删除，
   而 Redis 同时使用了惰性删除与定期删除。

## 2-4：为什么说Redis快

1. 完全基于内存，数据存在内存中，
   类似于hashmap，
   hashmap的优势就是查找和操作的
   时间复杂度是o（1）
2. 数据结构进行了特别的设计，
3. 比如说SDS结构中字符串长度len，压缩链表
4. 采用单线程，避免了不必要的上下文切换和竞争条件，
   也不存在多线程或者多线程导致切换而消耗CPU，
   不用去考虑各种所得问题，不存在枷锁释放
   操作，没有因为可能出现死锁二导致的性能消耗
5. 使用多路I/O复用模型，非阻塞IO，
   多路IO复用模型利用select、poll、epoll可以
   同时监察多个流的IO事件时，
   就从阻塞态中唤醒，也是程序就会轮询一遍所有的流，
   并且只依次顺序的处理就绪流，
   这样就可以避免了大量的无用操作
6. RESP协议也就是Redis的序列化协议，
   文本协议，解析迅速
7. 持久化采用子线程进行磁盘操作

## 2-5：Redis应用场景

1. `热点数据的缓存`
由于redis访问速度块、支持的数据类型比较丰富，
所以redis很适合用来存储热点数据，
另外结合expire，我们可以设置过期时间然后再进行缓存更新操作
2. `限时业务的运用`
redis中可以使用expire命令设置一个键的生存时间，
到时间后redis会删除它。利用这一特性可以运用
在限时的优惠活动信息、手机验证码等业务场景。
3. `计数器相关问题`
redis由于incrby命令可以实现原子性的递增，
所以可以运用于高并发的秒杀活动、分布式序列号的生成、
比如限制一个手机号发多少条短信、一个接口一分钟限
制多少请求、一个接口一天限制调用多少次等等。
4. `排行榜相关问题`
关系型数据库在排行榜方面查询速度普遍偏慢，
所以可以借助redis的SortedSet进行热点数据的排序。
5. `分布式锁`
6. `延时操作`
没有做过具体操作，
比如在订单生产后我们占用了库存，
10分钟后去检验用户是够真正购买，
如果没有购买将该单据设置无效，同时还原库存。 
7. `分页、模糊搜索`
可以利用zrangebylex方法可以进行模糊查询功能，
这个也是目前我在redis中发现的唯一一个支持对存储内容进行模糊查询的特性。
对公司进行项目的数据进行了模拟测试，
公司存储数据6000万左右，响应时间在700ms左右，
比mysql的like查询稍微快一点，
但是由于它可以避免大量的数据io操作，
所以总体还是比直接mysql查询更利于系统的性能保障。
8. `点赞、好友等相互关系的存储`
Redis set可以实现set是可以自动排重的，
比如说在微博应用中，
每个用户关注的人存在一个集合中，
就很容易实现求两个人的共同好友功能。
9. `队列`
由于redis有list push和list pop这样的命令，
所以能够很方便的执行队列操作。

# 3.Redis五种数据类型与编码方式

## 3-1：五种数据类型

1. string，常用命令set,get,strlen,exists,dect,incr,setex
   
```java
常用
   127.0.0.1:6379> set key value #设置 key-value 类型的值
   OK
   127.0.0.1:6379> get key # 根据 key 获得对应的 value
   "value"
   127.0.0.1:6379> exists key  # 判断某个 key 是否存在
   (integer) 1
   127.0.0.1:6379> strlen key # 返回 key 所储存的字符串值的长度。
   (integer) 5
   127.0.0.1:6379> del key # 删除某个 key 对应的值
   (integer) 1
   127.0.0.1:6379> get key
   (nil)

批量设置
   127.0.0.1:6379> mset key1 value1 key2 value2 # 批量设置 key-value 类型的值
   OK
   127.0.0.1:6379> mget key1 key2 # 批量获取多个 key 对应的 value

计数器（字符串的内容为整数的时候可以使用）：

   127.0.0.1:6379> set number 1
   OK
   127.0.0.1:6379> incr number # 将 key 中储存的数字值增一
   (integer) 2
   127.0.0.1:6379> get number
   "2"
   127.0.0.1:6379> decr number # 将 key 中储存的数字值减一
   (integer) 1
   127.0.0.1:6379> get number
   "1"

过期：

   127.0.0.1:6379> expire key  60 # 数据在 60s 后过期
   (integer) 1
   127.0.0.1:6379> setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)
   OK
   127.0.0.1:6379> ttl key # 查看数据还有多久过期
   (integer) 56
```

2. list，常用命令rpush,lpop,lpush,rpop,lrange、llen
   
```java
通过 rpush/lpop 实现队列：

   127.0.0.1:6379> rpush myList value1 # 向 list 的头部（右边）添加元素
   (integer) 1
   127.0.0.1:6379> rpush myList value2 value3 # 向list的头部（最右边）添加多个元素
   (integer) 3
   127.0.0.1:6379> lpop myList # 将 list的尾部(最左边)元素取出
   "value1"
   127.0.0.1:6379> lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end
   1) "value2"
   2) "value3"
   127.0.0.1:6379> lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一
   1) "value2"
   2) "value3"

通过 rpush/rpop 实现栈：

   127.0.0.1:6379> rpush myList2 value1 value2 value3
   (integer) 3
   127.0.0.1:6379> rpop myList2 # 将 list的头部(最右边)元素取出
   "value3"

通过 lrange 查看对应下标范围的列表元素：

   127.0.0.1:6379> rpush myList value1 value2 value3
   (integer) 3
   127.0.0.1:6379> lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end
   1) "value1"
   2) "value2"
   127.0.0.1:6379> lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一
   1) "value1"
   2) "value2"
   3) "value3"

通过 llen 查看链表长度：

   127.0.0.1:6379> llen myList
   (integer) 3
```

3. hash,常见命令hset,hmset,hexists,hget,hgetall,hkeys,hvals

```java
   127.0.0.1:6379> hset userInfoKey name "guide" description "dev" age "24"
   OK
   127.0.0.1:6379> hexists userInfoKey name # 查看 key 对应的 value中指定的字段是否存在。
   (integer) 1
   127.0.0.1:6379> hget userInfoKey name # 获取存储在哈希表中指定字段的值。
   "guide"
   127.0.0.1:6379> hget userInfoKey age
   "24"
   127.0.0.1:6379> hgetall userInfoKey # 获取在哈希表中指定 key 的所有字段和值
   1) "name"
   2) "guide"
   3) "description"
   4) "dev"
   5) "age"
   6) "24"
   127.0.0.1:6379> hkeys userInfoKey # 获取 key 列表
   1) "name"
   2) "description"
   3) "age"
   127.0.0.1:6379> hvals userInfoKey # 获取 value 列表
   1) "guide"
   2) "dev"
   3) "24"
   127.0.0.1:6379> hset userInfoKey name "GuideGeGe" # 修改某个字段对应的值
   127.0.0.1:6379> hget userInfoKey name
   "GuideGeGe"
```

4. set

```java

   127.0.0.1:6379> sadd mySet value1 value2 # 添加元素进去
   (integer) 2
   127.0.0.1:6379> sadd mySet value1 # 不允许有重复元素
   (integer) 0
   127.0.0.1:6379> smembers mySet # 查看 set 中所有的元素
   1) "value1"
   2) "value2"
   127.0.0.1:6379> scard mySet # 查看 set 的长度
   (integer) 2
   127.0.0.1:6379> sismember mySet value1 # 检查某个元素是否存在set 中，只能接收单个元素
   (integer) 1
   127.0.0.1:6379> sadd mySet2 value2 value3
   (integer) 2
   127.0.0.1:6379> sinterstore mySet3 mySet mySet2 # 获取 mySet 和 mySet2 的交集并存放在 mySet3 中
   (integer) 1
   127.0.0.1:6379> smembers mySet3
   1) "value2"
```

5. zset,常用命令zadd,zcard,zscore,zrange,zrevrange,zrem

```java
   127.0.0.1:6379> zadd myZset 3.0 value1 # 添加元素到 sorted set 中 3.0 为权重
   (integer) 1
   127.0.0.1:6379> zadd myZset 2.0 value2 1.0 value3 # 一次添加多个元素
   (integer) 2
   127.0.0.1:6379> zcard myZset # 查看 sorted set 中的元素数量
   (integer) 3
   127.0.0.1:6379> zscore myZset value1 # 查看某个 value 的权重
   "3"
   127.0.0.1:6379> zrange  myZset 0 -1 # 顺序输出某个范围区间的元素，0 -1 表示输出所有元素
   1) "value3"
   2) "value2"
   3) "value1"
   127.0.0.1:6379> zrange  myZset 0 1 # 顺序输出某个范围区间的元素，0 为 start  1 为 stop
   1) "value3"
   2) "value2"
   127.0.0.1:6379> zrevrange  myZset 0 1 # 逆序输出某个范围区间的元素，0 为 start  1 为 stop
   1) "value1"
   2) "value2"
```

## 3-2：String类型

### 3-2-1：String-内部结构

redis在内部存储string都是主要还是以`sds的数据结构`实现的，
但是，在整个redis的数据存储过程中为了提高性能，内部做了很多优化。整体选择顺序应该是：
1. 只对长度小于或等于 21 字节，并且可以被解释为整数的字符串进行编码，使用整数存储
2. 尝试将 RAW 编码的字符串编码为 EMBSTR 编码，使用EMBSTR 编码
3. 这个对象没办法进行编码，尝试从 SDS 中移除所有空余空间，使用SDS编码

#### 3-2-1-1：sds简介

最后一个字符为空字符。然而这个空字符不会被计算在len里头
比如说刚开始s1 只有5个空闲位子，
后面需要追加'hello' 5个字符，
很明显是不够的。Redis会做以下三个操作：
计算出大小是否足够
开辟空间至满足所需大小
开辟与已使用大小len相同长度的空闲free空间
（如果len < 1M）开辟1M长度的空闲free空间（如果len >= 1M）

#### 3-2-1-2：embstr和sds的区别（编码方式）

   主要就是在于内存的申请和回收
1. embstr的创建只需分配一次内存，
   而raw为两次（一次为sds分配对象，
   另一次为redisObject分配对象，embstr省去了第一次）。
   相对地，释放内存的次数也由两次变为一次。
2. embstr的redisObject和sds放在一起，更好地利用缓存带来的优势
3. redis并未提供任何修改embstr的方式，
   即embstr是只读的形式。
   对embstr的修改实际上是先转换为raw再进行修改。

#### 3-2-1-3：sds对象创建

sds对象创建sdsnewlen分配了一次内存。
robj对象的创建又分配了一次内存。
整个sds对象的创建其实就是
分配内存并初始化len和free字段。

#### 3-2-1-4：sds内存扩容

当字符串长度小于SDS_MAX_PREALLOC (1024*1024)，
那么就以2倍的速度扩容，
当字符串长度大于SDS_MAX_PREALLOC，
那么就以+SDS_MAX_PREALLOC的速度扩容。

#### 3-2-1-5：String-sds缩容

释放内存的过程中修改len和free字段，
并不释放实际占用内存。

#### 3-2-1-6：Redis字符串的性能优势

1. 快速获取字符串长度
2. 避免缓冲区溢出
3. 降低空间分配次数提升内存使用效率

### 3-2-2：动态字符串与C语言自带字符串的区别

1. 常数复杂度获取字符串长度
    由于len属性的存在，
    获取SDS字符串的长度只需要读取len属性，时间复杂度为O(1)。
    而对于C语言，
    获取字符串的长度通常是经过遍历计数来实现的，时间复杂度为O(n)
2. 避免缓冲区溢出
   对于SDS数据类型，在进行字符修改的时候，
   会首先根据记录的len属性检查内存空间是否满足需求，
   如果不满足，会进行相应的空间扩展，
   然后在进行修改操作，所以不会出现缓冲区溢出。
3. 减少修改字符串的内存重新分配次数
   C语言由于不记录字符串的长度，
   所以如果要修改字符串，
   必须要重新分配内存（先释放再申请），
   因为如果没有重新分配，
   字符串长度增大时会造成内存缓冲区溢出，
   字符串长度减小时会造成内存泄露。
   而对于SDS，由于len属性和free属性的存在，
   对于修改字符串SDS实现了空间预分配和惰性空间释放两种策略:
   * 1、`空间预分配:`对字符串进行空间扩展的时候，
                    扩展的内存比实际需要的多，
                    这样可以减少连续执行字符串增长
                    操作所需的内存重分配次数。
   * 2、`惰性空间释放`:对字符串进行缩短操作时，
                      程序不立即使用内存重新分配
                      来回收缩短后多余的字节，
                      而是使用 free属性将这些字节的数量记录下来，
                      等待后续使用。
4. 二进制安全
   因为C语言的字符串以空字符作为字符串结束的标识，
   而对于一些二进制文件（如图片等)，
   内容可能包括空字符串，
   因此C字符串无法正确存取;
   而所有SDS的 API 都是
   以处理二进制的方式来处理buf里面的元素，
   并且SDS不是以空字符串来判断是否结束，
   而是以len属性表示的长度来判断字符串是否结束。
5. 兼容部分C字符串函数
   虽然 SDS 是二进制安全的，
   但是一样遵从每个字符串都是以空字符串结尾的惯例，
   这样可以重用C语言库<string.h>中的一部分函数。

## 3-3：list类型

### 3-3-1：list-内部结构

redis list数据结构底层
`采用压缩列表ziplist或双向链表linkedlist两种数据结构进行存储，`
首先以ziplist进行存储，在不满足ziplist的存储要求后转换为linkedlist列表。也就是说
列表对象保存的所有字符串元素的长度小于64字节，用ziplist。
列表对象保存的元素数量小于512个。

#### 3-3-1-1：ziplist

ziplist的数据结构主要包括两层，`ziplist和zipEntry。`
ziplist包括zip header、zip entry、zip end三个模块。
zipentry由prevlen、encoding&length、value三部分组成。
prevlen主要是指前面zipEntry的长度，
coding&length是指编码字段长度和实际
存储value的长度，value是指真正的内容。
每个key/value存储结果中key
用一个zipEntry存储，value用一个zipEntry存储。

### 3-3-2：list元素添加过程

1. 创建list对象并添加到db的数据结构当中
2. 针对每个待插入的元素添加到list当中，
   list的每个元素的插入过程中，我们会对是否需要进行转码作两个判断：
    - 对每个插入元素的长度进行判断是否进行ziplist->linkedlist的转码。
    - 对list总长度是否超过ziplist最大长度的判断。

## 3-4：hash类型

### 3-4-1：hash底层存储结构

redis的哈希对象的底层存储可以
`使用ziplist（压缩列表）和hashtable。`
当hash对象可以同时满足
哈希对象保存的所有键值对的键和值的字符串长度都小于64字节
哈希对象保存的键值对数量小于512个
哈希对象就可以使用ziplist编码。

### 3-4-2：redis hash存储过程源码分析

我只是大体看过hset命令，这个过程应该是：
1. 首先查看hset中key对应的value是否存在
2. 判断key和value的长度确定是否需要从zipList到hashtab转换，
3. 对key/value进行string层面的编码，解决内存效率问题。
4. 更新hash节点中key/value问题。

### 3-4-3：Redis字典底层如何解决冲突

拉链法等方法

### 3-4-4：hash如何扩容

正常情况下，当hash表中元素的个数等于第一维数组的长度时，
就会开始扩容，扩容的新数组是原数组大小的2倍。
不过如果Redis正在做bgsave(持久化命令)，
为了减少内存也得过多分离，
Redis 尽量不去扩容，但是如果hash表非常满了，
达到了第一维数组长度的 5 倍了，
这个时候就会强制扩容。
当hash表因为元素
逐渐被删除变得越来越稀疏时，
Redis会对hash表进行缩容
来减少hash表的第一维数组空间占用。
所用的条件是元素个数
低于数组长度的10%，
缩容不会考虑Redis是否在做bgsave。

### 3-4-5：什么是渐进式--rehash

扩容和收缩操作不是一次性、集中式完成的，
而是分多次、渐进式完成的。
如果保存在Redis中的键值对只有几个几十个，
那么rehash操作可以瞬间完成，
但是如果键值对有几百万，几千万甚至几亿，
那么要一次性的进行 rehash，
势必会造成Redis一段时间内不能进行别的操作。
所以 Redis采用渐进式rehash
这样在进行渐进式rehash期间，
字典的删除查找更新等操作
可能会在两个哈希表上进行，
第一个哈希表没有找到，
就会去第二个哈希表上进行查找。
但是进行增加操作，
一定是在新的哈希表上进行的。

## 3-5：set类型

### 3-5-1：set底层存储
 
redis的集合对象set的底层存储结构底层
`使用了intset和hashtable两种数据结构存储的，`
intset我认为应该是一种数组类型的，
hashtable就是普通的哈希表（key为set的值，value为null）。
set的底层存储intset和hashtable是存在编码转换的，
使用intset存储必须满足
集合对象保存的所有元素都是整数值
集合对象保存的元素数量不超过512个
否则使用hashtable，

#### 3-5-1-1：intset的数据结构

intset内部其实是一个数组（int8_t coentents[]数组），
而且存储数据的时候是有序的，因为在查找数据的时候是通过二分查找来实现的。

### 3-5-2：set存储过程
 
set的sadd命令为例子，整个添加过程如下：
1. 检查set是否存在不存在则创建一个set结合。
2. 根据传入的set集合一个个进行添加，
   添加的时候需要进行内存压缩。
3. setTypeAdd执行set添加过程中
   会判断是否进行编码转换。

## 3-6：zset类型

### 3-6-1：zset底层存储结构

zset底层的存储结构
`包括ziplist（压缩列表）或skiplist（跳表），`
在同时满足
有序集合保存的元素数量小于128个
有序集合保存的所有元素的长度小于64字节
的时候，可以使用ziplist，其他时候使用skiplist，
当ziplist作为zset的底层存储结构时候，
每个集合元素使用两个紧挨
在一起的压缩列表节点来保存，
第一个节点保存元素的成员，
第二个元素保存元素的分值。
当skiplist作为zset的底层存储结构的时候，
使用skiplist按序保存元素及分值，
使用dict来保存元素和分值的映射关系。

### 3-6-2：skiplist数据结构
 
skiplist作为zset的存储结构，
主要是包括一个dict对象和一个skiplist对象。
dict保存key/value，key为元素，value为分值；
skiplist保存的有序的元素列表，
每个元素包括元素和分值。
两种数据结构下的元素指向相同的位置。

### 3-6-3：zset存储过程

以zadd的操作作为例子进行分析，
1. 解析参数得到每个元素及其对应的分值
2. 查找key对应的zset是否存在不存在则创建
3. 如果存储格式是ziplist，
   那么在执行添加的过程中
   我们需要区分元素存在和不存在两种情况，
   存在情况下先删除后添加；
   不存在情况下则添加并且需要考
   虑元素的长度是否超出限制或
   实际已有的元素个数是否超过
   最大限制进而决定是否转为skiplist对象。
4. 如果存储格式是skiplist，
   那么在执行添加的过程中
   我们需要区分元素存在和不存在两种情况，
   存在的情况下先删除后添加，
   不存在情况下那么就直接添加，
   在skiplist当中添加完以后
   我们同时需要更新dict的对象。

### 3-6-4：skiplist与平衡树、哈希表的比较

1. skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列，
   而哈希表不是有序的的。因此，在哈希表上只能做单个key的查找，
   不适合做范围查找。
   所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。
2. 在做范围查找的时候，平衡树比skiplist操作要复杂。
   在平衡树上，我们找到指定范围的小值之后，
   还需要以中序遍历的顺序继续寻找其它不超过大值的节点。
   而在skiplist上进行范围查找就非常简单，
   只需要在找到小值之后，
   对第1层链表进行若干步的遍历就可以实现。
3. 平衡树的插入和删除操作可能引发子树的调整，
   逻辑复杂，
   而skiplist的插入和删除
   只需要修改相邻节点的指针，
   操作简单又快速。
4. 从内存占用上来说，skiplist比平衡树更灵活一些。
   一般来说，平衡树每个节点包含2个指针(分别指向左右子树)，
   而skiplist每个节点包含的指针数目平均为1/(1-p)，
   具体取决于参数p的大小。
   如果像Redis里的实现一样，取p=1/4，
   那么平均每个节点包含1.33个指针，
   比平衡树更有优势。
5. 查找单个key，skiplist和平衡树的时间复杂度都为O(logn)，
   大体相当;
   而哈希表在保持较低的哈希值冲突概率的前提下，
   查找时间复杂度接近O(1)，
   性能更高一些。
6. 从算法实现难度上来比较，skiplist比平衡树要简单得多

# 4.Redis的单线程

## 4-1：为什么Redis是单线程

1. 可维护性对于一个项目来说非常重要，
   如果代码难以调试和测试，问题也经常难以复现，
   这对于任何一个项目来说都会严重地影响项目的可维护性。
   多线程模型虽然在某些方面表现优异，
   但是它却引入了程序执行顺序的不确定性，
   代码的执行过程不再是串行的，
   多个线程同时访问的变量如果没有谨慎处理就会带来诡异的问题。
   引入了多线程，我们就必须要同时引入并发控制
   来保证在多个线程同时访问数据时程序行为的正确性，
   这就需要工程师额外维护并发控制的相关代码，
   例如，我们会需要在可能被并发读写的变量上增加互斥锁：
   在访问这些变量或者内存之前也需要先对获取互斥锁，
   一旦忘记获取锁或者忘记释放锁就可能会导致各种诡异的问题，
   管理相关的并发控制机制也需要付出额外的研发成本和负担。
2. 使用单线程模型也并不意味着程序不能并发的处理任务，
   Redis 虽然使用单线程模型处理用户的请求，
   但是它却使用I/O多路复用机制并发处理
   来自客户端的多个连接，同时等待多个连接发送的请求。
   在 I/O 多路复用模型中，最重要的函数调用就是select以及类似函数，
   该方法的能够同时监控多个文件描述符的可读可写情况，
   当其中的某些文件描述符可读或者可写时，
   select 方法就会返回可读以及可写的文件描述符个数。
   使用 I/O 多路复用技术能够极大地减少系统的开销，
   系统不再需要额外创建和维护进程和线程来监听来自客户端的大量连接，
   减少了服务器的开发成本和维护成本。
3. Redis 选择单线程模型的决定性原因，
   Redis 并不是 CPU 密集型的服务，
   如果不开启AOF备份，所有Redis的操作都会在内存中
   完成不会涉及任何的 I/O 操作，
   这些数据的读写由于只发生在内存中，
   所以处理速度是非常快的；
   整个服务的瓶颈在于网络传输带来的
   延迟和等待客户端的数据传输，
   也就是网络 I/O，
   所以使用多线程模型处理全部的外部请求可能不是一个好的方案。
   比如说多线程中
   保存线程 1 的执行上下文；
   加载线程 2 的执行上下文；
   频繁的对线程的上下文进行切换
   可能还会导致性能地急剧下降，
   这可能会导致我们不仅没有提升请求处理的平均速度，
   反而进行了负优化

## 4-2：既然是单线程，那怎么监听大量的客户端连接呢？

Redis 通过IO 多路复用程序来监听
来自客户端的大量连接（或者说是监听多个 socket），
它会将感兴趣的事件及类型(读、写）
注册到内核中并监听每个事件是否发生。
这样的好处非常明显： 
I/O 多路复用技术的使用让Redis
不需要额外创建多余的线程
来监听客户端的大量连接，
降低了资源的消耗（和 NIO 中的 Selector 组件很像）。

## 4-3：Redis为什么又采用了多线程

适用于单个Redis服务器的命令不适用于数据分区；
数据分区无法解决热点读/写问题；
数据偏斜，重新分配和放大/缩小变得更加复杂
所以就需要提高网络 IO 读写性能

# 5.过期删除策略

## 5-1：Redis 给缓存数据设置过期时间有啥用？

因为内存是有限的，
如果缓存中的所有数据都是一直保存的话，
分分钟直接OOM的。
很多时候，我们的业务场景就是
需要某个数据只在某一时间段内存在，
比如我们的短信验证码可能只在1分钟内有效，
用户登录的 token 可能只在 1 天内有效。
如果使用传统的数据库来处理的话，
一般都是自己判断过期，
这样更麻烦并且性能要差很多。

## 5-2：Redis是如何判断数据是否过期的呢？

Redis 通过一个叫做过期字典（可以看作是hash表）
来保存数据过期的时间。
过期字典的键指向Redis数据库中的某个key(键)，
过期字典的值是一个long long类型的整数，
这个整数保存了key所指向的数据库键的过期时间。

## 5-3：过期策略分类

`Redis采用的是定期删除 + 懒惰删除策略。`

1. 惰性删除 ：只会在取出key的时候才对数据进行过期检查。
             这样对CPU最友好，
             但是可能会造成太多过期 key 没有被删除。
2. 定期删除 ：每隔一段时间抽取一批key执行删除过期key操作。
             并且，Redis 底层会并通过限制删除
             操作执行的时长和频率来
             减少删除操作对CPU时间的影响。
3. 立即删除。在设置键的过期时间时，
            创建一个回调事件，当过期时间达到时，
            由时间处理器自动执行键的删除操作。

### 5-3-1：定期删除策略

Redis 会将每个设置了过期时间的key放入到一个独立的字典中，
默认比如说每100ms进行一次过期扫描：
先随机抽取20个 key
删除这20个key中过期的key
如果过期的key比例超过1/4，
就继续随机抽取20个key，继续删除。

#### 5-3-1-1：为什不扫描所有的 key

Redis 是单线程，全部扫描会卡死。
而且为了防止每次扫描过期的key比例都超过1/4，
导致不停循环卡死线程，
Redis 为每次扫描添加了上限时间，默认是25ms。
如果客户端将超时时间设置的比较短，
比如 10ms，那么就会出现大量的链接因为超时而关闭，
业务端就会出现很多异常。
而且这时你还无法从Redis的slowlog中看到慢查询记录，
因为慢查询指的是逻辑处理过程慢，不包含等待时间。
如果在同一时间出现大面积 key 过期，
Redis 循环多次扫描过期词典，
直到过期的 key 比例小于 1/4。
这会导致卡顿，而且在高并发的情况下，
可能会导致缓存雪崩。

##### 5-3-1-1-1：为什么Redis为每次扫描添的上限时间是25ms

因为 Redis 是单线程，每个请求处理都需要排队，
而且由于Redis每次扫描都是25ms，也就是每个请求最多25ms，
100个请求就是 2500ms。
如果有大批量的 key 过期，
要给过期时间设置一个随机范围，
而不宜全部在同一时间过期，分散过期处理的压力。

#### 5-3-2-2：定期删除策略的实现

过期键的定期删除策略由activeExpireCycle函数实现，
每当Redis服务器的周期性操作serverCron函数执行时，
activeExpireCycle函数就会被调用，
它在规定的时间内，分多次遍历服务器中的各个数据库，
从数据库的expires字典中随机检查一部分键的过期时间，并删除其中的过期键。
activeExpireCycle函数的大体流程为：
函数每次运行时，都从一定数量的数据库中随机取出一定数量的键进行检查，
并删除其中的过期键，比如先从0号数据库开始检查，
下次函数运行时，可能就是从1号数据库开始检查，
直到15号数据库检查完毕，又重新从0号数据库开始检查，
这样可以保证每个数据库都被检查到。

### 5-3-2：懒惰删除策略

删除指令 del 会直接释放对象的内存，
大部分情况下，这个指令非常快，没有明显延迟。
不过如果删除的 key 是一个非常大的对象，
比如一个包含了千万元素的 hash，
在使用 FLUSHDB 和 FLUSHALL 删除包含大量键的数据库时，
那么删除操作就会导致单线程卡顿。
redis 4.0 引入了 lazyfree 的机制，
它可以将删除键或数据库的操作放在后台线程里执行， 
从而尽可能地避免服务器阻塞。

#### 5-3-2-1：懒惰删除策略优缺点

优点：对CPU时间非常友好
缺点：对内存非常不友好
举个例子，如果数据库有很多的过期键，
而这些过期键又恰好一直没有被访问到，
那这些过期键就会一直占用着宝贵的内存资源，造成资源浪费。

#### 5-3-2-2：惰性删除策略的实现

过期键的惰性删除策略由expireIfNeeded函数实现，
所有读写数据库的Redis命令在执行之前都会调用expireIfNeeded函数对输入键进行检查：
如果输入键已经过期，那么将输入键从数据库中删除
如果输入键未过期，那么不做任何处理

### 5-3-3：从库的过期策略

从库不会进行过期扫描，从库对过期的处理是被动的。
主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，
同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key。
因为指令同步是异步进行的，
所以主库过期的 key 的 del 指令没有及时同步到从库的话，
会出现主从数据的不一致，主库没有的数据在从库里还存在。

### 5-3-4：定时删除策略

定时删除策略通过使用定时器，
定时删除策略可以保证过期键尽可能快地被删除，并释放过期键占用的内存。

#### 5-3-4-1：定时删除策略优缺点

优点：对内存非常友好
缺点：对CPU时间非常不友好

举个例子，如果有大量的命令请求等待服务器处理，
并且服务器当前不缺少内存，
如果服务器将大量的CPU时间用来删除过期键，
那么服务器的响应时间和吞吐量就会受到影响。
也就是说，如果服务器创建大量的定时器，
服务器处理命令请求的性能就会降低


## 5-4：缓存淘汰机制

volatile-lru（least frequently used）：从已设置过期时间的数据集
                                      中挑选最近最少使用的数据淘汰
volatile-ttl：从已设置过期时间的数据集
               中挑选将要过期的数据淘汰
volatile-random：从已设置过期时间的数据集
                 中任意选择数据淘汰
allkeys-lru（least recently used）：当内存不足以容纳新写入数据时，
                                    在键空间中，移除最近最少使用的key
allkeys-random：从数据集中任意选择数据淘汰
no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，
             新写入操作会报错。这个应该没人使用吧！
volatile-lfu（least frequently used）：从已设置过期时间的数据集
                                       中挑选最不经常使用的数据淘汰
allkeys-lfu（least frequently used）：当内存不足以容纳新写入数据时，
                                      在键空间中，移除最不经常使用的 key

### 5-4-1：LRU算法原理

如果一个数据在最近一段时间没有被访问到，
那么在将来它被访问的可能性也很小。
也就是说，当限定的空间已存满数据时，
应当把最久没有被访问到的数据淘汰。

#### 5-4-1-1：如何实现LRU

方法三种

1. 用一个数组来存储数据，给每一个数据项标记一个访问时间戳，
   每次插入新数据项的时候，
   先把数组中存在的数据项的时间戳自增，
   并将新数据项的时间戳置为0并插入到数组中。
   每次访问数组中的数据项的时候，
   将被访问的数据项的时间戳置为0。
   当数组空间已满时，
   将时间戳最大的数据项淘汰。
2. 利用一个链表来实现，
   每次新插入数据的时候将新数据插到链表的头部；
   每次缓存命中（即数据被访问），
   则将数据移到链表头部；
   那么当链表满的时候，
   就将链表尾部的数据丢弃。
3. 利用链表和hashmap。
   当需要插入新的数据项的时候，
   如果新数据项在链表中存在（一般称为命中），
   则把该节点移到链表头部，
   如果不存在，则新建一个节点，
   放到链表头部，若缓存满了，
   则把链表最后一个节点删除即可。
   在访问数据的时候，
   如果数据项在链表中存在，
   则把该节点移到链表头部，
   否则返回-1。
   这样一来在链表尾部的节点就是
   最近最久未访问的数据项。

#### 5-4-1-2：LRU手写

```java
public class LRULinkedHashMap<K, V> extends LinkedHashMap<K, V> {  
    private final int maxCapacity;  
    private static final float DEFAULT_LOAD_FACTOR = 0.75f;  
    private final Lock lock = new ReentrantLock();  
    public LRULinkedHashMap(int maxCapacity) {  
        super(maxCapacity, DEFAULT_LOAD_FACTOR, true);  
        this.maxCapacity = maxCapacity;  }  
    @Override 
    protected boolean removeEldestEntry(java.util.Map.Entry<K, V> eldest) {  
        return size() > maxCapacity;  
    }  
    @Override 
    public boolean containsKey(Object key) {  
        try {  
            lock.lock();  
            return super.containsKey(key);  
        } finally {  
            lock.unlock();  }  }  
    @Override 
    public V get(Object key) {  
        try {  
            lock.lock();  
            return super.get(key);  
        } finally {  
            lock.unlock();  }  }  
    @Override 
    public V put(K key, V value) {  
        try {  
            lock.lock();  
            return super.put(key, value);  
        } finally {  
            lock.unlock();  }  }  
    public int size() {  
        try {  
            lock.lock();  
            return super.size();  
        } finally {  
            lock.unlock();  }  }  
    public void clear() {  
        try {  
            lock.lock();  
            super.clear();  
        } finally {  
            lock.unlock();  }  }  
    public Collection<Map.Entry<K, V>> getAll() {  
        try {  
            lock.lock();  
            return new ArrayList<Map.Entry<K, V>>(super.entrySet());  
        } finally {  
            lock.unlock();  }  }  }  
```

## 5-5：复制功能（主从）对过期键的处理

在主从复制模式下，从服务器的过期键删除动作由主服务器控制：
主服务器在删除一个过期键后，
会显式地向所有从服务器发送一个DEL命令，
告知从服务器删除这个过期键。
从服务器在执行客户端发送的读命令时
即使发现该键已过期也不会删除该键，照常返回该键的值。
从服务器只有接收到主服务器发送的DEL命令后，才会删除过期键。

## 5-6：持久化对过期键的处理

### 5-6-1：RDB对过期键的处理

在执行SAVE命令或者BGSAVE命令创建一个新的RDB文件时，
程序会对数据库中的键进行检查，
已过期的键不会被保存到新创建的RDB文件中。
比如说，如果数据库中包含3个键k1、k2、k3，
并且k2已经过期，那么创建新的RDB文件时，
程序只会将k1和k3保存到RDB文件中，k2则会被忽略。
在启动Redis服务器时，如果服务器只开启了RDB持久化，
那么服务器将会载入RDB文件：
如果服务器以主服务器模式运行，
在载入RDB文件时，程序会对文件中保存的键进行检查，
未过期的键会被载入到数据库中，过期键会被忽略。
如果服务器以从服务器模式运行，在载入RDB文件时，
文件中保存的所有键，不论是否过期，都会被载入到数据库中。
因为主从服务器在进行数据同步（完整重同步）的时候，
从服务器的数据库会被清空，所以一般情况下，过期键对载入RDB文件的从服务器不会造成影响。

### 5-6-2：AOF对过期键的处理

如果数据库中的某个键已经过期，
并且服务器开启了AOF持久化功能，
当过期键被惰性删除或者定期删除后，
程序会向AOF文件追加一条DEL命令，显式记录该键已被删除。
比如说如果客户端执行命令GET message访问已经过期的message键，
那么服务器将执行3个动作：
从数据库中删除message键
追加一条DEL message命令到AOF文件
向执行GET message命令的客户端返回空回复
在执行AOF文件重写时，程序会对数据库中的键进行检查，
已过期的键不会被保存到重写后的AOF文件中。

# 6.持久化机制

## 6-1：什么是Redis持久化？

将数据(如内存中的对象)保存到可永久保存的存储设备中。

## 6-2：Redis 为什么要持久化?

Redis 中的数据类型都支持Push/Pop、Add/Remove
及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。
在此基础上，Redis 支持各种不同方式的排序。
为了保证效率，数据都是缓存在内存中。
因为数据都是缓存在内存中的，
当你重启系统或者关闭系统后，
缓存在内存中的数据都会消失殆尽，再也找不回来了。
所以，为了让数据能够长期保存，
就要将 Redis 放在缓存中的数据做持久化存储。

## 6-3：Redis 怎么实现持久化?

Redis有两种持久化的方式：快照（RDB文件）和追加式文件（AOF文件）

`RDB 持久化`：该机制可以在指定的时间间隔内生成数据集的时间点快照。
`AOF 持久化`：记录服务器执行的所有写操作命令，
             并在服务器启动时，通过重新执行这些命令来还原数据集。
             AOF文件中的命令全部以 Redis 协议的格式来保存，
             新命令会被追加到文件的末尾。 
             Redis 还可以在后台对 AOF 文件进行重写（rewrite），
             使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小
无持久化：让数据只在服务器运行时存在。
同时应用 AOF 和 RDB：当 Redis 重启时， 
它会优先使用 AOF 文件来还原数据集， 
因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整

### 6-3-1：RDB（快照）优缺点

`优点：`
RDB 是一个非常紧凑（compact）的文件，
它保存了 Redis 在某个时间点上的数据集。 
这种文件非常适合用于进行备份： 
比如说，你可以在最近的 24 小时内，
每小时备份一次 RDB 文件，
并且在每个月的每一天，
也备份一个 RDB 文件。 
这样的话，即使遇上问题，
也可以随时将数据集还原到不同的版本。
RDB 非常适用于灾难恢复：它只有一个文件，
并且内容都非常紧凑，可以在加密后将它传送到别的数据中心。
RDB 可以最大 Redis的性能：父进程在保存RDB文件时唯一要做的就是 
fork出一个子进程，然后这个子进程就会处理接下来的所有保存工作，
父进程无须执行任何磁盘 I/O 操作。RDB 在恢复大数据集时的
速度比 AOF 的恢复速度要快。
`缺点：`
如果你需要尽量避免在服务器故障时丢失数据，
RDB不太合适。 
虽然 Redis 允许你设置不同的保存点来控制保存RDB文件的频率， 
但是，因为RDB文件需要保存整个数据集的状态， 
所以它并不是一个轻松的操作。 
因此你可能会至少5分钟才保存一次RDB文件。 
在这种情况下，一旦发生故障停机，
你就可能会丢失好几分钟的数据。
每次保存 RDB 的时候，Redis 都要 fork() 
出一个子进程，
并由子进程来进行实际的持久化工作。 
在数据集比较庞大时， 
fork() 可能会非常耗时，
造成服务器在某某毫秒内停止处理客户端；
如果数据集非常巨大，
并且 CPU 时间非常紧张的话，
那么这种停止时间甚至可能会长达整整一秒。

### 6-3-2：AOF 的优缺点。

`优点：`
1、使用 AOF 持久化会让 Redis 变得非常耐久：
你可以设置不同的 fsync 策略，
比如无 fsync ，每秒钟一次 fsync ，
或者每次执行写入命令时 fsync 。
AOF 的默认策略为每秒钟 fsync 一次，
在这种配置下，Redis 仍然可以保持良好的性能，
并且就算发生故障停机，
也最多只会丢失一秒钟的数据
fsync 会在后台线程执行，所以主线程可以继续努力地处理命令请求。
AOF 文件是一个只进行追加操作的日志文件，
因此对 AOF 文件的写入不需要进行 seek
即使日志因为某些原因而包含了未写入完整的命令
比如写入时磁盘已满，写入中途停机，等等，
redis-check-aof 工具也可以轻易地修复这种问题。
2、Redis 可以在 AOF 文件体积变得过大时，
自动地在后台对 AOF 进行重写：
重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。
整个重写操作是绝对安
全的，因为 Redis 在创建新 AOF 文件的过程中，
会继续将命令追加到现有的AOF 文件里面，
即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 
而一旦新 AOF文件创建完毕，
Redis 就会从旧 AOF 文件切换到新 AOF 文件，
并开始对新 AOF 文件进行追加操作。
`缺点：`
对于相同的数据集来说，
AOF 文件的体积通常要大于 RDB 文件的体积。
根据所使用的fsync策略，
AOF 的速度可能会慢于RDB。 
在一般情况下， 
每秒 fsync 的性能依然非常高， 
而关闭 fsync 可以让 AOF 的速度和 RDB一样快，
 即使在高负荷之下也是如此。 
 不过在处理巨大的写入载入时，
 RDB 可以提供更有保证的最大延迟时间

## 6-4：Redis持久化数据和缓存怎么做扩容？

如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。
如果Redis被当做一个持久化存储使用，
必须使用固定的keys-to-nodes映射关系，
节点的数量一旦确定不能变化。
否则的话,在Redis节点需要动态变化的情况，
必须使用可以在运行时进行数据再平衡的一套系统

## 6-5：持久化期间工作流程

客户端向数据库发送写命令 (数据在客户端的内存中)
数据库接收到客户端的写请求 (数据在服务器的内存中)
数据库调用系统API将数据写入磁盘 (数据在内核缓冲区中)
操作系统将写缓冲区传输到磁盘控控制器 (数据在磁盘缓存中)
操作系统的磁盘控制器将数据写入实际的物理媒介 中 (数据在磁盘中)

## 6-6：持久化机制

修改



# 7.集群主从复制

## 7-1：Redis的结构

Redis的主从结构可以采用一主多从或者级联结构，
Redis主从复制可以根据是否是全量分为全量同步和增量同步

## 7-2：Redis主从复制的特点

1. redis采用异步方式复制数据到slave节点，
   从redis2.8开始，slave节点会周期性地
   确认自己每次复制的数据量；
2. 一个master节点可以配置多个slave节点；
3. slave节点可以连接其他的slave节点；
4. slave节点做复制的时候，不会阻塞master节点的正常工作；
5. slave节点做复制的时候，也不会阻塞对自己的查询操作，
   它会用旧数据集来提供服务，
   但在复制完成时，需要删除旧数据集，
   加载新数据集，这时会暂停对外服务；
6. slave节点主要用来横向扩容，做读写分离，
   扩容的slave节点可以提高读的吞吐量；
7. 如果采用主从架构，必须开启master节点的持久化，
   不建议用slave节点作master节点的数据热备，
   因为如果一旦关掉master的持久化，
   可能在master宕机重启时数据是空的，
   然后一经复制，slave节点也会随之丢失。



# 8.缓存穿透、雪崩、击穿

## 8-1：缓存穿透

### 8-1-1：什么是缓存穿透

解释 1：缓存查询一个没有的 key，同时数据库也没有，
       如果黑客大量的使用这种方式，那么就会导致 DB 宕机。

解决方案：我们可以使用一个默认值来防止，
         例如，当访问一个不存在的 key，然后再去访问数据库，
         还是没有，那么就在缓存里放一个占位符，下次来的时候，
         检查这个占位符，如果发生时占位符，就不去数据库查询了，防止 DB 宕机。

解释 2：大量请求查询一个刚刚失效的 key，
       导致 DB 压力倍增，可能导致宕机，
       但实际上，查询的都是相同的数据。

解决方案：可以在这些请求代码加上双重检查锁。
         但是那个阶段的请求会变慢。不过总比 DB 宕机好。

### 8-1-2：缓存穿透的解决方案

1. 加入布隆过滤器
   通过它我们可以非常方便地
   判断一个给定数据是否存在于海量数据中。
   我们需要的就是判断 key 是否合法，
   有没有感觉布隆过滤器就是我们想要找的那个数据。
   首先把所有可能存在的请求的值都存放在布隆过滤器中，
   当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。
   不存在的话，直接返回请求参数错误信息给客户端，
   存在的话才会走下面的流程。
2. 如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），
   我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟

## 8-2：缓存雪崩

### 8-2-1：什么是缓存雪崩

缓存在同一时间大面积的失效，
后面的请求都直接落到了数据库上，
造成数据库短时间内承受大量请求。
比如说系统的缓存模块出了问题比如宕机导致不可用。
造成系统的所有访问，都要走数据库。
或者说秒杀活动，开始 12 个小时之前，
我们统一存放了一批商品到 Redis 中，
设置的缓存过期时间也是 12 个小时，
那么秒杀开始的时候，
这些秒杀的商品的访问直接就失效了。
导致的情况就是，相应的请求直接就落到了数据库上，
就像雪崩一样可怕。

### 8-2-2：有哪些解决办法？

事前：redis 高可用，主从+哨兵，
     redis cluster，避免全盘崩溃。
事中：本地 ehcache 缓存 + hystrix 限流&降级，
     避免 MySQL 被打死。
事后：redis 持久化，一旦重启，
     自动从磁盘上加载数据，快速恢复缓存数据。

用户发送一个请求，系统 A 收到请求后，
先查本地 ehcache 缓存，如果没查到再查 redis。
如果 ehcache 和 redis 都没有，再查数据库，
将数据库中的结果，写入 ehcache 和 redis 中。
限流组件，可以设置每秒的请求，有多少能通过组件，
剩余的未通过的请求可以通过走降级！
可以返回一些默认的值，或者友情提示，或者空白的值。
好处：
数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。
只要数据库不死，就是说，
对用户来说，2/5 的请求都是可以被处理的。
只要有 2/5 的请求可以被处理，
就意味着你的系统没死，
对用户来说，可能就是点击几次刷不出来页面
，但是多点几次，就可以刷出来一次。

## 8-3：缓存击穿

### 8-3-1：什么是缓存击穿

对于一些设置了过期时间的key，
如果这些key可能会在某些时间点被超高并发地访问，
是一种非常“热点”的数据。
缓存在某个时间点过期的时候，
恰好在这个时间点对这个Key有大量的并发请求过来，
这些请求发现缓存过期一般都会从后端DB加载数据并回射到缓存，
这个时候大并发的请求可能会瞬间把后端DB压垮。

### 8-3-2：缓存击穿的解决方案

1. 使用互斥锁(mutex key)
是使用mutex。就是在缓存失效的时候（判断拿出来的值为空），
不是立即去load db，
而是先使用缓存工具的某些带成功操作返回值的操作
（比如Redis的SETNX或者Memcache的ADD）
去set一个mutex key，当操作返回成功时，
再进行load db的操作并回设缓存；
否则，就重试整个get缓存的方法。
```java
public String get(key) {
      String value = redis.get(key);
      if (value == null) { //代表缓存值过期
          //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db
          if (redis.setnx(key_mutex, 1, 3 * 60) == 1) {  //代表设置成功
               value = db.get(key);
                      redis.set(key, value, expire_secs);
                      redis.del(key_mutex);
              } else {  //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可
                      sleep(50);
                      get(key);  //重试
              }
          } else {
              return value;}}
```
2. "提前"使用互斥锁(mutex key)
在value内部设置1个超时值(timeout1), 
timeout1比实际的memcache timeout(timeout2)小。
当从cache读取到timeout1发现它已经过期时候，
马上延长timeout1并重新设置到cache。
然后再从数据库加载数据并设置到cache中。
```java
v = memcache.get(key);
if (v == null) {
    if (memcache.add(key_mutex, 3 * 60 * 1000) == true) {
        value = db.get(key);
        memcache.set(key, value);
        memcache.delete(key_mutex);
    } else {
        sleep(50);
        retry();
    }
} else {
    if (v.timeout <= now()) {
        if (memcache.add(key_mutex, 3 * 60 * 1000) == true) {
            // extend the timeout for other threads
            v.timeout += 3 * 60 * 1000;
            memcache.set(key, v, KEY_TIMEOUT * 2);

            // load the latest value from db
            v = db.get(key);
            v.timeout = KEY_TIMEOUT;
            memcache.set(key, value, KEY_TIMEOUT * 2);
            memcache.delete(key_mutex);
        } else {
            sleep(50);
            retry();
        }
    }
}
```
3. 采用永远不过期的策略

(1) 从redis上看，确实没有设置过期时间，
    这就保证了，不会出现热点key过期问题，也就是“物理”不过期。

(2) 从功能上看，如果不过期，可能就是成为静态的了
    所以把过期时间存在key对应的value里，
    如果发现要过期了，
    通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期
```java
String get(final String key) {
        V v = redis.get(key);
        String value = v.getValue();
        long timeout = v.getTimeout();
        if (v.timeout <= System.currentTimeMillis()) {
            // 异步更新后台异常执行
            threadPool.execute(new Runnable() {
                public void run() {
                    String keyMutex = "mutex:" + key;
                    if (redis.setnx(keyMutex, "1")) {
                        // 3 min timeout to avoid mutex holder crash
                        redis.expire(keyMutex, 3 * 60);
                        String dbValue = db.get(key);
                        redis.set(key, dbValue);
                        redis.delete(keyMutex);
                    }
                }
            });
        }
        return value;
}
```
### 8-3-3：几种方案优缺点

1. 方案一：
 优势
   1. 思路简单
   2. 保证一致性
 缺点
   3. 代码复杂度增大2. 存在死锁的风险3. 存在线程池阻塞的风险

2. 方案二
 优点
   加另外一个过期时间
   保证一致性
 缺点同上

3. 方案三：
 优点
   1. 不过期(本文)
   2. 异步构建缓存，不会阻塞线程池
 缺点
   1. 不保证一致性。
   2. 代码复杂度增大(每个value都要维护一个timekey)。
   3. 占用一定的内存空间(每个value都要维护一个timekey)。

## 8-4：什么是缓存并发竞争？怎么解决？

解释：多个客户端写一个 key，如果顺序错了，
      数据就不对了。但是顺序我们无法控制。

解决方案：使用分布式锁，例如 zk，
         同时加入数据的时间戳。同一时刻，
         只有抢到锁的客户端才能写入，同时，写入时，
         比较当前数据的时间戳和缓存中数据的时间戳。



# 9.缓存和数据库数据的一致性

## 9-1：什么是缓存和数据库双写不一致

连续写数据库和缓存，但是操作期间，出现并发了，数据不一致了。

## 9-2：解决方案

通常，更新缓存和数据库有几种顺序：
1. 先更新数据库，再更新缓存。
2. 先删缓存，再更新数据库。
3. 先更新数据库，再删除缓存。
那么
`先更新数据库，再更新缓存。`
这么做的问题是：当有 2 个请求同时更新数据，
那么如果不使用分布式锁，
将无法控制最后缓存的值到底是多少。
也就是并发写的时候有问题。
`先删缓存，再更新数据库。`
这么做的问题：如果在删除缓存后，
有客户端读数据，将可能读到旧数据，
并有可能设置到缓存中，导致缓存中的数据一直是老数据。
\\有 2 种解决方案：\\
   1. 使用“双删”，即删更删，最后一步的删除作为异步操作，
      就是防止有客户端读取的时候设置了旧值。
   2. 使用队列，当这个 key 不存在时，
      将其放入队列，串行执行，
      必须等到更新数据库完毕才能读取数据。
`先更新数据库，再删除缓存`
如果先更新数据库，再删除缓存，
那么就会出现更新数据库之前有瞬间数据不是很及时。
同时，如果在更新之前，缓存刚好失效了，
读客户端有可能读到旧值，
然后在写客户端删除结束后再次设置了旧值，非常巧合的情况。
有 2 个前提条件：缓存在写之前的时候失效，
同时，在写客户度删除操作结束后，
放置旧数据 —— 也就是读比写慢。设置有的写操作还会锁表。
如果出现了就可以使用双删
记录更新期间有没有客户端读数据库，
如果有，在更新完数据库之后，执行延迟删除。
还有一种可能，如果执行更新数据库，准备执行删除缓存时，
服务挂了，执行删除失败
可以通过订阅数据库的 binlog 来删除。



# 10.事务

## 10-1：Redis事务的概念

Redis 事务的本质是一组命令的集合。
事务支持一次执行多个命令，一个事务中所有命令都会被序列化。
在事务执行过程，会按照顺序串行化执行队列中的命令，
其他客户端提交的命令请求不会插入到事务执行命令序列中。

## 10-2：Redis事务的三个阶段

开启：以MULTI开始一个事务
入队：将多个命令入队到事务中，
     接到这些命令并不会立即执行，
     而是放到等待执行的事务队列里面
执行：由EXEC命令触发事务

## 10-3：Redis事务相关命令

multi，标记一个事务块的开始，返回 ok
exec，执行所有事务块内，事务块内所有命令执行的先后顺序的返回值，
      操作被，返回空值 nil
discard，取消事务，放弃执行事务块内的所有命令，返回 ok
watch，监视 key 在事务执行之前是否被其他指令改动，
       若已修改则事务内的指令取消执行，返回 ok
unwatch，取消 watch 命令对 key 的监视，返回 ok

## 10-4：Redis的ACID

Redis只`一致性`和`隔离性`两个特性，其他特性是不支持的。

### 10-4-1：原子性

单个 Redis 命令的执行是原子性的，
但 Redis 没有在事务上增加任何维持原子性的机制，
所以 Redis 事务的执行并不是原子性的
如果一个事务队列中的所有命令都被成功地执行，
那么称这个事务执行成功
另一方面，如果Redis服务器进程在执行事务的过程中被停止 
比如接到 KILL 信号、宿主机器停机，等等，那么事务执行失败
事务失败时，Redis 也不会进行任何的重试或者回滚动作，
不满足要么全部全部执行，要么都不执行的条件

### 10-4-2：一致性

首先，如果一个事务的指令全部被执行，
那么数据库的状态是满足数据库完整性约束的
其次，如果一个事务中有的指令有错误，
那么数据库的状态是满足数据完整性约束的
最后，如果事务运行到某条指令时，
进程被kill掉了，
如果当前redis采用的是内存模式，
那么重启之后redis数据库是空的，
那么满足一致性条件
如果当前采用RDB模式存储的，
在执行事务时，Redis不会中断事务去执行保存RDB的工作，
只有在事务执行之后，
保存 RDB 的工作才有可能开始。
所以当 RDB 模式下的 Redis 服务器进程在事务中途被杀死时，
事务内执行的命令，不管成功了多少，
都不会被保存到 RDB 文件里。 
恢复数据库需要使用现有的 RDB 文件，
而这个 RDB 文件的数据保存的是最近一次的数据库快照，
所以它的数据可能不是最新的，
但只要 RDB 文件本身没有因为 其他问题而出错，
那么还原后的数据库就是一致的
如果当前采用的是AOF存储的，
那么可能事务的内容还未写入到AOF文件，
那么此时肯定是满足一致性的，
如果事务的内容有部分写入到AOF文件中，
那么需要用工具把AOF中事务执行部分成功的指令移除，
这时，移除之后的AOF文件也是满足一致性的
所以，redis事务满足一致性约束

### 10-4-3：一致性

Redis 是单进程程序，并且它保证在执行事务时，
不会对事务进行中断，
事务可以运行直到执行完所有事务队列中的命令为止。
因此，Redis 的事务是总是带有隔离性的。

### 10-4-4：持久性

因为事务不过是用队列包裹起了一组 Redis 命令，
并没有提供任何额外的持久性功能，
所以事务的持久性由 Redis 所使用的持久化模式决定
在单纯的内存模式下，事务肯定是不持久的
在 RDB 模式下，
服务器可能在事务执行之后、
RDB 文件更新之前的这段时间失败，
所以 RDB 模式下的 Redis 事务也是不持久的
在 AOF 的“总是 SYNC ”模式下，
事务的每条命令在执行成功之后，
都会立即调用 fsync 或 fdatasync 
将事务数据写入到 AOF 文件。
但是，这种保存是由后台线程进行的，
主线程不会阻塞直到保存成功，
所以从命令执行成功到数据保存到硬盘之间，
还是有一段非常小的间隔，
所以这种模式下的事务也是不持久的。
其他 AOF 模式也和“总是 SYNC ”模式类似，
所以它们都是不持久的。

# 11.Redis应用

## 11-1：为什么Redis 变慢了

1. 使用复杂度高的命令
   通过查看慢日志记录，
   我们就可以知道在什么时间执行哪些命令比较耗时，
   如果你的业务经常使用O(n)以上复杂度的命令，
   例如sort、sunion、zunionstore，
   或者在执行O(n)命令时操作的数据量比较大，
   这些情况下Redis处理数据时就会很耗时。
   最好不使用这些复杂度较高的命令，
   并且一次不要获取太多的数据，
   每次尽量操作少量的数据，
   让Redis可以及时处理返回。
2. 存储大key
   针对大key的问题，
   Redis官方在4.0版本推出了lazy-free的机制，
   用于异步释放大key的内存
   降低对Redis性能的影响。
   即使这样，我们也不建议使用大key，
   大key在集群的迁移过程中，也会影响到迁移的性能，
3. 集中过期
   平时在使用Redis时没有延时比较大的情况，
   但在某个时间点突然出现一波延时，
   而且报慢的时间点很有规律，
   例如某个整点，或者间隔多久就会发生一次。
   如果出现这种情况，
   就需要考虑是否存在大量key集中过期的情况。
   在集中过期时增加一个随机时间，
   把这些需要过期的key的时间打散即可。
4. 实例内存达到上限
   有时我们把Redis当做纯缓存使用，
   就会给实例设置一个内存上限maxmemory，
   然后开启LRU淘汰策略。
   当实例的内存达到了maxmemory后，
   你会发现之后的每次写入新的数据，有可能变慢了。
   导致变慢的原因是，
   当Redis内存达到maxmemory后，
   每次写入新的数据之前，
   必须先踢出一部分数据，
   让内存维持在maxmemory之下。
   这个踢出旧数据的逻辑也是需要消耗时间的，
   而具体耗时的长短，要取决于配置的淘汰策略
5. fork耗时严重
   如果你的Redis开启了自动生成RDB和AOF重写功能，
   那么有可能在后台生成RDB和AOF重写时导致Redis的访问延迟增大，
   而等这些任务执行完毕后，延迟情况消失。
   生成RDB和AOF都需要父进程fork出一个子进程进行数据的持久化，
   在fork执行过程中，父进程需要拷贝内存页表给子进程，
   如果整个实例内存占用很大，
   那么需要拷贝的内存页表会比较耗时，
   此过程会消耗大量的CPU资源，在完成fork之前，
   整个实例会被阻塞住，无法处理任何请求，
   如果此时CPU资源紧张，那么fork的时间会更长，
   甚至达到秒级。这会严重影响Redis的性能。
   所以使用Redis时建议部署在物理机上，降低fork的影响。
6. 绑定CPU
   绑定CPU的Redis，在进行数据持久化时，
   fork出的子进程，子进程会继承父进程的CPU使用偏好，
   而此时子进程会消耗大量的CPU资源进行数据持久化，
   子进程会与主进程发生CPU争抢，
   这也会导致主进程的CPU资源不足访问延迟增大。
   所以在部署Redis进程时，
   如果需要开启RDB和AOF重写机制，
   一定不能进行CPU绑定操作！
7. 开启AOF
   当执行AOF文件重写时会因为fork执行耗时
   导致Redis延迟增大，除了这个之外，
   如果开启AOF机制，设置的策略不合理，
   也会导致性能问题。
8. 使用Swap
   如果你发现Redis突然变得非常慢，
   每次访问的耗时都达到了几百毫秒甚至秒级，
   那此时就检查Redis是否使用到了Swap，
   这种情况下Redis基本上已经无法提供高性能的服务。
   我们知道，操作系统提供了Swap机制，
   目的是为了当内存不足时，
   可以把一部分内存中的数据换到磁盘上，
   以达到对内存使用的缓冲。
   但当内存中的数据被换到磁盘上后，
   访问这些数据就需要从磁盘中读取，
   这个速度要比内存慢太多！
9. 网卡负载过高
   Redis也稳定运行了很长时间，
   但在某个时间点之后开始，
   访问Redis开始变慢了，而且一直持续到现在，
   检查一下机器的网卡流量，
   是否存在网卡流量被跑满的情况。
   网卡负载过高，在网络层和TCP层就会出现数据发送延迟、
   数据丢包等情况。Redis的高性能除了内存之外，
   就在于网络IO，请求量突增会导致网卡负载变高。

# 12.锁

## 12-1：redis加锁的几种实现

redis能用的的加锁命令分表是INCR、SETNX、SET
1. 第一种锁命令INCR
这种加锁的思路是， key 不存在，那么 key 的值会先被初始化为0 ，然后再执行INCR操作进行加一。 
然后其它用户在执行 INCR 操作进行加一时，如果返回的数大于 1 ，说明这个锁正在被使用当中。
2. 第二种锁SETNX
这种加锁的思路是，如果 key 不存在，将 key 设置为 value 
如果 key 已存在，则 SETNX 不做任何动作
3. 第三种锁SET
之前方法都需要设置 key 过期。如果请求执行因为某些原因意外退出了，
导致创建了锁但是没有删除锁，那么这个锁将一直存在，以至于以后缓存再也得不到更新。
于是乎我们需要给锁加一个过期时间以防不测。 
但是借助 Expire 来设置就不是原子性操作了。
所以还可以通过事务来确保原子性，
使用 SET 命令本身已经从版本 2.6.12 开始包含了设置过期时间的功能。

## 12-2：分布式锁

### 12-2-1：什么是分布式锁？

当多个进程不在同一个系统中，用分布式锁控制多个进程对资源的访问。

#### 12-2-1-1：分布式锁使用场景

比如说线程A和线程B都共享某个变量X。
如果是单机情况下（单JVM），线程之间共享内存，
只要使用线程锁就可以解决并发问题。
如果是分布式情况下（多JVM），
线程A和线程B很可能不是在同一JVM中，
这样线程锁就无法起到作用了，
这时候就要用到分布式锁来解决。

#### 12-2-1-2：如何实现分布式锁

1. 互斥性
   在任意时刻，只有一个客户端能持有锁。
2. 不能死锁
   客户端在持有锁的期间崩溃而没有主动解锁，
   也能保证后续其他客户端能加锁。
3. 容错性
   只要大部分的Redis节点正常运行
   客户端就可以加锁和解锁。

### 12-2-2：分布式锁常见的三种实现方式：

1. 数据库乐观锁；
2. 基于Redis的分布式锁；
3. 基于ZooKeeper的分布式锁。

#### 12-2-2-1：如何实现加锁解锁

可以直接通过
```java
set key value px milliseconds nx
```
命令实现加锁， 
通过Lua脚本实现解锁。
```java
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```
#### 12-2-2-2：加锁代码分析

首先，set()加入了NX参数，
可以保证如果已有key存在，
则函数不会调用成功，
也就是只有一个客户端能持有锁，
满足互斥性。
其次，由于我们对锁设置了过期时间，
即使锁的持有者后续发生崩溃而没有解锁，
锁也会因为到了过期时间而自动解锁（即key被删除），
不会发生死锁。最后，
因为我们将value赋值为requestId，
用来标识这把锁是属于哪个请求加的，
那么在客户端在解锁的时候就可以进行校验
是否是同一个客户端。

#### 12-2-2-3：解锁代码分析

将Lua代码传到jedis.eval()方法里，
并使参数KEYS[1]赋值为lockKey，
ARGV[1]赋值为requestId。在执行的时候，
首先会获取锁对应的value值，
检查是否与requestId相等，
如果相等则解锁（删除key）。

#### 12-2-2-4：redlock算法

这个场景是假设有一个 redis cluster，
有 5 个 redis master 实例。然后执行如下步骤获取一把锁：

1. 获取当前时间戳，单位是毫秒；
2. 轮流尝试在每个 master 节点上创建锁，
   过期时间较短，一般就几十毫秒；
3. 尝试在大多数节点上建立一个锁，
   比如 5 个节点就要求是 3 个节点 n / 2 + 1；
4. 客户端计算建立好锁的时间，
   如果建立锁的时间小于超时时间，就算建立成功了；
5. 要是锁建立失败了，
   那么就依次之前建立过的锁删除；
6. 只要别人建立了一把分布式锁，
   你就得不断轮询去尝试获取锁。
