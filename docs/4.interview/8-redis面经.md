<!--
 * @Author: 孙浩然
 * @Date: 2020-07-28 11:04:41
 * @LastEditors: 孙浩然
 * @LastEditTime: 2020-08-28 09:56:50
 * @FilePath: \docs\4.interview\8-redis面经.md
 * @博客地址: 个人博客，如果各位客官觉得不错，请点个赞，谢谢。[地址](https://codefool0307.github.io/Java-Point/#/)，如对源码有异议请在我的博客中提问
-->
# 1.缓存

## 1-1：缓存思想

我们为了避免用户在请求数据的时候获取速度过于缓慢，所以我们在数据库之上增加了缓存这一层来弥补。

## 1-2：使用缓存为系统带来了什么问题

1. 系统复杂性增加：引入缓存之后，你要维护缓存和数据库的数据一致性、维护热点缓存等等。
2. 系统开发成本增加：引入缓存意味着系统需要一个单独的缓存服务，这是需要花费相应的成本的，并且这个成本还是很贵的，
   毕竟耗费的是宝贵的内存。但是，如果你只是简单的使用一下本地缓存存储一下简单的数据，并且数据量不大的话，那么就不需要单独去弄一个缓存服务。

## 1-3：本地缓存解决方案
先来聊聊本地缓存，这个实际在很多项目中用的蛮多，特别是单体架构的时候。数据量不大，并且没有分布式要求的话，使用本地缓存还是可以的。

常见的单体架构图如下，我们使用 Nginx 来做负载均衡，部署两个相同的服务到服务器，两个服务使用同一个数据库，并且使用的是本地缓存。

单体架构

那本地缓存的方案有哪些呢？且听 Guide 给你来说一说。

一：JDK 自带的 HashMap 和 ConcurrentHashMap 了。

ConcurrentHashMap 可以看作是线程安全版本的 HashMap ，两者都是存放 key/value 形式的键值对。但是，大部分场景来说不会使用这两者当做缓存，因为只提供了缓存的功能，并没有提供其他诸如过期时间之类的功能。一个稍微完善一点的缓存框架至少要提供：过期时间、淘汰机制、命中率统计这三点。

二： Ehcache 、 Guava Cache 、 Spring Cache 这三者是使用的比较多的本地缓存框架。

Ehcache 的话相比于其他两者更加重量。不过，相比于 Guava Cache 、 Spring Cache 来说， Ehcache 支持可以嵌入到 hibernate 和 mybatis 作为多级缓存，并且可以将缓存的数据持久化到本地磁盘中、同时也提供了集群方案（比较鸡肋，可忽略）。

Guava Cache 和 Spring Cache 两者的话比较像。

Guava 相比于 Spring Cache 的话使用的更多一点，它提供了 API 非常方便我们使用，同时也提供了设置缓存有效时间等功能。它的内部实现也比较干净，很多地方都和 ConcurrentHashMap 的思想有异曲同工之妙。

使用 Spring Cache 的注解实现缓存的话，代码会看着很干净和优雅，但是很容易出现问题比如缓存穿透、内存溢出。

三： 后起之秀 Caffeine。

相比于 Guava 来说 Caffeine 在各个方面比如性能要更加优秀，一般建议使用其来替代 Guava 。并且， Guava 和 Caffeine 的使用方式很像！

本地缓存固然好，但是缺陷也很明显，比如多个相同服务之间的本地缓存的数据无法共享。

下面我们从为什么要有分布式缓存为接入点来正式进入 Redis 的相关问题总结。

## 1-4：为什么要有分布式缓存?/为什么不直接用本地缓存?
我们可以把分布式缓存（Distributed Cache） 看作是一种内存数据库的服务，它的最终作用就是提供缓存数据的服务。

如下图所示，就是一个简单的使用分布式缓存的架构图。我们使用 Nginx 来做负载均衡，部署两个相同的服务到服务器，两个服务使用同一个数据库和缓存。

集中式缓存架构

本地的缓存的优势是低依赖，比较轻量并且通常相比于使用分布式缓存要更加简单。

再来分析一下本地缓存的局限性：

本地缓存对分布式架构支持不友好，比如同一个相同的服务部署在多台机器上的时候，各个服务之间的缓存是无法共享的，因为本地缓存只在当前机器上有。
本地缓存容量受服务部署所在的机器限制明显。 如果当前系统服务所耗费的内存多，那么本地缓存可用的容量就很少。
使用分布式缓存之后，缓存部署在一台单独的服务器上，即使同一个相同的服务部署在再多机器上，也是使用的同一份缓存。 并且，单独的分布式缓存服务的性能、容量和提供的功能都要更加强大。

使用分布式缓存的缺点呢，也很显而易见，那就是你需要为分布式缓存引入额外的服务比如 Redis 或 Memcached，你需要单独保证 Redis 或 Memcached 服务的高可用。

1. 缓存读写模式/更新策略
下面介绍到的三种模式各有优劣，不存在最佳模式，根据具体的业务场景选择适合自己的缓存读写模式。

5.1. Cache Aside Pattern（旁路缓存模式）
写：更新 DB，然后直接删除 cache 。
读：从 cache 中读取数据，读取到就直接返回，读取不到的话，就从 DB 中取数据返回，然后再把数据放到 cache 中。
Cache Aside Pattern 中服务端需要同时维系 DB 和 cache，并且是以 DB 的结果为准。另外，Cache Aside Pattern 有首次请求数据一定不在 cache 的问题，对于热点数据可以提前放入缓存中。

Cache Aside Pattern 是我们平时使用比较多的一个缓存读写模式，比较适合读请求比较多的场景。

5.2. Read/Write Through Pattern（读写穿透）
Read/Write Through 套路是：服务端把 cache 视为主要数据存储，从中读取数据并将数据写入其中。cache 服务负责将此数据读取和写入 DB，从而减轻了应用程序的职责。

写（Write Through）：先查 cache，cache 中不存在，直接更新 DB。 cache 中存在，则先更新 cache，然后 cache 服务自己更新 DB（同步更新 cache 和 DB）。
读(Read Through)： 从 cache 中读取数据，读取到就直接返回 。读取不到的话，先从 DB 加载，写入到 cache 后返回响应。
Read-Through Pattern 实际只是在 Cache-Aside Pattern 之上进行了封装。在 Cache-Aside Pattern 下，发生读请求的时候，如果 cache 中不存在对应的数据，是由客户端自己负责把数据写入 cache，而 Read Through Pattern 则是 cache 服务自己来写入缓存的，这对客户端是透明的。

和 Cache Aside Pattern 一样， Read-Through Pattern 也有首次请求数据一定不再 cache 的问题，对于热点数据可以提前放入缓存中。

5.3. Write Behind Pattern（异步缓存写入）
Write Behind Pattern 和 Read/Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 DB 的读写。

但是，两个又有很大的不同：Read/Write Through 是同步更新 cache 和 DB，而 Write Behind Caching 则是只更新缓存，不直接更新 DB，而是改为异步批量的方式来更新 DB。

Write Behind Pattern 下 DB 的写性能非常高，尤其适合一些数据经常变化的业务场景比如说一篇文章的点赞数量、阅读数量。 往常一篇文章被点赞 500 次的话，需要重复修改 500 次 DB，但是在 Write Behind Pattern 下可能只需要修改一次 DB 就可以了。

但是，这种模式同样也给 DB 和 Cache 一致性带来了新的考验，很多时候如果数据还没异步更新到 DB 的话，Cache 服务宕机就 gg 了。

## 1-5：为什么要⽤ redis/为什么要⽤缓存

1. 高性能方面，假如⽤户第⼀次访问数据库中的某些数据。这个过程会⽐较
   慢，因为是从硬盘上读取的。将该⽤户访问的数据存在缓存中，这样下⼀
   次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接
   操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步
   改变缓存中相应的数据即可！

2. ⾼并发：直接操作缓存能够承受的请求是远远⼤于直接访问数据库的，所
   以我们可以考虑把数据库中的部分数据转移到缓存中去，这样⽤户的⼀部
   分请求会直接到缓存这⾥⽽不⽤经过数据库。

## 1-6：为什么要⽤ redis ⽽不⽤ map/guava 做缓存?

缓存分为本地缓存和分布式缓存。以 Java 为例，使⽤⾃带的 map 或者 guava 实现的是本地缓存，最主要的特点是轻量以及快速，⽣命周期随着 jvm 的销毁⽽结束，并且在多实例的情况下，每个实例都需要各⾃保存⼀份缓存，缓存不具有⼀致性。

使⽤ redis 或 memcached 之类的称为分布式缓存，在多实例的情况下，各实例共⽤⼀份缓存数据，缓存具有⼀致性。缺点是需要保持 redis 或 memcached服务的⾼可⽤，整个程序架构上较为复杂。

## Redis与Memcached区别

1. redis⽀持更丰富的数据类型（⽀持更复杂的应⽤场景） ： Redis不仅
   仅⽀持简单的k/v类型的数据，同时还提供list， set， zset， hash
   等数据结构的存储。 memcache⽀持简单的数据类型，String。
2. Redis⽀持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时
   候可以再次加载进⾏使⽤,⽽Memecache把数据全部存在内存之中。
3. 集群模式： memcached没有原⽣的集群模式，需要依靠客户端来实现往
   集群中分⽚写⼊数据；但是 redis ⽬前是原⽣⽀持 cluster 模式的.
4. Memcached是多线程，⾮阻塞IO复⽤的⽹络模型； Redis使⽤单线程的多
   路 IO 复⽤模型。

## 为什么说Redis快

书本

# 缓存雪崩

## 什么是缓存雪崩



## 如何解决 Redis 的并发竞争 Key 问题

所谓 Redis 的并发竞争 Key 的问题也就是多个系统同时对⼀个 key 进⾏操作，但是最后执⾏的顺序和我们期望的顺序不同，这样也就导致了结果的不同！

推荐⼀种⽅案：分布式锁（zookeeper 和 redis 都可以实现分布式锁）。（如果不存在 Redis 的并发竞争 Key 问题，不要使⽤分布式锁，这样会影响性能）基于zookeeper临时有序节点可以实现的分布式锁。⼤致思想为：每个客户端对某个⽅法加锁时，在zookeeper上的与该⽅法对应的指定节点的⽬录下，⽣成⼀个唯⼀的瞬时有序节点。 判断是否获取锁的⽅式很简单，只需要判断有序节点中序号最⼩的⼀个。 当释放锁的时候，只需将这个瞬时节点删除即可。同时，其可以避免服务宕机导致的锁⽆法释放，⽽产⽣的死锁问题。完成业务流程后，删除对应的⼦节点释放锁。在实践中，当然是从以可靠性为主。所以⾸推Zookeeper。


## Redis的数据结构

## 介绍zset类型的底层结构



## redis怎么保证原子性？

因为redis是单线程。


## Redis单线程，如何实现异步和非阻塞

对于Redis的网络请求，Redis会有一个EventLoop，里面有两个数组events,fired。events存放被注册的事件，fired用于存放EventLoop从多路复用器（epoll）中读取到的，将要执行的事件。

异步和非阻塞就反映在这里，注册到多路复用器（epoll）后去做其他事，之后通过主动轮询多路复用器，来逐个取出将要执行的事件，放入fired，逐个执行，这个过程是单线程的，因此不会出现并发问题。


## redis为什么是单进程？

如果我的数据全都在内存里，我单线程的去操作 就是效率最高的，为什么呢，因为多线程的本质就是 CPU 模拟出来多个线程的情况，这种模拟出来的情况就有一个代价，就是上下文的切换，对于一个内存的系统来说，它没有上下文的切换就是效率最高的。redis 用 单个CPU 绑定一块内存的数据，然后针对这块内存的数据进行多次读写的时候，都是在一个CPU上完成的，所以它是单线程处理这个事。

## 什么时候可以用多线程

下层的存储等慢速的情况

## 引出redis的分布式锁

## redis负载多少，测过没有

## Redis的zset原理