<!--
 * @Author: 孙浩然
 * @Date: 2020-07-24 15:15:07
 * @LastEditors: 孙浩然
 * @LastEditTime: 2020-07-28 11:30:55
 * @FilePath: \docs\4.interview\6-计算机网络.md
 * @博客地址: 个人博客，如果各位客官觉得不错，请点个赞，谢谢。[地址](https://codefool0307.github.io/Java-Point/#/)，如对源码有异议请在我的博客中提问
--> 
<!--
 * @Author: 孙浩然
 * @Date: 2020-07-24 15:15:07
 * @LastEditors: 孙浩然
 * @LastEditTime: 2020-07-28 11:08:34
 * @FilePath: \docs\4.interview\6-计算机网络.md
 * @博客地址: 个人博客，如果各位客官觉得不错，请点个赞，谢谢。[地址](https://codefool0307.github.io/Java-Point/#/)，如对源码有异议请在我的博客中提问
--> 
# 1.各层协议

## 1-1：OSI与TCP/IP各层的结构与功能,都有哪些协议?

![avatar](http://qd6kny79g.bkt.clouddn.com/01-TCP.jpg)

![avatar](http://qd6kny79g.bkt.clouddn.com/02-TCP.jpg)

1. 应用层

为应用程序提供服务并且规定通信的规范和细节

常见的协议:
* HTTP(超文本传输协议)
* FTP(文件传输协议)
* TELNET(远程登录协议)
* SMTP(简单邮件传输协议)
* DNS(域名解析协议)

6. 表示层

主要负责数据格式的转换

5. 会话层

负责建立和断开通信连接

4.传输层

是唯一负责总体的数据传输和数据控制的一层。

* TCP: ~~面向连接 ,可靠性强, 传输效率低~~
* UDP: ~~无连接,可靠性弱,传输效率快~~

3.网络层

将数据传输到目标地址；主要负责寻找地址和路由选择，网络层还可以实现拥塞控制、网际互连等功能

* IP
* IPX
* RIP
* OSPF等

2.数据链路层

物理地址寻址、数据的成帧、流量控制、数据的检错、重发等。

* ARP
* RARP
* SDLC
* HDLC
* PPP
* STP
* 帧中继等

1. 物理层

负责0、1比特流(0/1序列)与电压的高低、光的闪灭之间的转换


## 1-2：⽹络层与数据链路层有什么关系呢？

1. IP 的作⽤是主机之间通信⽤的，负责在「没有直连」的两个⽹络之间进⾏通信传输
2. MAC 的作⽤则是实现「直连」的两个设备之间通信。

理解一下：

就比如说，你想从xx村到海南市，你不得做公交车、汽车、火车、轮船到海南

那么你这整个的一个路线图，就是一个网络层，行程开端就是xx村---->>>源IP，目的IP---->行程结束就是海南

那么我从xx村到xx镇相当于是在这个区间内移动路线，也就是数据链路层，其中，xx村好⽐源 MAC 地址，xx镇好⽐⽬的 MAC 地址。
（只要是在线路（网络层包含的都是））

这个xx村、海南不会发生变化，但是中间的位置会一直在变，也就是说

IP源、目的不会变， Mac源、目的会变化


# 2.TCP的三次握手

## 2-1：TCP三次握手流程

1. 第⼀次握⼿： Client 什么都不能确认； Server 确认了对⽅发送正常，⾃⼰接收正常
2. 第⼆次握⼿： Client 确认了：⾃⼰发送、接收正常，对⽅发送、接收正常； Server 确认了：对⽅发送
正常，⾃⼰接收正常
3. 第三次握⼿： Client 确认了：⾃⼰发送、接收正常，对⽅发送、接收正常； Server 确认了：⾃⼰发
送、接收正常，对⽅发送、接收正常


## 2-2：TCP为什么要三次握⼿

1. 为了实现可靠数据传输， TCP 协议的通信双方， 都必须维护一个序列号， 以标识发送出去的数据包中， 哪些是已经被对方收到的。 
2. 如果只是两次握手， 至多只有连接发起方的起始序列号能被确认， 另一方选择的序列号则得不到确认


## 2-3：TCP为什么SYN

![avatar](http://qd6kny79g.bkt.clouddn.com/02-TCP%E9%9D%A2%E7%BB%8F.jpg)

接收端传回发送端所发送的 SYN 是为了告诉发送端，我接收到的信息确实就是你所发送的信号了。

## 2-4：TCP除了SYN，为什么还要 ACK

双⽅通信⽆误必须是两者互相发送信息都⽆误。传了 SYN，证明发送⽅到接收⽅的通道没有问题，但是
接收⽅到发送⽅的通道还需要 ACK 信号来进⾏验证。

## 2-5：如何对三次握手进行性能优化

![avatar](http://qd6kny79g.bkt.clouddn.com/08-TCP.jpg)

### 2-5-1:如何调整 SYN 半连接队列⼤⼩？

要想增⼤半连接队列， 不能只单纯增⼤tcp_max_syn_backlog的值，还需⼀同增⼤somaxconn和backlog，也就是增⼤accept队列,否则只单纯增⼤tcp_max_syn_backlog是⽆效的。
最后，改变了参数后，要重启Nginx服务，因为SYN半连接队列和accept队列都是在listen()初始化的。

### 2-5-2：如果SYN半连接队列已满，只能丢弃连接吗？

并不是这样，开启syncookies功能就可以在不使⽤SYN半连接队列的情况下成功建⽴连接。

### 2-5-3：syncookies的⼯作原理

服务器根据当前状态计算出⼀个值，放在⼰⽅发出的SYN+ACK报⽂中发出，当客户端返回ACK报⽂时，取出该值验证，如果合法，就认为连接建⽴成功

syncookies 参数主要有以下三个值：
0 值，表示关闭该功能；
1 值，表示仅当 SYN 半连接队列放不下时，再启⽤它；
2 值，表示⽆条件开启功能；
那么在应对 SYN 攻击时，只需要设置为 1 即可


## 2-6：如何绕过三次握手发送数据

TCP Fast Open 功能可以绕过三次握⼿，使得 HTTP 请求减少了1个RTT的时间， Linux下可以通过tcp_fastopen开启该功能，同时必须保证服务端和客户端同时⽀持。

第⼀次发起 HTTP GET请求的时候，还是需要正常的三次握⼿流程。

之后发起 HTTP GET请求的时候，可以绕过三次握⼿，这就减少了握⼿带来的 1 个 RTT 的时间消耗。

## 2-7：TCP Fast Open的过程

I、客户端⾸次建⽴连接时的过程：
1. 客户端发送SYN报⽂，该报⽂包含Fast Open选项，且该选项的Cookie为空，这表明客户端请求Fast Open Cookie；
2. ⽀持 TCP Fast Open 的服务器⽣成 Cookie，并将其置于 SYN-ACK 数据包中的 Fast Open 选项以发回客户端；
3. 客户端收到 SYN-ACK 后，本地缓存 Fast Open 选项中的 Cookie。


II、如果客户端再次向服务器建⽴连接时的过程：
1. 客户端发送 SYN 报⽂，该报⽂包含「数据」以及此前记录的 Cookie；
2. ⽀持 TCP Fast Open 的服务器会对收到 Cookie 进⾏校验：如果 Cookie 有效，服务器将在 SYNACK 报⽂中对 SYN 和「数据」进⾏确认，服务器随后将「数据」递送⾄相应的应⽤程序；如果Cookie ⽆效，服务器将丢弃 SYN 报⽂中包含的「数据」，且其随后发出的 SYN-ACK 报⽂将只确认 SYN 的对应序列号；
3. 如果服务器接受了 SYN 报⽂中的「数据」，服务器可在握⼿完成之前发送「数据」， 这就减少了握⼿带来的 1 个 RTT 的时间消耗；
4. 客户端将发送 ACK 确认服务器发回的 SYN 以及「数据」，但如果客户端在初始的 SYN 报⽂中发送的「数据」没有被确认，则客户端将重新发送「数据」；
5. 此后的 TCP 连接的数据传输过程和⾮ TFO 的正常情况⼀致。





# 3 四次挥手

## 3-1：TCP四次挥手流程

1. 客户端-发送⼀个FIN，⽤来关闭客户端到服务器的数据传送
2. 服务器-收到这个FIN，它发回⼀个ACK，确认序号为收到的序号加1 。和SYN⼀样，⼀个FIN将占⽤⼀个序号
3. 服务器-关闭与客户端的连接，发送⼀个FIN给客户端
4. 客户端-发回 ACK 报⽂确认，并将确认序号设置为收到序号加1

## 3-2：TCP为什么要四次挥手

任何⼀⽅都可以在数据传送结束后发出连接释放的通知，待对⽅确认后进⼊半关闭状态。当另⼀⽅也没有数据再发送的时候，则发出连接释放通知，对⽅确认后就完全关闭了TCP连接。

更多细节，请看[文章](https://blog.csdn.net/qzcsu/article/details/72861891)

## 3-3：如何对四次挥手进行优化

![avatar](http://qd6kny79g.bkt.clouddn.com/09-TCP.jpg)


## 3-4：为什么TIME_WAIT 等待的时间是 2MSL？

⽹络中可能存在来⾃发送⽅的数据包，当这些发送⽅的数据包被接收⽅处理后⼜会向对⽅发送响应，所以⼀来⼀回需要等待 2 倍的时间。

## 3-5：大量closed_waited对服务端有什么影响

导致cpu的使用率过高，可以通过netstat查看，但是我个人认为影响不是很大

## 已经主动关闭连接了为啥还要保持资源一段时间呢？

1. 防止上一次连接中的包，迷路后重新出现，影响新连接
2. 可靠的关闭TCP连接。在主动关闭方发送的最后一个ack(fin) 有可能丢失，这时被动方会重新发fin, 如果这时主动方处于 CLOSED 状态 ，就会响应 rst 而不是 ack。所以主动方要处于 TIME_WAIT 状态，而不能是 CLOSED 。另外这么设计TIME_WAIT 会定时的回收资源，并不会占用很大资源的。

## 什么命令可以查看有多少连接

待定

# 4 TCP与UDP
## 4-1：TCP与UDP区别

![avatar](http://qd6kny79g.bkt.clouddn.com/03-TCP.jpg)

1. UDP 在传送数据之前不需要先建⽴连接，TCP 提供⾯向连接的服务。在传送数据之前必须先建⽴连接，数据传送结束后要释放连接。
UDP 不提供可靠交付，但在某些情况下 UDP 确是⼀种最有效的⼯作⽅式（⼀般⽤于即时通信），
⽐如： QQ 语⾳、 QQ 视频 、直播等等

2.  UDP 确是⼀种最有效的⼯作⽅式（⼀般⽤于即时通信）,TCP⼀般⽤于⽂件传输、发送和接收邮件、远程登录等场景

## 4-2:TCP 协议如何保证可靠传输方式

1. 确认应答+序列号:TCP给发送的每⼀个包进⾏编号，接收⽅对数据包进⾏排序，把有序数据传送给应⽤层。

2. 校验和：TCP 将保持它⾸部和数据的检验和。这是⼀个端到端的检验和，⽬的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错， TCP将丢弃这个报⽂段和不确认收到此报⽂段。

3. 流量控制：TCP 连接的每⼀⽅都有固定⼤⼩的缓冲空间， TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收⽅来不及处理发送⽅的数据，能提示发送⽅降低发送的速率，防⽌包丢失。 TCP 使⽤的流量控制协议是可变⼤⼩的滑动窗⼝协议。 （TCP 利⽤滑动窗⼝实现流量控制）

4. 拥塞控制：当⽹络拥塞时，减少数据的发送。

5. ARQ协议： 也是为了实现可靠传输的，它的基本原理就是每发完⼀个分组就停⽌发送，等待对⽅
确认。在收到确认后再发下⼀个分组。

6. 超时重传： 当 TCP 发出⼀个段后，它启动⼀个定时器，等待⽬的端确认收到这个报⽂段。如果
不能及时收到⼀个确认，将重发这个报⽂段。

## 4-3：TCP传输数据的性能优化

![avatar](http://qd6kny79g.bkt.clouddn.com/10-TCP.jpg)

## 4-4：UDP如何做可靠传输

1、超时重传
2、有序接受
3、应答确认
4、滑动窗口流量控制



# 5.ARQ协议

## 5-1:什么是ARQ协议

ARQ协议是⾃动重传请求，他是OSI模型中数据链路层和传输层的错误纠正协议之⼀。它通过使⽤确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送⽅在发送后⼀段时间之内没有收到确认帧，它通常会重新发送。 ARQ包括停⽌等待ARQ协议和连续ARQ协议。

## 5-2：什么是停⽌等待ARQ协议
停⽌等待协议是为了实现可靠传输的，它的基本原理就是每发完⼀个分组就停⽌发送，等待对⽅确认（回复ACK）。如果过了⼀段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下⼀个分组；在停⽌等待协议中，若接收⽅收到重复分组，就丢弃该分组，但同时还要发送确认；

1. 优点： 简单
2. 缺点： 信道利⽤率低，等待时间⻓

## 5-3: 什么是连续ARQ协议

连续 ARQ 协议可提⾼信道利⽤率。发送⽅维持⼀个发送窗⼝，凡位于发送窗⼝内的分组可以连续发送出去，⽽不需要等待对⽅确认。接收⽅⼀般采⽤累计确认，对按序到达的最后⼀个分组发送确认，表明到这个分组为⽌的所有分组都已经正确收到了。

1. 优点： 信道利⽤率⾼，容易实现，即使确认丢失，也不必重传。
2. 缺点： 不能向发送⽅反映出接收⽅已经正确收到的所有分组的信息。 
   * ⽐如：发送⽅发送了5条消息，中间第三条丢失（3号），这时接收⽅只能对前两个发送确认。发送⽅⽆法知道后三个分组的下落，⽽只好把后三个全部重传⼀次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的N 个消息。

# 6.滑动窗⼝和流量控制

## 6-1：什么是滑动窗⼝和流量控制

流量控制是为了控制发送⽅发送速率，保证接收⽅来得及接收。 接收⽅发送的确认报⽂中的窗⼝字段可以⽤来控制发送⽅窗⼝⼤⼩，从⽽影响发送⽅的发送速率。将窗⼝字段设置为0，则发送⽅不能发送数据。

# 7. 拥塞控制

## 7-1：什么是拥塞控制

在某段时间，若对⽹络中某⼀资源的需求超过了该资源所能提供的可⽤部分，⽹络的性能就要变坏。这种情况就叫拥塞。拥塞控制就是为了防⽌过多的数据注⼊到⽹络中，这样就可以使⽹络中的路由器或链路不致过载。拥塞控制所要做的都有⼀个前提，就是⽹络能够承受现有的⽹络负荷。


## 7-2：拥塞控制算法

TCP的拥塞控制采⽤了四种算法：慢开始、拥塞避免、快重传快恢复。

1. 慢开始： 慢开始算法的思路是当主机开始发送数据时，如果⽴即把⼤量数据字节注⼊到⽹络，那么可能会引起⽹络阻塞，因为现在还不知道⽹络的符合情况。经验表明，较好的⽅法是先探测⼀下，即由⼩到⼤逐渐增⼤发送窗⼝，也就是由⼩到⼤逐渐增⼤拥塞窗⼝数值。 cwnd初始值为1，每经过⼀个传播轮次， cwnd加倍。
2. 拥塞避免： 拥塞避免算法的思路是让拥塞窗⼝cwnd缓慢增⼤，即每经过⼀个往返时间RTT就把发送放的cwnd加1.
3. 快重传与快恢复： 它能快速恢复丢失的数据包。没有 FRR，如果数据包丢失了， TCP 将会使⽤定时器来要求传输暂停。在暂停的这段时间内，没有新的或复制的数据包被发送。有了 FRR，如果接收机接收到⼀个不按顺序的数据段，它会⽴即给发送机发送⼀个重复确认。如果发送机接收到三个重复确认，它会假定确认件指出的数据段丢失了，并⽴即重传这些丢失的数据段。有了FRR，就不会因为重传时要求的暂停被耽误。 　当有单独的数据包丢失时，快速重传和恢复（FRR）能最有效地⼯作。当有多个数据信息包在某⼀段很短的时间内丢失时，它则不能很有效地⼯作。

# 8.在浏览器中输⼊url地址 

## 8.1：->> 显示主⻚的过程(⾯试常客)

1. DNS解析
2. TCP连接
3. 发送HTTP请求
4. 服务器处理请求并返回HTTP报⽂
5. 浏览器解析渲染⻚⾯
6. 连接结束

![avatar](http://qd6kny79g.bkt.clouddn.com/04-TCP.jpg)

[文章](https://segmentfault.com/a/1190000006879700)


## 8.2：->> 浏览某个网页各个协议与HTTP关系

想浏览 http://demo.jp/xss Web页面
客户端 ➡ DNS
（告诉我demo.jp的IP地址吧）

  1. HTTP协议的职责
     生成针对目标Web服务器的HTTP请求报文（请给我 http://demo.jp/xss 页面的资源）

  2. TCP协议的职责
     为了方便通信，将HTTP请求报文分割成报文段
     按序号分为多个报文段
     把每个报文段可靠的传给对方


DNS ➡ 客户端
（demo.jp对应的IP地址时20X.189.105.112）

   1. IP协议的职责（路由器）
      搜索对方的地址，一边中转一边传送

客户端 ➡ demo.jp服务器（IP地址：20X.189.105.112）

   1. TCP协议的职责
     从对方那里收到的报文段
     重组到达的报文段
     按序号以原来的顺序重组请求报文

2. HTTP协议的职责
   对Web服务器请求的内容的处理（原来时想要这台计算机上的/xss/资源啊）

## 8-3:DNS解析全过程

1. 浏览器先检查自身缓存中有没有被解析过的这个域名对应的ip地址，如果有，解析结束。同时域名被缓存的时间也可通过TTL属性来设置。

2. 如果浏览器缓存中没有，浏览器会检查操作系统缓存中有没有对应的已解析过的结果。

3.  如果至此还没有命中域名，才会真正的请求本地域名服务器（LDNS）来解析这个域名，

4. 如果LDNS仍然没有命中，就直接跳到Root Server 域名服务器请求解析

5. 根域名服务器返回给LDNS一个所查询域的主域名服务器

6. 此时LDNS再发送请求给上一步返回的gTLD

7. 接受请求的gTLD查找并返回这个域名对应的Name Server的地址，这个Name Server就是网站注册的域名服务器

8. Name Server根据映射关系表找到目标ip，返回给LDNS

9. LDNS缓存这个域名和对应的ip

10. LDNS把解析的结果返回给用户，用户根据TTL值缓存到本地系统缓存中，域名解析过程至此结束

 

# 9.状态码

![avatar](http://qd6kny79g.bkt.clouddn.com/05-TCP.jpg)


# 10.HTTP（面试超高频）

![avatar](http://qd6kny79g.bkt.clouddn.com/06-TCP.jpg)

## 10-1：什么是HTTP？

HTTP 是超⽂本传输协议，主要有三部分组成：超⽂本、传输、协议

1. 协议：确⽴了⼀种计算机之间交流通信的规范，以及相关的各种控制和错误处理⽅式
2. 传输：计算机世界⾥专⻔⽤来在两点之间传输数据的约定和规范
3. 它本身只是纯⽂字⽂件，但内部⽤很多标签定义了图⽚、视频等的链接，再经过浏览器的解释，呈现给我们的就是⼀个⽂字、有画⾯的⽹⻚了

HTTP 是⼀个在计算机世界⾥专⻔在「两点」之间「传输」⽂字、图⽚、⾳频、视频等「超⽂本」数据的「约定和规范」


## 10-2：HTTP的常用字段

1. Host字段
   客户端发送请求时，就可以将请求发往「同⼀台」服务器上的不同⽹站。

2. Content-Length 字段
   服务器在返回数据时，表明本次回应的数据⻓度。

3. Connection 字段
   最常⽤于客户端要求服务器使⽤TCP持久连接，以便其他请求复⽤。
注：HTTP/1.1 版本的默认连接都是持久连接，但为了兼容⽼版本的 HTTP，需要指定Connection⾸部字段的值为 Keep-Alive 。

4. Content-Type 字段
   ⽤于服务器回应时，告诉客户端，本次数据是什么格式。
   
   如：Content-Type: text/html; charset=utf-8，可以使⽤ Accept 字段声明⾃⼰可以接受哪些数据格式：Accept: */*
   
5. Content-Encoding
   数据的压缩⽅法。表示服务器返回的数据使⽤了什么压缩格式

## 10-3：get与post的区别

1. Get ⽅法的含义是请求从服务器获取资源，这个资源可以是静态的⽂本、⻚⾯、图⽚视频等。
   
   * ⽐如，你打开网页，浏览器就会发送 GET 请求给服务器，服务器就会返回⽂章的所有⽂字及资源。

2. POST ⽅法则是相反操作，它向 URI 指定的资源提交数据，数据就放在报⽂的body⾥。

   * 你在我⽂章底部，敲⼊了留⾔后点击「提交」，浏览器就会执⾏⼀次 POST 请求，把你的留⾔⽂字放进了报⽂ body ⾥，然后拼接好 POST 请求头，通过 TCP 协议发送给服务器。

### 10-3-1：安全和幂等

1. 在 HTTP 协议⾥，所谓的「安全」是指请求⽅法不会「破坏」服务器上的资源。
2. 所谓的「幂等」，意思是多次执⾏相同的操作，结果都是「相同」的。

### 10-3-2：get、post安全和幂等呢？

1. GET ⽅法就是安全且幂等的
   * 因为它是「只读」操作，⽆论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。

2. POST 不是安全且幂等的
   * 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。

## 10-4：HTTP1.1优缺点

<font color=red size='5'>I.优点</font>

1. 简单
HTTP 基本的报⽂格式就是 header + body ，头部信息也是 key-value 简单⽂本的形式， 易于理解，降低了学习和使⽤的⻔槛。

2. 灵活和易于扩展
HTTP协议⾥的各类请求⽅法、 URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发⼈员⾃定义和扩充。
同时 HTTP 由于是⼯作在应⽤层，则它下层可以随意变化。

3. 应⽤⼴泛和跨平台

<font color=red size='5'>II.缺点</font>

HTTP 协议⾥有优缺点⼀体的双刃剑，分别是「⽆状态、明⽂传输」，同时还有⼀⼤缺点「不安全」。

1. ⽆状态
因为服务器不会去记忆HTTP的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的CPU和内存⽤来对外提供服务。
但是⽆状态，它在完成有关联性的操作时会⾮常麻烦。例如登录->添加购物⻋->下单->结算->⽀付，这系列操作都要知道⽤户的身份才⾏。但服务器不知道这些请求是有关联的，每次都要问⼀遍身份信息。

注：对于⽆状态的问题，解法⽅案有很多种，其中⽐较简单的⽅式⽤ Cookie 技术。Cookie 通过在请求和响应报⽂中写⼊ Cookie 信息来控制客户端的状态。相当于， 在客户端第⼀次请求后，服务器会下发⼀个装有客户信息的「⼩贴纸」，后续客户端请求服务器的时候，带上「⼩贴纸」，服务器就能认得了

2. 明⽂传输

明⽂意味着在传输过程中的信息，是可⽅便阅读的，通过浏览器的控制台或抓包软件都可以直接⾁眼查看，为我们调试⼯作带了极⼤的便利性。但是这正是这样， HTTP 的所有信息都暴露在了光天化⽇下，相当于信息裸奔。在传输的漫⻓的过程中，信息的内容都毫⽆隐私可⾔，很容易就能被窃取。

3. 不安全
HTTP ⽐较严重的缺点就是不安全：

注：HTTP 的安全问题，可以⽤HTTPS的⽅式解决，也就是通过引⼊SSL/TLS 层。


## 10-5：HTTP/1.1 的性能如何？

一般来说， HTTP/1.1 的性能⼀般般，后续的 HTTP/2和HTTP/3就是在优化HTTP的性能。

1. ⻓连接，早期 HTTP/1.0，那就是每发起⼀个请求需要三次握手四次挥手等等操作，增加了通信开销。为了解决这些问题， HTTP/1.1 提出了⻓连接的通信⽅式，这种⽅式的好处在于减少了 TCP 连接的重复建⽴和断开所造成的额外开销，减轻了服务器端的负载。持久连接的特点是，只要任意⼀端没有明确提出断开连接，则保持 TCP 连接状态。
   
2. 管道⽹络传输
HTTP/1.1 采⽤了⻓连接的⽅式，可在同⼀个 TCP 连接⾥⾯，客户端可以发起多个请求，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以减少整体的响应时间。
* 举例来说，客户端需要请求两个资源。以前的做法是，在同⼀个TCP连接⾥⾯，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。
* 管道机制则是允许浏览器同时发出 A 请求和 B 请求。
  
3. 队头阻塞
由于服务器还是按照顺序，先回应A请求，完成后再回应B请求。要是前⾯的回应特别慢，后⾯就会有许多请求排队等着

## 10-6：HTTP 与 HTTPS区别

1. HTTP 是超⽂本传输协议，信息是明⽂传输，存在安全⻛险的问题。 HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP ⽹络层之间加⼊了 SSL/TLS 安全协议，使得报⽂能够加密传输。

2. HTTP 连接建⽴相对简单，TCP 三次握⼿之后便可进⾏HTTP的报⽂传输。⽽ HTTPS 在 TCP 三次握⼿之后，还需进⾏SSL/TLS的握⼿过程，才可进⼊加密报⽂传输。

3. HTTP 的端⼝号是 80， HTTPS 的端⼝号是 443。

4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

## 10-7：HTTPS 解决了 HTTP 的哪些问题？

HTTP 由于是明⽂传输，所以安全上存在以下三个⻛险：

1. 窃听⻛险，⽐如通信链路上可以获取通信内容，⽤户号容易没。

2. 篡改⻛险，⽐如强制植⼊垃圾⼴告，视觉污染，⽤户眼容易瞎。

3. 冒充⻛险，⽐如冒充淘宝⽹站，⽤户钱容易没。

HTTPS 在 HTTP 与 TCP 层之间加⼊了 SSL/TLS 协议，可以很好的解决了上述的⻛险：

1. 混合加密的⽅式实现信息的机密性，解决了窃听的⻛险。

2. 摘要算法的⽅式来实现完整性，它能够为数据⽣成独⼀⽆⼆的「指纹」，指纹⽤于校验数据的完整性，解决了篡改的⻛险。

3. 将服务器公钥放⼊到数字证书中，解决了冒充的⻛险。

不完全


## 10-8：HTTPS 是如何建⽴连接的？其间交互了什么？

1. 客户端向服务器索要并验证服务器的公钥。
2. 双⽅协商⽣产「会话秘钥」。
3. 双⽅采⽤「会话秘钥」进⾏加密通信。


## 10-9：SSL/TLS握⼿

1. ClientHello

⾸先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。在这⼀步，客户端主要向服务器发送以下信息：

（1）客户端⽀持的 SSL/TLS 协议版本，如 TLS 1.2 版本。

（2）客户端⽣产的随机数（ Client Random ），后⾯⽤于⽣产「会话秘钥」。

（3）客户端⽀持的密码套件列表，如 RSA 加密算法。

2. SeverHello

服务器收到客户端请求后，向客户端发出响应，也就是 SeverHello 。服务器回应的内容有如下内容：

（1）确认 SSL/ TLS 协议版本，如果浏览器不⽀持，则关闭加密通信。

（2）服务器⽣产的随机数（ Server Random ），后⾯⽤于⽣产「会话秘钥」。

（3）确认的密码套件列表，如 RSA 加密算法。（4）服务器的数字证书。

3. 客户端回应

客户端收到服务器的回应之后，⾸先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。

如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使⽤它加密报⽂，向服务器发送如下信息：

（1）⼀个随机数（ pre-master key ）。该随机数会被服务器公钥加密。
（2）加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。
（3）客户端握⼿结束通知，表示客户端的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘要，⽤来供服务端校验。

上⾯第⼀项的随机数是整个握⼿阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就⽤双⽅协商的加密算法， 各⾃⽣成本次通信的「会话秘钥」。

4. 服务器的最后回应

服务器收到客户端的第三个随机数（ pre-master key ）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。然后，向客户端发⽣最后的信息：

（1）加密通信算法改变通知，表示随后的信息都将⽤「会话秘钥」加密通信。

（2）服务器握⼿结束通知，表示服务器的握⼿阶段已经结束。这⼀项同时把之前所有内容的发⽣的数据做个摘要，⽤来供客户端校验。


## 10-10：说说 HTTP/1.1 相⽐ HTTP/1.0 提⾼了什么性能？

1. 使⽤ TCP ⻓连接的⽅式改善了 HTTP/1.0 短连接造成的性能开销。
2. ⽀持管道（pipeline）⽹络传输，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以减少整体的响应时间。但 HTTP/1.1 还是

## 10-11：HTTP1.1缺点
1. 请求 / 响应头部（Header）未经压缩就发送，⾸部信息越多延迟越⼤。只能压缩 Body 的部分；发送冗⻓的⾸部。每次互相发送相同的⾸部造成的浪费较多；
2. 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端⼀直请求不到数据，也就是队头阻塞；
3. 没有请求优先级控制；
4. 请求只能从客户端开始，服务器只能被动响应。

## 10-12：HTTP/2 做了什么优化？

1. 头部压缩
HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是⼀样的或是相似的，那么，协议会帮你消除重复的部分。
* 这就是所谓的 HPACK 算法：在客户端和服务器同时维护⼀张头信息表，所有字段都会存⼊这个表，⽣成⼀个索引号，以后就不发送同样字段了，只发送索引号，这样就提⾼速度了。

2. ⼆进制格式
HTTP/2 全⾯采⽤了⼆进制格式，头信息和数据体都是⼆进制，计算机收到报⽂后，⽆需再将明⽂的报⽂转成⼆进制，⽽是直接解析⼆进制报⽂，这增加了数据传输的效率。

3. 数据流
HTTP/2 的数据包不是按顺序发送的，同⼀个连接⾥⾯连续的数据包，可能属于不同的回应。

4. 多路复⽤
HTTP/2 是可以在⼀个连接中并发多个请求或回应，⽽不⽤按照顺序⼀⼀对应。


5. 服务器推送
HTTP/2 还在⼀定程度上改善了传统的「请求 - 应答」⼯作模式，服务不再是被动地响应，也可以主动向客户端发送消息。


## 10-13:HTTP/2 有哪些缺陷？ 

多个 HTTP 请求在复⽤⼀个 TCP 连接，下层的 TCP 协议是不知道有多少个HTTP请求的。所以⼀旦发⽣了丢包现象，就会触发 TCP 的重传机制，这样在⼀个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。

## 10-14:HTTP/3 做了哪些优化？

HTTP/3 把HTTP下层的TCP协议改成了UDP

因为UDP 发⽣是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1的队头阻塞 和HTTP/2的⼀个丢包全部重传问题。

但是由于UDP是不可靠传输的，而基于UDP的QUIC协议可以实现类似TCP的可靠性传输。

## 10-15：QUIC

QUIC是⼀个在UDP之上的伪TCP+TLS+HTTP/2的多路复⽤的协议。

1. 当某个流发⽣丢包时，只会阻塞这个流， 其他流不会受到影响。
2. 更改了头部压缩算法，升级成了 QPack 。
3. QUIC 直接把以往的TCP和TLS/1.3的6次交互合并成了3次，减少了交互次数。

## 10-16：HTTP⻓连接,短连接(也是TCP连接,短连接)

1. 在HTTP/1.0中默认使⽤短连接。也就是说，客户端和服务器每进⾏⼀次HTTP操作，就建⽴⼀次连接，任
务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web⻚中包含有其他的Web资源（如
JavaScript⽂件、图像⽂件、 CSS⽂件等），每遇到这样⼀个Web资源，浏览器就会重新建⽴⼀个HTTP会
话。
2. 从HTTP/1.1起，默认使⽤⻓连接，⽤以保持连接特性。客户端和服务器之间⽤于传输HTTP数据的TCP连接不
会关闭，客户端再次访问这个服务器时，会继续使⽤这⼀条已经建⽴的连接

## 10-117：HTTP是不保存状态的协议,如何保存⽤户状态?

通过Session机制解决，Session的主要作⽤就是通过服务端记录⽤户的状态。
   * 如应用场景购物⻋，当你要添加商品到购物⻋的时候，系统不知道是哪个⽤户操作的，因为HTTP协议是⽆状态的。服务端给特定的⽤户创建特定Session之后就可以标识这个⽤户并且跟踪这个⽤户了（⼀般情况下，服务器会在⼀定时间内保存这个Session，过了时间限制，就会销毁这个Session）

### 10-17—1：如何保存session

在服务端保存Session的⽅法很多，最常⽤的就是内存和数据库(⽐如是使⽤内存数据库redis保存)。

### 10-17-2:如何实现 Session 跟踪呢？

⼤部分情况下，我们都是通过在Cookie 中附加⼀个 Session ID 来⽅式来跟踪。

### 10-17-3:Cookie 被禁⽤怎么办?
最常⽤的就是利⽤ URL 重写把 Session ID 直接附加在URL路径的后⾯。

## 10-18:Cookie的作⽤是什么?(与session区别)

1. Cookie ⼀般⽤来保存⽤户信息 
2. Cookie 数据保存在客户端(浏览器端)， Session 数据保存在服务器端。
3. Cookie 存储在客户端中，⽽Session存储在服务器上，相对来说 Session 安全性更⾼。如果要在
4. Cookie 中存储⼀些敏感信息，不要直接写⼊ Cookie 中，最好能将 Cookie 信息加密然后使⽤到的时候再去服务器端解密。

## 10-19：HTTP 1.0和HTTP 1.1的主要区别是什么

[HTTP一些细节](https://mp.weixin.qq.com/s/GICbiyJpINrHZ41u_4zT-A?)

1. ⻓连接 : 在HTTP/1.0中，默认使⽤的是短连接，也就是说每次请求都要重新建⽴⼀次连接。如果每次请求都要这样的话，开销会⽐较⼤。
            HTTP 1.1起，默认使⽤⻓连接 ,

2. 错误状态响应码 :在HTTP1.1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发⽣冲突；410（Gone）表示服务器上的某个资源被永久性的删除。

3. 缓存处理 :在HTTP1.0中主要使⽤header⾥的If-Modified-Since,Expires来做为缓存判断的标准， 
            HTTP1.1则引⼊了更多的缓存控制策略例如Entity tag， If-Unmodified-Since, If-Match,If-None-Match等更多可供选择的缓存头来控制缓存策略。

1. 带宽优化及⽹络连接的使⽤ :HTTP1.0中，存在⼀些浪费带宽的现象，例如客户端只是需要某个对象的⼀部分，⽽服务器却将整个对象送过来了，并且不 ⽀持断点续传功能， HTTP1.1则在请求头引⼊了range头域，它允许只请求资源的某个部分，即返回码是206（Partial Content），这样就⽅便了开发者⾃由的选择以便于充分利⽤带宽和连接。

## 10-20:URI和URL的区别是什么?

URI的作⽤像身份证号⼀样， URL的作⽤更像家庭住址⼀样。

## 10-21:HTTP 和 HTTPS 的区别？
1. 端⼝ ： HTTP的URL由“http://”起始且默认使⽤端⼝80，⽽HTTPS的URL由“https://”起始且默认使⽤端⼝443。
2. 安全性和资源消耗： HTTP协议运⾏在TCP之上，所有传输的内容都是明⽂，客户端和服务器端都⽆法验证对⽅的身份。 HTTPS是运⾏在SSL/TLS之上的HTTP协议， SSL/TLS 运⾏在TCP之上。所有传输的内容都经过加密，加密采⽤对称加密，但对称加密的密钥⽤服务器⽅的证书进⾏了⾮对称加密。所以说， HTTP安全性没有HTTPS⾼，但是 HTTPS ⽐HTTP耗费更多服务器资源。

## 10-22：HTTPS的加密过程

1. 用户在浏览器发起HTTPS请求（如 https://www.mogu.com/），默认使用服务端的443端口进行连接；
2. HTTPS需要使用一套CA数字证书，证书内会附带一个公钥Pub，而与之对应的私钥Private保留在服务端不公开；
3. 服务端收到请求，返回配置好的包含公钥Pub的证书给客户端；
4. 客户端收到证书，校验合法性，主要包括是否在有效期内、证书的域名与请求的域名是否匹配，上一级证书是否有效（递归判断，直到判断到系统内置或浏览器配置好的根证书），如果不通过，则显示HTTPS警告信息，如果通过则继续；
5. 客户端生成一个用于对称加密的随机Key，并用证书内的公钥Pub进行加密，发送给服务端；
6. 服务端收到随机Key的密文，使用与公钥Pub配对的私钥Private进行解密，得到客户端真正想发送的随机Key；
7. 服务端使用客户端发送过来的随机Key对要传输的HTTP数据进行对称加密，将密文返回客户端；
8. 客户端使用随机Key对称解密密文，得到HTTP数据明文；
9. 后续HTTPS请求使用之前交换好的随机Key进行对称加解密。

## 10-23:加密
1. 对称加密：密钥只有⼀个，加密解密为同⼀个密码，且加解密速度快，典型的对称加密，算法有DES、 AES等；
2. ⾮对称加密：密钥成对出现（且根据公钥⽆法推知私钥，根据私钥也⽆法推知公钥），加密解密使⽤不同密钥（公钥加密需要私钥解密，私钥加密需要公钥解密），相对对称加密速度较慢，典型的⾮对称加密算法有RSA、 DSA等。


### 暂定

1) ⽆差错情况:
   
发送⽅发送分组,接收⽅在规定时间内收到,并且回复确认.发送⽅再次发送。

1) 出现差错情况（超时重传） :

停⽌等待协议中超时重传是指只要超过⼀段时间仍然没有收到确认，就重传前⾯发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完⼀个分组需要设置⼀个超时计时器，其重传时间应⽐数据在分组传输的平均往返时间更⻓⼀些。这种⾃动重传⽅式常称为 ⾃动重传请求 ARQ 。另外在停⽌等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。 连续 ARQ 协议 可提⾼信道利⽤率。发送维持⼀个发送窗⼝，凡位于发送窗⼝内的分组可连续发送出去，⽽不需要等待对⽅确认。接收⽅⼀般采⽤累积确认，对按序到达的最后⼀个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。

3) 确认丢失和确认迟到

确认丢失 ：确认消息在传输过程丢失。当A发送M1消息， B收到后， B向A发送了⼀个M1确认消息，但却在传输过程中丢失。⽽A并不知道，在超时计时过后， A重传M1消息， B再次收到该消息后采取以下两点措施： 1. 丢弃这个重复的M1消息，不向上层交付。 2. 向A发送确认消息。（不会认为已经发送过了，就不再发送。 A能重传，就证明B的确认消息丢失）。确认迟到 ：确认消息在传输过程中迟到。 A发送M1消息， B收到并发送确认。在超时时间内没有
收到确认消息， A重传M1消息， B仍然收到并继续发送确认消息（B收到了2份M1）。此时A收到了B第⼆次发送的确认消息。接着发送其他数据。过了⼀会， A收到了B第⼀次发送的对M1的确认消息（A也收到了2份确认消息）。处理如下： 1. A收到重复的确认后，直接丢弃。 2. B收到重复的M1
后，也直接丢弃重复的M1。




# 11.IP

![avatar](http://qd6kny79g.bkt.clouddn.com/07-TCP.jpg)

## 11-1：⼴播地址⽤于什么？

⼴播地址⽤于在同⼀个链路中相互连接的主机之间发送数据包。

学校班级中就有⼴播的例⼦，在准备上课的时候，通常班⻓会喊： “上课， 全体起⽴！ ”，班⾥的同学听到这句话是不是全部都站起来了？这个句话就有⼴播的含义。

我认为就是我接受到了这个信息，上课之前要站起来

## 11-2:IP分类的优缺点

IP分类的优点

简单明了、选路（基于⽹络地址）简单。

IP分类的缺点

缺点⼀：
同⼀⽹络下没有地址层次，缺少地址的灵活性。
缺点⼆：
不能很好的与现实⽹络匹配。如C类地址主机数量太少，B类主机数量太多等等

## 11-3：如何解决IP分类存在的问题

为了解决IP分类存在许多缺点，提出了⽆分类地址的⽅案，即CIDR 。
这种⽅式不再有分类地址的概念， 32⽐特的IP地址被划分为两部分，前⾯是⽹络号，后⾯是主机号。

## 11-4：为什么要分离⽹络号和主机号？

1. 因为两台计算机要通讯，⾸先要判断是否处于同⼀个⼴播域内，即⽹络地址是否相同。如果⽹络地址相同，表明接受⽅在本⽹络上，那么可以把数据包直接发送到⽬标主机。
 
怎么进⾏⼦⽹划分？
在上⾯我们知道可以通过⼦⽹掩码划分出⽹络号和主机号，那实际上⼦⽹掩码还有⼀个作⽤，那就是划
分⼦⽹。
⼦⽹划分实际上是将主机地址分为两个部分：⼦⽹⽹络地址和⼦⽹主机地址。形式如下：未做⼦⽹划分的 ip 地址：⽹络地址＋主机地址
做⼦⽹划分后的 ip 地址：⽹络地址＋（⼦⽹⽹络地址＋⼦⽹主机地址）
假设对 C 类地址进⾏⼦⽹划分，⽹络地址 192.168.1.0，使⽤⼦⽹掩码 255.255.255.192 对其进⾏⼦⽹
划分。
C 类地址中前 24 位是⽹络号，最后 8 位是主机号，根据⼦⽹掩码可知从 8 位主机号中借⽤ 2 位作为⼦
⽹号。
由于⼦⽹⽹络地址被划分成 2 位，那么⼦⽹地址就有 4 个，分别是 00、 01、 10、 11，具体划分如下
图：划分后的 4 个⼦⽹如下表格：
公有 IP 地址与私有 IP 地址
在 A、 B、 C 分类地址，实际上有分公有 IP 地址和私有 IP 地址。



## 解释一下ip地址 子网掩码与网关
























