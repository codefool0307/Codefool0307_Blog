# 1.缓存---概念

缓存，就是数据交换的缓冲区
目的是，把读写速度【慢】的介质的数据保存在读写速度【快】的介质中，
从而提高读写速度，减少时间消耗

比如说磁盘缓存：磁盘缓存其实就把常用的磁盘数据保存在内存中，
内存读写速度也是远高于磁盘的。
读数据，时从内存读取。
写数据时，可先写到内存，定时或定量回写到磁盘，或者是同步回写。

## 1-4：为什么要有分布式缓存?/为什么不直接用本地缓存?

其实分布式缓存类似于一种内存数据库的服务，
它的最终作用就是提供缓存数据的服务。
本地的缓存的优势是低依赖，
比较轻量并且通常相比于使用分布式缓存要更加简单。
本地缓存对分布式架构支持不友好，
比如同一个相同的服务部署在多台机器上的时候，
各个服务之间的缓存是无法共享的，
因为本地缓存只在当前机器上有。
本地缓存容量受服务部署所在的机器限制明显。
如果当前系统服务所耗费的内存多，
那么本地缓存可用的容量就很少。
使用分布式缓存之后，
缓存部署在一台单独的服务器上，
即使同一个相同的服务部署在再多机器上，
也是使用的同一份缓存。 
并且，单独的分布式缓存服务的性能、
容量和提供的功能都要更强。
使用分布式缓存的缺点呢，
也很显而易见，
那就是你需要为分布式缓存引入额外的服务
比如Redis或Memcached，
你需要单独保证 Redis 或 Memcached 服务的高可用。


# 缓存---原因

1. 提升读写性能
2. 减小 MySQL 的读取压力

# 缓存---缓存算法

1. LRU（least recently used ，最近最少使用)
2. LFU（Least Frequently used ，最不经常使用)
3. FIFO（first in first out ，先进先出)

## -1:手写LRU算法

![https://leetcode-cn.com/problems/lru-cache/solution/lruhuan-cun-ji-zhi-by-leetcode-solution/]

1. 用一个数组来存储数据，给每一个数据项标记一个访问时间戳，
   每次插入新数据项的时候，
   先把数组中存在的数据项的时间戳自增，
   并将新数据项的时间戳置为0并插入到数组中。
   每次访问数组中的数据项的时候，
   将被访问的数据项的时间戳置为0。
   当数组空间已满时，
   将时间戳最大的数据项淘汰。
2. 利用一个链表来实现，
   每次新插入数据的时候将新数据插到链表的头部；
   每次缓存命中（即数据被访问），
   则将数据移到链表头部；
   那么当链表满的时候，
   就将链表尾部的数据丢弃。
3. 利用链表和hashmap。
   当需要插入新的数据项的时候，
   如果新数据项在链表中存在（一般称为命中），
   则把该节点移到链表头部，
   如果不存在，则新建一个节点，
   放到链表头部，若缓存满了，
   则把链表最后一个节点删除即可。
   在访问数据的时候，
   如果数据项在链表中存在，
   则把该节点移到链表头部，
   否则返回-1。
   这样一来在链表尾部的节点就是
   最近最久未访问的数据项。

#### 5-4-1-2：LRU手写

```java
public class LRULinkedHashMap<K, V> extends LinkedHashMap<K, V> {  
    private final int maxCapacity;  
    private static final float DEFAULT_LOAD_FACTOR = 0.75f;  
    private final Lock lock = new ReentrantLock();  
    public LRULinkedHashMap(int maxCapacity) {  
        super(maxCapacity, DEFAULT_LOAD_FACTOR, true);  
        this.maxCapacity = maxCapacity;  }  
    @Override 
    protected boolean removeEldestEntry(java.util.Map.Entry<K, V> eldest) {  
        return size() > maxCapacity;  
    }  
    @Override 
    public boolean containsKey(Object key) {  
        try {  
            lock.lock();  
            return super.containsKey(key);  
        } finally {  
            lock.unlock();  }  }  
    @Override 
    public V get(Object key) {  
        try {  
            lock.lock();  
            return super.get(key);  
        } finally {  
            lock.unlock();  }  }  
    @Override 
    public V put(K key, V value) {  
        try {  
            lock.lock();  
            return super.put(key, value);  
        } finally {  
            lock.unlock();  }  }  
    public int size() {  
        try {  
            lock.lock();  
            return super.size();  
        } finally {  
            lock.unlock();  }  }  
    public void clear() {  
        try {  
            lock.lock();  
            super.clear();  
        } finally {  
            lock.unlock();  }  }  
    public Collection<Map.Entry<K, V>> getAll() {  
        try {  
            lock.lock();  
            return new ArrayList<Map.Entry<K, V>>(super.entrySet());  
        } finally {  
            lock.unlock();  }  }  }  
```

# 缓存---常见问题

写入问题
   缓存何时写入？并且写时如何避免并发重复写入？
   缓存如何失效？
   缓存和 DB 的一致性如何保证？

如何避免缓存穿透的问题？
如何避免缓存击穿的问题？
如果避免缓存雪崩的问题？

## 8-1：缓存穿透

解释 1：缓存查询一个没有的 key，同时数据库也没有，
       如果黑客大量的使用这种方式，那么就会导致 DB 宕机。

解决方案：我们可以使用一个默认值来防止，
         例如，当访问一个不存在的 key，然后再去访问数据库，
         还是没有，那么就在缓存里放一个占位符，下次来的时候，
         检查这个占位符，如果发生时占位符，就不去数据库查询了，防止 DB 宕机。

解释 2：大量请求查询一个刚刚失效的 key，
       导致 DB 压力倍增，可能导致宕机，
       但实际上，查询的都是相同的数据。

解决方案：可以在这些请求代码加上双重检查锁。
         但是那个阶段的请求会变慢。不过总比 DB 宕机好。

### 8-1-2：缓存穿透的解决方案

1. 缓存空对象。
   当从 DB 查询数据为空，我们仍然将这个空结果进行缓存，
   具体的值需要使用特殊的标识，能和真正缓存的数据区分开。
   还有是需要设置较短的过期时间，不然会浪费内存

2. 布隆过滤器。
   在缓存服务的基础上，构建 BloomFilter 数据结构，
   在 BloomFilter 中存储对应的 KEY 是否存在，
   如果存在，说明该 KEY 对应的值不为空。
      1、根据 KEY 查询【BloomFilter 缓存】。
         如果不存在对应的值，直接返回；
         如果存在，继续向下执行。
      2、根据 KEY 查询在【数据缓存】的值。如果存在值，直接返回；如果不存在值，继续向下执行。
      3、查询 DB 对应的值，如果存在，则更新到缓存，并返回该值。

### 8-1-3:为什么 BloomFilter 不存储 KEY 是不存在的情况

1. BloomFilter 存在误判，可能会导致一个存在的key被误判成为不存在
2. BloomFilter 不允许删除。例如说，一个 KEY 一开始是不存在的，后来数据新增了，
   但是 BloomFilter 不允许删除的特点，就会导致一直会被判断成不存在。

### -1-4:两种方案的优缺点

	          缓存空对象	                 BloomFilter 布隆过滤器
适用场景	   1、数据命中不高                    1、数据命中不高
            2、保证一致性	              2、数据相对固定、实时性低

维护成本	    1、代码维护简单                    1、代码维护复杂
          2、需要过多的缓存空间                2、缓存空间占用小
              3、数据不一致	

## 8-2：缓存雪崩

### 8-2-1：什么是缓存雪崩

指缓存由于某些原因无法提供服务( 例如，缓存挂掉了 )，
所有请求全部达到 DB 中，导致 DB 负荷大增，最终挂掉的情况。
或者说秒杀活动，开始 12 个小时之前，
我们统一存放了一批商品到 Redis 中，
设置的缓存过期时间也是 12 个小时，
那么秒杀开始的时候，
这些秒杀的商品的访问直接就失效了。
导致的情况就是，相应的请求直接就落到了数据库上，
就像雪崩一样可怕。

### 8-2-2：有哪些解决办法？

1）缓存高可用
  通过搭建缓存的高可用，避免缓存挂掉导致无法提供服务的情况，从而降低出现缓存雪崩的情况。
  假设我们使用 Redis 作为缓存，则可以使用 Redis Sentinel 或 Redis Cluster 实现高可用。
2）本地缓存
   如果使用本地缓存时，即使分布式缓存挂了，也可以将 DB 查询到的结果缓存到本地，避免后续请求全部到达 DB 中。
3）请求 DB 限流
   通过限制 DB 的每秒请求数，避免把 DB 也打挂了。这样
       可能有一部分用户，还可以使用，系统还没死透。
        未来缓存服务恢复后，系统立即就已经恢复，无需再处理 DB 也挂掉的情况。

### -2-3:本地缓存实时性如何保证？

方案一，可以引入消息队列。在数据更新时，发布数据更新的消息；而进程中有相应的消费者消费该消息，从而更新本地缓存。
方案二，设置较短的过期时间，请求时从 DB 重新拉取。

## 8-3：缓存击穿

对于一些设置了过期时间的key，
如果这些key可能会在某些时间点被超高并发地访问，
是一种非常“热点”的数据。
缓存在某个时间点过期的时候，
恰好在这个时间点对这个Key有大量的并发请求过来，
这些请求发现缓存过期一般都会从后端DB加载数据并回射到缓存，
这个时候大并发的请求可能会瞬间把后端DB压垮。

### 8-3-2：缓存击穿的解决方案

1. 使用互斥锁(mutex key)
   请求发现缓存不存在后，去查询 DB 前，使用分布式锁，
   保证有且只有一个线程去查询 DB ，并更新到缓存。
   首先
   1、获取分布式锁，直到成功或超时。如果超时，则抛出异常，返回。
      如果成功，继续向下执行。
   2、获取缓存。如果存在值，则直接返回；如果不存在，则继续往下执行。
      因为，获得到锁，可能已经被“那个”线程去查询过 DB ，并更新到缓存中了。
   3、查询 DB ，并更新到缓存中，返回值。
```java
public String get(key) {
      String value = redis.get(key);
      if (value == null) { //代表缓存值过期
          //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db
          if (redis.setnx(key_mutex, 1, 3 * 60) == 1) {  //代表设置成功
               value = db.get(key);
                      redis.set(key, value, expire_secs);
                      redis.del(key_mutex);
              } else {  //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可
                      sleep(50);
                      get(key);  //重试
              }
          } else {
              return value;}}
```
2. 手动过期。
   缓存上从不设置过期时间，功能上将过期时间存在 KEY 对应的 VALUE 里。流程如下：
   1、获取缓存。通过 VALUE 的过期时间，判断是否过期。
      如果未过期，则直接返回；如果已过期，继续往下执行。
   2、通过一个后台的异步线程进行缓存的构建，也就是“手动”过期。
      通过后台的异步线程，保证有且只有一个线程去查询 DB。
   3、同时，虽然 VALUE 已经过期，还是直接返回。通过这样的方式，
      保证服务的可用性，虽然损失了一定的时效性。

### 8-3-3：几种方案优缺点

             使用互斥锁	               手动过期
优点	       1、思路简单        1、性价最佳，用户无需等待
            2、保证一致性	

缺点	     1、代码复杂度增大      1、无法保证缓存一致性
           2、存在死锁的风险	

## 8-4：什么是缓存并发竞争？怎么解决？

解释：多个客户端写一个 key，如果顺序错了，
      数据就不对了。但是顺序我们无法控制。

解决方案：使用分布式锁，例如 zk，
         同时加入数据的时间戳。同一时刻，
         只有抢到锁的客户端才能写入，同时，写入时，
         比较当前数据的时间戳和缓存中数据的时间戳。

# 缓存---与DB一致性

## -1:产生原因

1. 并发的场景下，导致读取老的 DB 数据，更新到缓存中。
   主要是更新 DB 数据之前，先删除 Cache 的数据。
   在低并发量下没什么问题，但是在高并发下，就会存在问题。
   在(删除 Cache 的数据, 和更新 DB 数据)时间之间，恰好有一个请求，
   我们如果使用被动读，因为此时 DB 数据还是老的，
   又会将老的数据写入到 Cache 中。

2. 缓存和 DB 的操作，不在一个事务中，可能只有一个 DB 操作成功，
   而另一个 Cache 操作失败，导致不一致。

## -2:解决方案

通常，更新缓存和数据库有几种顺序：
1. 先更新数据库，再更新缓存。
2. 先删缓存，再更新数据库。
3. 先更新数据库，再删除缓存。
那么
`先更新数据库，再更新缓存。`
这么做的问题是：当有 2 个请求同时更新数据，
那么如果不使用分布式锁，
将无法控制最后缓存的值到底是多少。
也就是并发写的时候有问题。
`先删缓存，再更新数据库。`
这么做的问题：如果在删除缓存后，
有客户端读数据，将可能读到旧数据，
并有可能设置到缓存中，导致缓存中的数据一直是老数据。
\\有 2 种解决方案：\\
   1. 使用“双删”，即删更删，最后一步的删除作为异步操作，
      就是防止有客户端读取的时候设置了旧值。
   2. 使用队列，当这个 key 不存在时，
      将其放入队列，串行执行，
      必须等到更新数据库完毕才能读取数据。
`先更新数据库，再删除缓存`
如果先更新数据库，再删除缓存，
那么就会出现更新数据库之前有瞬间数据不是很及时。
同时，如果在更新之前，缓存刚好失效了，
读客户端有可能读到旧值，
然后在写客户端删除结束后再次设置了旧值，非常巧合的情况。
有 2 个前提条件：缓存在写之前的时候失效，
同时，在写客户度删除操作结束后，
放置旧数据 —— 也就是读比写慢。设置有的写操作还会锁表。
如果出现了就可以使用双删
记录更新期间有没有客户端读数据库，
如果有，在更新完数据库之后，执行延迟删除。
还有一种可能，如果执行更新数据库，准备执行删除缓存时，
服务挂了，执行删除失败
可以通过订阅数据库的 binlog 来删除。

# 缓存---缓存预热

在刚启动的缓存系统中，如果缓存中没有任何数据，
如果依靠用户请求的方式重建缓存数据，那么对数据库的压力非常大，
而且系统的性能开销也是巨大的。

此时，最好的策略是启动时就把热点数据加载好。
这样，用户请求时，直接读取的就是缓存的数据，
而无需去读取 DB 重建缓存数据。

举个例子，热门的或者推荐的商品，需要提前预热到缓存中。

## -1:如何实现

1. 数据量不大时，项目启动时，自动进行初始化。
2. 写个修复数据脚本，手动执行该脚本。
3. 写个管理界面，可以手动点击，预热对应的数据到缓存中。

# 缓存---淘汰策略

1. 定时去清理过期的缓存。
2. 当有用户请求过来时，再判断这个请求所用到的缓存是否过期，过期的话就去底层系统得到新数据并更新缓存。


# 2.Redis---概念

是一个基于内存的高性能 Key-Value 数据库。

## 2-1：为什么要⽤ redis/为什么要⽤缓存

1. 高性能方面，假如⽤户第⼀次访问数据库中的某些数据。
   这个过程会⽐较慢，因为是从硬盘上读取的。
   将该⽤户访问的数据存在缓存中，
   这样下⼀次再访问这些数据的时候
   就可以直接从缓存中获取了。
   操作缓存就是直接操作内存，
   所以速度相当快。
   如果数据库中的对应数据改变的之后，
   同步改变缓存中相应的数据即可！
2. ⾼并发：直接操作缓存能够承受的请求
   是远远⼤于直接访问数据库的，
   所以我们可以考虑把数据库中的
   部分数据转移到缓存中去，
   这样⽤户的⼀部分请求会
   直接到缓存这⾥⽽不⽤经过数据库。

## 2-2：为什么要⽤ redis ⽽不⽤ map/guava 做缓存

缓存分为本地缓存和分布式缓存。
以 Java 为例，使⽤⾃带的 map 或者 guava 实现的是本地缓存，
最主要的特点是轻量以及快速，
⽣命周期随着 jvm 的销毁⽽结束，
并且在多实例的情况下，
每个实例都需要各⾃保存⼀份缓存，
缓存不具有⼀致性。

使⽤ redis 或 memcached 之类的称为分布式缓存，
在多实例的情况下，各实例共⽤⼀份缓存数据，
缓存具有⼀致性。
缺点是需要保持 redis 或 memcached服务的⾼可⽤，
整个程序架构上较为复杂。

## 2-3：说一下 Redis 和 Memcached 的区别和共同点

共同点 ：

都是基于内存的数据库，一般都用来当做缓存使用。
都有过期策略。
两者的性能都非常高。

区别 ：

1. Redis支持更丰富的数据类型（支持更复杂的应用场景）。
   Redis 不仅仅支持简单的 k/v 类型的数据，
   同时还提供 list，set，zset，hash 等数据结构的存储。
   Memcached 只支持最简单的 k/v 数据类型。
2. Redis支持数据的持久化，
   可以将内存中的数据保持在磁盘中，
   重启的时候可以再次加载进行使用,
   而 Memecache 把数据全部存在内存之中。
3. Redis 有灾难恢复机制。
   因为可以把缓存中的数据持久化到磁盘上。
4. Redis 在服务器内存使用完之后，
   可以将不用的数据放到磁盘上。
   但是，Memcached 在服务器内存使用完之后，
   就会直接报异常。
5. Memcached 没有原生的集群模式，
   需要依靠客户端来实现往集群中分片写入数据；
   但是 Redis 目前是原生支持 cluster 模式的.
6. Memcached 是多线程，
   非阻塞 IO 复用的网络模型；
   Redis 使用单线程的多路 IO 复用模型。
7. Redis 支持发布订阅模型、Lua 脚本、事务等功能，
   而 Memcached 不支持。
   并且，Redis 支持更多的编程语言。
8. Memcached过期数据的删除策略
   只用了惰性删除，
   而 Redis 同时使用了惰性删除与定期删除。

## 2-4：为什么说Redis快

1. 完全基于内存，数据存在内存中，
   类似于hashmap，
   hashmap的优势就是查找和操作的
   时间复杂度是o（1）
2. 数据结构进行了特别的设计，
3. 比如说SDS结构中字符串长度len，压缩链表
4. 采用单线程，避免了不必要的上下文切换和竞争条件，
   也不存在多线程或者多线程导致切换而消耗CPU，
   不用去考虑各种所得问题，不存在枷锁释放
   操作，没有因为可能出现死锁二导致的性能消耗
5. 使用多路I/O复用模型，非阻塞IO，
   多路IO复用模型利用select、poll、epoll可以
   同时监察多个流的IO事件时，
   就从阻塞态中唤醒，也是程序就会轮询一遍所有的流，
   并且只依次顺序的处理就绪流，
   这样就可以避免了大量的无用操作
6. RESP协议也就是Redis的序列化协议，
   文本协议，解析迅速
7. 持久化采用子线程进行磁盘操作

## 2-5：Redis应用场景

1. `热点数据的缓存`
由于redis访问速度块、支持的数据类型比较丰富，
所以redis很适合用来存储热点数据，
另外结合expire，我们可以设置过期时间然后再进行缓存更新操作
2. `限时业务的运用`
redis中可以使用expire命令设置一个键的生存时间，
到时间后redis会删除它。利用这一特性可以运用
在限时的优惠活动信息、手机验证码等业务场景。
3. `计数器相关问题`
redis由于incrby命令可以实现原子性的递增，
所以可以运用于高并发的秒杀活动、分布式序列号的生成、
比如限制一个手机号发多少条短信、一个接口一分钟限
制多少请求、一个接口一天限制调用多少次等等。
4. `排行榜相关问题`
关系型数据库在排行榜方面查询速度普遍偏慢，
所以可以借助redis的SortedSet进行热点数据的排序。
5. `分布式锁`
6. `延时操作`
没有做过具体操作，
比如在订单生产后我们占用了库存，
10分钟后去检验用户是够真正购买，
如果没有购买将该单据设置无效，同时还原库存。 
7. `分页、模糊搜索`
可以利用zrangebylex方法可以进行模糊查询功能，
这个也是目前我在redis中发现的唯一一个支持对存储内容进行模糊查询的特性。
对公司进行项目的数据进行了模拟测试，
公司存储数据6000万左右，响应时间在700ms左右，
比mysql的like查询稍微快一点，
但是由于它可以避免大量的数据io操作，
所以总体还是比直接mysql查询更利于系统的性能保障。
8. `点赞、好友等相互关系的存储`
Redis set可以实现set是可以自动排重的，
比如说在微博应用中，
每个用户关注的人存在一个集合中，
就很容易实现求两个人的共同好友功能。
9. `队列`
由于redis有list push和list pop这样的命令，
所以能够很方便的执行队列操作。

# 3.Redis五种数据类型与编码方式

## 3-1：五种数据类型

1. string，常用命令set,get,strlen,exists,dect,incr,setex
   
```java
常用
   127.0.0.1:6379> set key value #设置 key-value 类型的值
   OK
   127.0.0.1:6379> get key # 根据 key 获得对应的 value
   "value"
   127.0.0.1:6379> exists key  # 判断某个 key 是否存在
   (integer) 1
   127.0.0.1:6379> strlen key # 返回 key 所储存的字符串值的长度。
   (integer) 5
   127.0.0.1:6379> del key # 删除某个 key 对应的值
   (integer) 1
   127.0.0.1:6379> get key
   (nil)

批量设置
   127.0.0.1:6379> mset key1 value1 key2 value2 # 批量设置 key-value 类型的值
   OK
   127.0.0.1:6379> mget key1 key2 # 批量获取多个 key 对应的 value

计数器（字符串的内容为整数的时候可以使用）：

   127.0.0.1:6379> set number 1
   OK
   127.0.0.1:6379> incr number # 将 key 中储存的数字值增一
   (integer) 2
   127.0.0.1:6379> get number
   "2"
   127.0.0.1:6379> decr number # 将 key 中储存的数字值减一
   (integer) 1
   127.0.0.1:6379> get number
   "1"

过期：

   127.0.0.1:6379> expire key  60 # 数据在 60s 后过期
   (integer) 1
   127.0.0.1:6379> setex key 60 value # 数据在 60s 后过期 (setex:[set] + [ex]pire)
   OK
   127.0.0.1:6379> ttl key # 查看数据还有多久过期
   (integer) 56
```

2. list，常用命令rpush,lpop,lpush,rpop,lrange、llen
   
```java
通过 rpush/lpop 实现队列：

   127.0.0.1:6379> rpush myList value1 # 向 list 的头部（右边）添加元素
   (integer) 1
   127.0.0.1:6379> rpush myList value2 value3 # 向list的头部（最右边）添加多个元素
   (integer) 3
   127.0.0.1:6379> lpop myList # 将 list的尾部(最左边)元素取出
   "value1"
   127.0.0.1:6379> lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end
   1) "value2"
   2) "value3"
   127.0.0.1:6379> lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一
   1) "value2"
   2) "value3"

通过 rpush/rpop 实现栈：

   127.0.0.1:6379> rpush myList2 value1 value2 value3
   (integer) 3
   127.0.0.1:6379> rpop myList2 # 将 list的头部(最右边)元素取出
   "value3"

通过 lrange 查看对应下标范围的列表元素：

   127.0.0.1:6379> rpush myList value1 value2 value3
   (integer) 3
   127.0.0.1:6379> lrange myList 0 1 # 查看对应下标的list列表， 0 为 start,1为 end
   1) "value1"
   2) "value2"
   127.0.0.1:6379> lrange myList 0 -1 # 查看列表中的所有元素，-1表示倒数第一
   1) "value1"
   2) "value2"
   3) "value3"

通过 llen 查看链表长度：

   127.0.0.1:6379> llen myList
   (integer) 3
```

3. hash,常见命令hset,hmset,hexists,hget,hgetall,hkeys,hvals

```java
   127.0.0.1:6379> hset userInfoKey name "guide" description "dev" age "24"
   OK
   127.0.0.1:6379> hexists userInfoKey name # 查看 key 对应的 value中指定的字段是否存在。
   (integer) 1
   127.0.0.1:6379> hget userInfoKey name # 获取存储在哈希表中指定字段的值。
   "guide"
   127.0.0.1:6379> hget userInfoKey age
   "24"
   127.0.0.1:6379> hgetall userInfoKey # 获取在哈希表中指定 key 的所有字段和值
   1) "name"
   2) "guide"
   3) "description"
   4) "dev"
   5) "age"
   6) "24"
   127.0.0.1:6379> hkeys userInfoKey # 获取 key 列表
   1) "name"
   2) "description"
   3) "age"
   127.0.0.1:6379> hvals userInfoKey # 获取 value 列表
   1) "guide"
   2) "dev"
   3) "24"
   127.0.0.1:6379> hset userInfoKey name "GuideGeGe" # 修改某个字段对应的值
   127.0.0.1:6379> hget userInfoKey name
   "GuideGeGe"
```

4. set

```java

   127.0.0.1:6379> sadd mySet value1 value2 # 添加元素进去
   (integer) 2
   127.0.0.1:6379> sadd mySet value1 # 不允许有重复元素
   (integer) 0
   127.0.0.1:6379> smembers mySet # 查看 set 中所有的元素
   1) "value1"
   2) "value2"
   127.0.0.1:6379> scard mySet # 查看 set 的长度
   (integer) 2
   127.0.0.1:6379> sismember mySet value1 # 检查某个元素是否存在set 中，只能接收单个元素
   (integer) 1
   127.0.0.1:6379> sadd mySet2 value2 value3
   (integer) 2
   127.0.0.1:6379> sinterstore mySet3 mySet mySet2 # 获取 mySet 和 mySet2 的交集并存放在 mySet3 中
   (integer) 1
   127.0.0.1:6379> smembers mySet3
   1) "value2"
```

5. zset,常用命令zadd,zcard,zscore,zrange,zrevrange,zrem

```java
   127.0.0.1:6379> zadd myZset 3.0 value1 # 添加元素到 sorted set 中 3.0 为权重
   (integer) 1
   127.0.0.1:6379> zadd myZset 2.0 value2 1.0 value3 # 一次添加多个元素
   (integer) 2
   127.0.0.1:6379> zcard myZset # 查看 sorted set 中的元素数量
   (integer) 3
   127.0.0.1:6379> zscore myZset value1 # 查看某个 value 的权重
   "3"
   127.0.0.1:6379> zrange  myZset 0 -1 # 顺序输出某个范围区间的元素，0 -1 表示输出所有元素
   1) "value3"
   2) "value2"
   3) "value1"
   127.0.0.1:6379> zrange  myZset 0 1 # 顺序输出某个范围区间的元素，0 为 start  1 为 stop
   1) "value3"
   2) "value2"
   127.0.0.1:6379> zrevrange  myZset 0 1 # 逆序输出某个范围区间的元素，0 为 start  1 为 stop
   1) "value1"
   2) "value2"
```

## 3-2：String类型

### 3-2-1：String-内部结构

redis在内部存储string都是主要还是以`sds的数据结构`实现的，
但是，在整个redis的数据存储过程中为了提高性能，内部做了很多优化。整体选择顺序应该是：
1. 只对长度小于或等于 21 字节，并且可以被解释为整数的字符串进行编码，使用整数存储
2. 尝试将 RAW 编码的字符串编码为 EMBSTR 编码，使用EMBSTR 编码
3. 这个对象没办法进行编码，尝试从 SDS 中移除所有空余空间，使用SDS编码

#### 3-2-1-1：sds简介

最后一个字符为空字符。然而这个空字符不会被计算在len里头
比如说刚开始s1 只有5个空闲位子，
后面需要追加'hello' 5个字符，
很明显是不够的。Redis会做以下三个操作：
计算出大小是否足够
开辟空间至满足所需大小
开辟与已使用大小len相同长度的空闲free空间
（如果len < 1M）开辟1M长度的空闲free空间（如果len >= 1M）

#### 3-2-1-2：embstr和sds的区别（编码方式）

   主要就是在于内存的申请和回收
1. embstr的创建只需分配一次内存，
   而raw为两次（一次为sds分配对象，
   另一次为redisObject分配对象，embstr省去了第一次）。
   相对地，释放内存的次数也由两次变为一次。
2. embstr的redisObject和sds放在一起，更好地利用缓存带来的优势
3. redis并未提供任何修改embstr的方式，
   即embstr是只读的形式。
   对embstr的修改实际上是先转换为raw再进行修改。

#### 3-2-1-3：sds对象创建

sds对象创建sdsnewlen分配了一次内存。
robj对象的创建又分配了一次内存。
整个sds对象的创建其实就是
分配内存并初始化len和free字段。

#### 3-2-1-4：sds内存扩容

当字符串长度小于SDS_MAX_PREALLOC (1024*1024)，
那么就以2倍的速度扩容，
当字符串长度大于SDS_MAX_PREALLOC，
那么就以+SDS_MAX_PREALLOC的速度扩容。

#### 3-2-1-5：String-sds缩容

释放内存的过程中修改len和free字段，
并不释放实际占用内存。

#### 3-2-1-6：Redis字符串的性能优势

1. 快速获取字符串长度
2. 避免缓冲区溢出
3. 降低空间分配次数提升内存使用效率

### 3-2-2：动态字符串与C语言自带字符串的区别

1. 常数复杂度获取字符串长度
    由于len属性的存在，
    获取SDS字符串的长度只需要读取len属性，时间复杂度为O(1)。
    而对于C语言，
    获取字符串的长度通常是经过遍历计数来实现的，时间复杂度为O(n)
2. 避免缓冲区溢出
   对于SDS数据类型，在进行字符修改的时候，
   会首先根据记录的len属性检查内存空间是否满足需求，
   如果不满足，会进行相应的空间扩展，
   然后在进行修改操作，所以不会出现缓冲区溢出。
3. 减少修改字符串的内存重新分配次数
   C语言由于不记录字符串的长度，
   所以如果要修改字符串，
   必须要重新分配内存（先释放再申请），
   因为如果没有重新分配，
   字符串长度增大时会造成内存缓冲区溢出，
   字符串长度减小时会造成内存泄露。
   而对于SDS，由于len属性和free属性的存在，
   对于修改字符串SDS实现了空间预分配和惰性空间释放两种策略:
   * 1、`空间预分配:`对字符串进行空间扩展的时候，
                    扩展的内存比实际需要的多，
                    这样可以减少连续执行字符串增长
                    操作所需的内存重分配次数。
   * 2、`惰性空间释放`:对字符串进行缩短操作时，
                      程序不立即使用内存重新分配
                      来回收缩短后多余的字节，
                      而是使用 free属性将这些字节的数量记录下来，
                      等待后续使用。
4. 二进制安全
   因为C语言的字符串以空字符作为字符串结束的标识，
   而对于一些二进制文件（如图片等)，
   内容可能包括空字符串，
   因此C字符串无法正确存取;
   而所有SDS的 API 都是
   以处理二进制的方式来处理buf里面的元素，
   并且SDS不是以空字符串来判断是否结束，
   而是以len属性表示的长度来判断字符串是否结束。
5. 兼容部分C字符串函数
   虽然 SDS 是二进制安全的，
   但是一样遵从每个字符串都是以空字符串结尾的惯例，
   这样可以重用C语言库<string.h>中的一部分函数。

## 3-3：list类型

### 3-3-1：list-内部结构

redis list数据结构底层
`采用压缩列表ziplist或双向链表linkedlist两种数据结构进行存储，`
首先以ziplist进行存储，在不满足ziplist的存储要求后转换为linkedlist列表。也就是说
列表对象保存的所有字符串元素的长度小于64字节，用ziplist。
列表对象保存的元素数量小于512个。

#### 3-3-1-1：ziplist

ziplist的数据结构主要包括两层，`ziplist和zipEntry。`
ziplist包括zip header、zip entry、zip end三个模块。
zipentry由prevlen、encoding&length、value三部分组成。
prevlen主要是指前面zipEntry的长度，
coding&length是指编码字段长度和实际
存储value的长度，value是指真正的内容。
每个key/value存储结果中key
用一个zipEntry存储，value用一个zipEntry存储。

### 3-3-2：list元素添加过程

1. 创建list对象并添加到db的数据结构当中
2. 针对每个待插入的元素添加到list当中，
   list的每个元素的插入过程中，我们会对是否需要进行转码作两个判断：
    - 对每个插入元素的长度进行判断是否进行ziplist->linkedlist的转码。
    - 对list总长度是否超过ziplist最大长度的判断。

## 3-4：hash类型

### 3-4-1：hash底层存储结构

redis的哈希对象的底层存储可以
`使用ziplist（压缩列表）和hashtable。`
当hash对象可以同时满足
哈希对象保存的所有键值对的键和值的字符串长度都小于64字节
哈希对象保存的键值对数量小于512个
哈希对象就可以使用ziplist编码。

### 3-4-2：redis hash存储过程源码分析

我只是大体看过hset命令，这个过程应该是：
1. 首先查看hset中key对应的value是否存在
2. 判断key和value的长度确定是否需要从zipList到hashtab转换，
3. 对key/value进行string层面的编码，解决内存效率问题。
4. 更新hash节点中key/value问题。

### 3-4-3：Redis字典底层如何解决冲突

拉链法等方法

### 3-4-4：hash如何扩容

正常情况下，当hash表中元素的个数等于第一维数组的长度时，
就会开始扩容，扩容的新数组是原数组大小的2倍。
不过如果Redis正在做bgsave(持久化命令)，
为了减少内存也得过多分离，
Redis 尽量不去扩容，但是如果hash表非常满了，
达到了第一维数组长度的 5 倍了，
这个时候就会强制扩容。
当hash表因为元素
逐渐被删除变得越来越稀疏时，
Redis会对hash表进行缩容
来减少hash表的第一维数组空间占用。
所用的条件是元素个数
低于数组长度的10%，
缩容不会考虑Redis是否在做bgsave。

### 3-4-5：什么是渐进式--rehash

扩容和收缩操作不是一次性、集中式完成的，
而是分多次、渐进式完成的。
如果保存在Redis中的键值对只有几个几十个，
那么rehash操作可以瞬间完成，
但是如果键值对有几百万，几千万甚至几亿，
那么要一次性的进行 rehash，
势必会造成Redis一段时间内不能进行别的操作。
所以 Redis采用渐进式rehash
这样在进行渐进式rehash期间，
字典的删除查找更新等操作
可能会在两个哈希表上进行，
第一个哈希表没有找到，
就会去第二个哈希表上进行查找。
但是进行增加操作，
一定是在新的哈希表上进行的。

## 3-5：set类型

### 3-5-1：set底层存储
 
redis的集合对象set的底层存储结构底层
`使用了intset和hashtable两种数据结构存储的，`
intset我认为应该是一种数组类型的，
hashtable就是普通的哈希表（key为set的值，value为null）。
set的底层存储intset和hashtable是存在编码转换的，
使用intset存储必须满足
集合对象保存的所有元素都是整数值
集合对象保存的元素数量不超过512个
否则使用hashtable，

#### 3-5-1-1：intset的数据结构

intset内部其实是一个数组（int8_t coentents[]数组），
而且存储数据的时候是有序的，因为在查找数据的时候是通过二分查找来实现的。

### 3-5-2：set存储过程
 
set的sadd命令为例子，整个添加过程如下：
1. 检查set是否存在不存在则创建一个set结合。
2. 根据传入的set集合一个个进行添加，
   添加的时候需要进行内存压缩。
3. setTypeAdd执行set添加过程中
   会判断是否进行编码转换。

## 3-6：zset类型

### 3-6-1：zset底层存储结构

zset底层的存储结构
`包括ziplist（压缩列表）或skiplist（跳表），`
在同时满足
有序集合保存的元素数量小于128个
有序集合保存的所有元素的长度小于64字节
的时候，可以使用ziplist，其他时候使用skiplist，
当ziplist作为zset的底层存储结构时候，
每个集合元素使用两个紧挨
在一起的压缩列表节点来保存，
第一个节点保存元素的成员，
第二个元素保存元素的分值。
当skiplist作为zset的底层存储结构的时候，
使用skiplist按序保存元素及分值，
使用dict来保存元素和分值的映射关系。

### 3-6-2：skiplist数据结构
 
skiplist作为zset的存储结构，
主要是包括一个dict对象和一个skiplist对象。
dict保存key/value，key为元素，value为分值；
skiplist保存的有序的元素列表，
每个元素包括元素和分值。
两种数据结构下的元素指向相同的位置。

### 3-6-3：zset存储过程

以zadd的操作作为例子进行分析，
1. 解析参数得到每个元素及其对应的分值
2. 查找key对应的zset是否存在不存在则创建
3. 如果存储格式是ziplist，
   那么在执行添加的过程中
   我们需要区分元素存在和不存在两种情况，
   存在情况下先删除后添加；
   不存在情况下则添加并且需要考
   虑元素的长度是否超出限制或
   实际已有的元素个数是否超过
   最大限制进而决定是否转为skiplist对象。
4. 如果存储格式是skiplist，
   那么在执行添加的过程中
   我们需要区分元素存在和不存在两种情况，
   存在的情况下先删除后添加，
   不存在情况下那么就直接添加，
   在skiplist当中添加完以后
   我们同时需要更新dict的对象。

### 3-6-4：skiplist与平衡树、哈希表的比较

1. skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列，
   而哈希表不是有序的的。因此，在哈希表上只能做单个key的查找，
   不适合做范围查找。
   所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。
2. 在做范围查找的时候，平衡树比skiplist操作要复杂。
   在平衡树上，我们找到指定范围的小值之后，
   还需要以中序遍历的顺序继续寻找其它不超过大值的节点。
   而在skiplist上进行范围查找就非常简单，
   只需要在找到小值之后，
   对第1层链表进行若干步的遍历就可以实现。
3. 平衡树的插入和删除操作可能引发子树的调整，
   逻辑复杂，
   而skiplist的插入和删除
   只需要修改相邻节点的指针，
   操作简单又快速。
4. 从内存占用上来说，skiplist比平衡树更灵活一些。
   一般来说，平衡树每个节点包含2个指针(分别指向左右子树)，
   而skiplist每个节点包含的指针数目平均为1/(1-p)，
   具体取决于参数p的大小。
   如果像Redis里的实现一样，取p=1/4，
   那么平均每个节点包含1.33个指针，
   比平衡树更有优势。
5. 查找单个key，skiplist和平衡树的时间复杂度都为O(logn)，
   大体相当;
   而哈希表在保持较低的哈希值冲突概率的前提下，
   查找时间复杂度接近O(1)，
   性能更高一些。
6. 从算法实现难度上来比较，skiplist比平衡树要简单得多

# Redis---线程模式

Redis 是非阻塞 IO ，多路复用

# Redis---单线程

Redis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，
所以 Redis 才叫做单线程的模型。

## 4-1：为什么Redis是单线程

1. 可维护性对于一个项目来说非常重要，
   如果代码难以调试和测试，问题也经常难以复现，
   这对于任何一个项目来说都会严重地影响项目的可维护性。
   多线程模型虽然在某些方面表现优异，
   但是它却引入了程序执行顺序的不确定性，
   代码的执行过程不再是串行的，
   多个线程同时访问的变量如果没有谨慎处理就会带来诡异的问题。
   引入了多线程，我们就必须要同时引入并发控制
   来保证在多个线程同时访问数据时程序行为的正确性，
   这就需要工程师额外维护并发控制的相关代码，
   例如，我们会需要在可能被并发读写的变量上增加互斥锁：
   在访问这些变量或者内存之前也需要先对获取互斥锁，
   一旦忘记获取锁或者忘记释放锁就可能会导致各种诡异的问题，
   管理相关的并发控制机制也需要付出额外的研发成本和负担。
2. 使用单线程模型也并不意味着程序不能并发的处理任务，
   Redis 虽然使用单线程模型处理用户的请求，
   但是它却使用I/O多路复用机制并发处理
   来自客户端的多个连接，同时等待多个连接发送的请求。
   在 I/O 多路复用模型中，最重要的函数调用就是select以及类似函数，
   该方法的能够同时监控多个文件描述符的可读可写情况，
   当其中的某些文件描述符可读或者可写时，
   select 方法就会返回可读以及可写的文件描述符个数。
   使用 I/O 多路复用技术能够极大地减少系统的开销，
   系统不再需要额外创建和维护进程和线程来监听来自客户端的大量连接，
   减少了服务器的开发成本和维护成本。
3. Redis 选择单线程模型的决定性原因，
   Redis 并不是 CPU 密集型的服务，
   如果不开启AOF备份，所有Redis的操作都会在内存中
   完成不会涉及任何的 I/O 操作，
   这些数据的读写由于只发生在内存中，
   所以处理速度是非常快的；
   整个服务的瓶颈在于网络传输带来的
   延迟和等待客户端的数据传输，
   也就是网络 I/O，
   所以使用多线程模型处理全部的外部请求可能不是一个好的方案。
   比如说多线程中
   保存线程 1 的执行上下文；
   加载线程 2 的执行上下文；
   频繁的对线程的上下文进行切换
   可能还会导致性能地急剧下降，
   这可能会导致我们不仅没有提升请求处理的平均速度，
   反而进行了负优化

## 4-2：既然是单线程，那怎么监听大量的客户端连接呢？

Redis 通过IO 多路复用程序来监听
来自客户端的大量连接（或者说是监听多个 socket），
它会将感兴趣的事件及类型(读、写）
注册到内核中并监听每个事件是否发生。
这样的好处非常明显： 
I/O 多路复用技术的使用让Redis
不需要额外创建多余的线程
来监听客户端的大量连接，
降低了资源的消耗（和 NIO 中的 Selector 组件很像）。

## -3:为什么 Redis 单线程模型也能效率这么高？

1、C 语言实现。
2、纯内存操作。
   Redis 为了达到最快的读写速度，将数据都读到内存中，
   并通过异步的方式将数据写入磁盘。所以 Redis 具有快速和数据持久化的特征。
   如果不将数据放在内存中，磁盘 I/O 速度为严重影响 Redis 的性能。
3、基于非阻塞的 IO 多路复用机制。
4、单线程，避免了多线程的频繁上下文切换问题。
   Redis 利用队列技术，将并发访问变为串行访问，消除了传统数据库串行控制的开销。
5、丰富的数据结构。
   Redis 全程使用 hash 结构，读取速度快，还有一些特殊的数据结构，
   对数据存储进行了优化。例如，压缩表，对短数据进行压缩存储；再再如，跳表，使用有序的数据结构加快读取的速度。
   也因为 Redis 是单线程的，所以可以实现丰富的数据结构，无需考虑并发的问题。

## -4:Redis是单线程的，如何提高多核 CPU 的利用率？

可以在同一个服务器部署多个 Redis 的实例，并把他们当作不同的服务器来使用，在某些时候，无论如何一个服务器是不够的， 所以，如果你想使用多个 CPU ，你可以考虑一下分区。

## 4-3：Redis为什么又采用了多线程

适用于单个Redis服务器的命令不适用于数据分区；
数据分区无法解决热点读/写问题；
数据偏斜，重新分配和放大/缩小变得更加复杂
所以就需要提高网络 IO 读写性能

# 过期删除策略---分类

`Redis采用的是定期删除 + 懒惰删除策略。`

1. 惰性删除 ：只会在取出key的时候才对数据进行过期检查。
             这样对CPU最友好，
             但是可能会造成太多过期 key 没有被删除。
2. 定期删除 ：每隔一段时间抽取一批key执行删除过期key操作。
             并且，Redis 底层会并通过限制删除
             操作执行的时长和频率来
             减少删除操作对CPU时间的影响。
3. 立即删除。在设置键的过期时间时，
            创建一个回调事件，当过期时间达到时，
            由时间处理器自动执行键的删除操作。

### 5-3-1：定期删除策略

Redis 会将每个设置了过期时间的key放入到一个独立的字典中，
默认比如说每100ms进行一次过期扫描：
先随机抽取20个 key
删除这20个key中过期的key
如果过期的key比例超过1/4，
就继续随机抽取20个key，继续删除。

#### 5-3-1-1：为什不扫描所有的 key

Redis 是单线程，全部扫描会卡死。
而且为了防止每次扫描过期的key比例都超过1/4，
导致不停循环卡死线程，
Redis 为每次扫描添加了上限时间，默认是25ms。
如果客户端将超时时间设置的比较短，
比如 10ms，那么就会出现大量的链接因为超时而关闭，
业务端就会出现很多异常。
而且这时你还无法从Redis的slowlog中看到慢查询记录，
因为慢查询指的是逻辑处理过程慢，不包含等待时间。
如果在同一时间出现大面积 key 过期，
Redis 循环多次扫描过期词典，
直到过期的 key 比例小于 1/4。
这会导致卡顿，而且在高并发的情况下，
可能会导致缓存雪崩。

##### 5-3-1-1-1：为什么Redis为每次扫描添的上限时间是25ms

因为 Redis 是单线程，每个请求处理都需要排队，
而且由于Redis每次扫描都是25ms，也就是每个请求最多25ms，
100个请求就是 2500ms。
如果有大批量的 key 过期，
要给过期时间设置一个随机范围，
而不宜全部在同一时间过期，分散过期处理的压力。

#### 5-3-2-2：定期删除策略的实现

过期键的定期删除策略由activeExpireCycle函数实现，
每当Redis服务器的周期性操作serverCron函数执行时，
activeExpireCycle函数就会被调用，
它在规定的时间内，分多次遍历服务器中的各个数据库，
从数据库的expires字典中随机检查一部分键的过期时间，并删除其中的过期键。
activeExpireCycle函数的大体流程为：
函数每次运行时，都从一定数量的数据库中随机取出一定数量的键进行检查，
并删除其中的过期键，比如先从0号数据库开始检查，
下次函数运行时，可能就是从1号数据库开始检查，
直到15号数据库检查完毕，又重新从0号数据库开始检查，
这样可以保证每个数据库都被检查到。

### 5-3-2：懒惰删除策略

删除指令 del 会直接释放对象的内存，
大部分情况下，这个指令非常快，没有明显延迟。
不过如果删除的 key 是一个非常大的对象，
比如一个包含了千万元素的 hash，
在使用 FLUSHDB 和 FLUSHALL 删除包含大量键的数据库时，
那么删除操作就会导致单线程卡顿。
redis 4.0 引入了 lazyfree 的机制，
它可以将删除键或数据库的操作放在后台线程里执行， 
从而尽可能地避免服务器阻塞。

#### 5-3-2-1：懒惰删除策略优缺点

优点：对CPU时间非常友好
缺点：对内存非常不友好
举个例子，如果数据库有很多的过期键，
而这些过期键又恰好一直没有被访问到，
那这些过期键就会一直占用着宝贵的内存资源，造成资源浪费。

#### 5-3-2-2：惰性删除策略的实现

过期键的惰性删除策略由expireIfNeeded函数实现，
所有读写数据库的Redis命令在执行之前都会调用expireIfNeeded函数对输入键进行检查：
如果输入键已经过期，那么将输入键从数据库中删除
如果输入键未过期，那么不做任何处理

### 5-3-3：从库的过期策略

从库不会进行过期扫描，从库对过期的处理是被动的。
主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，
同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key。
因为指令同步是异步进行的，
所以主库过期的 key 的 del 指令没有及时同步到从库的话，
会出现主从数据的不一致，主库没有的数据在从库里还存在。

### 5-3-4：定时删除策略

定时删除策略通过使用定时器，
定时删除策略可以保证过期键尽可能快地被删除，并释放过期键占用的内存。

#### 5-3-4-1：定时删除策略优缺点

优点：对内存非常友好
缺点：对CPU时间非常不友好

举个例子，如果有大量的命令请求等待服务器处理，
并且服务器当前不缺少内存，
如果服务器将大量的CPU时间用来删除过期键，
那么服务器的响应时间和吞吐量就会受到影响。
也就是说，如果服务器创建大量的定时器，
服务器处理命令请求的性能就会降低



# 5.过期删除策略---概念

## 5-1：Redis 给缓存数据设置过期时间有啥用？

因为内存是有限的，
如果缓存中的所有数据都是一直保存的话，
分分钟直接OOM的。
很多时候，我们的业务场景就是
需要某个数据只在某一时间段内存在，
比如我们的短信验证码可能只在1分钟内有效，
用户登录的 token 可能只在 1 天内有效。
如果使用传统的数据库来处理的话，
一般都是自己判断过期，
这样更麻烦并且性能要差很多。

## 5-2：Redis是如何判断数据是否过期的呢？

Redis 通过一个叫做过期字典（可以看作是hash表）
来保存数据过期的时间。
过期字典的键指向Redis数据库中的某个key(键)，
过期字典的值是一个long long类型的整数，
这个整数保存了key所指向的数据库键的过期时间。

# 数据淘汰机制---分类

volatile-lru（least frequently used）：从已设置过期时间的数据集
                                      中挑选最近最少使用的数据淘汰
volatile-ttl：从已设置过期时间的数据集
               中挑选将要过期的数据淘汰
volatile-random：从已设置过期时间的数据集
                 中任意选择数据淘汰
allkeys-lru（least recently used）：当内存不足以容纳新写入数据时，
                                    在键空间中，移除最近最少使用的key
allkeys-random：从数据集中任意选择数据淘汰
no-eviction：禁止驱逐数据，也就是说当内存不足以容纳新写入数据时，
             新写入操作会报错。这个应该没人使用吧！
volatile-lfu（least frequently used）：从已设置过期时间的数据集
                                       中挑选最不经常使用的数据淘汰
allkeys-lfu（least frequently used）：当内存不足以容纳新写入数据时，
                                      在键空间中，移除最不经常使用的 key



# 持久化机制---对过期键的处理

### 5-6-1：RDB对过期键的处理

在执行SAVE命令或者BGSAVE命令创建一个新的RDB文件时，
程序会对数据库中的键进行检查，
已过期的键不会被保存到新创建的RDB文件中。
比如说，如果数据库中包含3个键k1、k2、k3，
并且k2已经过期，那么创建新的RDB文件时，
程序只会将k1和k3保存到RDB文件中，k2则会被忽略。
在启动Redis服务器时，如果服务器只开启了RDB持久化，
那么服务器将会载入RDB文件：
如果服务器以主服务器模式运行，
在载入RDB文件时，程序会对文件中保存的键进行检查，
未过期的键会被载入到数据库中，过期键会被忽略。
如果服务器以从服务器模式运行，在载入RDB文件时，
文件中保存的所有键，不论是否过期，都会被载入到数据库中。
因为主从服务器在进行数据同步（完整重同步）的时候，
从服务器的数据库会被清空，所以一般情况下，过期键对载入RDB文件的从服务器不会造成影响。

### 5-6-2：AOF对过期键的处理

如果数据库中的某个键已经过期，
并且服务器开启了AOF持久化功能，
当过期键被惰性删除或者定期删除后，
程序会向AOF文件追加一条DEL命令，显式记录该键已被删除。
比如说如果客户端执行命令GET message访问已经过期的message键，
那么服务器将执行3个动作：
从数据库中删除message键
追加一条DEL message命令到AOF文件
向执行GET message命令的客户端返回空回复
在执行AOF文件重写时，程序会对数据库中的键进行检查，
已过期的键不会被保存到重写后的AOF文件中。

# 6.持久化机制---概念

将数据(如内存中的对象)保存到可永久保存的存储设备中。

## 6-2：Redis 为什么要持久化?

Redis 中的数据类型都支持Push/Pop、Add/Remove
及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。
在此基础上，Redis 支持各种不同方式的排序。
为了保证效率，数据都是缓存在内存中。
因为数据都是缓存在内存中的，
当你重启系统或者关闭系统后，
缓存在内存中的数据都会消失殆尽，再也找不回来了。
所以，为了让数据能够长期保存，
就要将 Redis 放在缓存中的数据做持久化存储。

# 7.持久化机制---分类

`RDB 持久化`：该机制可以在指定的时间间隔内生成数据集的时间点快照。
`AOF 持久化`：记录服务器执行的所有写操作命令，
             并在服务器启动时，通过重新执行这些命令来还原数据集。
             AOF文件中的命令全部以 Redis 协议的格式来保存，
             新命令会被追加到文件的末尾。 
             Redis 还可以在后台对 AOF 文件进行重写（rewrite），
             使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小

## 6-3-1：RDB（快照）优缺点

`优点：`
1. 灵活设置备份频率和周期。比如说可能打算
   每个小时归档一次最近 24 小时的数据，
   同时还要每天归档一次最近 30 天的数据。
   通过这样的备份策略，一旦系统出现灾难性故障，
   我们可以非常容易的进行恢复。

2. 非常适合冷备份，对于灾难恢复而言，RDB 是非常不错的选择。
   因为我们可以非常轻松的将一个单独的文件压缩后再转移到其它存储介质上。
   可以将这种完整的数据文件发送到一些远程的安全存储上去，

3. 性能最大化。对于 Redis 的服务进程而言，在开始持久化时，
   它唯一需要做的只是 fork 出子进程，之后再由子进程完成这些持久化的工作，
   这样就可以极大的避免服务进程执行 IO 操作了。
   也就是说，RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis 保持高性能。

4. 恢复更快。相比于 AOF 机制，RDB 的恢复速度更更快，更适合恢复数据，特别是在数据集非常大的情况。

`缺点：`

1. 如果你想保证数据的高可用性，即最大限度的避免数据丢失，
   那么 RDB 将不是一个很好的选择。因为系统一旦在定时持久化之前出现宕机现象，
   此前没有来得及写入磁盘的数据都将丢失。

2. 由于 RDB 是通过 fork 子进程来协助完成数据持久化工作的，
   因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是 1 秒钟。

## 6-3-2：AOF 的优缺点

`优点：`
1. 可以带来更高的数据安全性，即数据持久性。
   Redis 中提供了 3 种同步策略，即每秒同步、每修改(执行一个命令)同步和不同步。
   由于每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，
   那么这一秒钟之内修改的数据将会丢失。
   而每修改同步，我们可以将其视为同步持久化，
   每次发生的数据变化都会被立即记录到磁盘中。可以预见，
   这种方式在效率上是最低的。
   
2. 由于该机制对日志文件的写入操作采用的是 append 模式，
   因此在写入过程中即使出现宕机现象，也不会破坏日志文件中已经存在的内容。
   因为以 append-only 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高。
   另外，如果我们本次操作只是写入了一半数据就出现了系统崩溃问题，
   在 Redis 下一次启动之前，我们可以通过 redis-check-aof 
   工具来帮助我们解决数据一致性的问题。

3. 如果 AOF 日志过大，Redis 可以自动启用 rewrite 机制。
   即使出现后台重写操作，也不会影响客户端的读写。因为在 rewrite log 的时候，
   会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。
   再创建新日志文件的时候，老的日志文件还是照常写入。
   当新的 merge 后的日志文件 ready 的时候，再交换新老日志文件即可。

4. AOF 包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。
   事实上，我们也可以通过该文件完成数据的重建。

`缺点：`
1. 对于相同数量的数据集而言，AOF 文件通常要大于 RDB 文件。
   RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。

2. 根据同步策略的不同，AOF 在运行效率上往往会慢于 RDB 。
   每秒同步策略的效率是比较高的，同步禁用策略的效率和 RDB 一样高效。

3. 通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。
   类似 AOF 这种较为复杂的基于命令日志/merge/回放的方式，
   比基于 RDB 每次持久化一份完整的数据快照文件的方式，更加脆弱一些，
   容易有 bug 。不过 AOF 就是为了避免 rewrite 过程导致的 bug ，
   因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，
   而是基于当时内存中的数据进行指令的重新构建，这样健壮性会好很多。

## -3:为什么不建议在主 Redis 节点开启 RDB 功能呢

因为会带来一定时间的阻塞，特别是数据量大的时候。

1. 子进程 fork 相关的阻塞：在 bgsave 的时候，Redis 主进程会 fork 一个子进程，
                        利用操作系统的写时复制技术，这个子进程在拷贝父进程的时候理论上是很快的，
                        因为并不需要全拷贝，比如主进程虽然占了 10G 内存，
                        但子进程拷贝他可能只要 200 毫秒，
                        我认为也就阻塞了 200 毫秒(此耗时基本跟主进程占用的内存是成正比的)，
                        这个具体的时间可以通过统计项 info stats 里的 last_fork_usec 查看。

2. CPU 单线程相关的阻塞：Redis 主进程是单线程跑在单核 CPU 上的，如果显示绑定了CPU ，
                      则子进程会与主进程共享一个 CPU ，而子进程进行持久化的时候是非常占CPU（强势 90%），
                      因此这种情况也可能导致提供服务的主进程发生阻塞（因此如果需要持久化功能，不建议绑定CPU）。

3. 内存相关的阻塞：虽然利用写时复制技术可以大大降低进程拷贝的内存消耗，
                 但这也导致了父进程在处理写请求时需要维护修改的内存页，
                 因此这部分内存过大的话（修改页数多或每页占空间大）也会导致父进程的写操作阻塞。
                 （而不巧的是，Linux中TransparentHugePage 会将复制内存页面单位有 4K 变成 2M ，
                 这对于 Redis 来说是比较不友好的，也是建议优化的，具体可百度之）

4. 磁盘相关的阻塞：极端情况下，假设整个机器的内存已经所剩无几，
                触发了内存交换（SWAP），则整个 Redis的效率将会非常低下（显然这不仅仅针对 save/bgsave ），
                因此，关注系统的 io 情况，也是定位阻塞问题的一种方法。

## -4:选择合适的持久化机制

1. bgsave 做镜像全量持久化，AOF 做增量持久化。
   因为 bgsave 会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，
   所以需要 AOF 来配合使用。在 Redis 实例重启时，
   会使用 bgsave 持久化文件重新构建内存，
   再使用 AOF 重放近期的操作指令来实现完整恢复重启之前的状态。
   在重启恢复的时候，使用的是 RDB-AOF 的混合方案

### -3-1:bgsave 的原理是什么

fork 和 cow 。fork 是指 Redis 通过创建子进程来进行 bgsave 操作。
cow 指的是 copy on write ，子进程创建后，父子进程共享数据段，
父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。

### -3-2:如果突然机器掉电会怎样

取决于 AOF 日志 sync 属性的配置，如果不要求性能，
在每条写指令时都 sync 一下磁盘，就不会丢失数据。
但是在高性能的要求下每次都 sync 是不现实的，一般都使用定时 sync ，
比如 1 秒 1 次，这个时候最多就会丢失 1 秒的数据。

# 持久化机制---扩容

如果Redis被当做缓存使用，使用一致性哈希实现动态扩容缩容。
如果Redis被当做一个持久化存储使用，
必须使用固定的keys-to-nodes映射关系，
节点的数量一旦确定不能变化。
否则的话,在Redis节点需要动态变化的情况，
必须使用可以在运行时进行数据再平衡的一套系统

# 持久化机制---工作流程

客户端向数据库发送写命令 (数据在客户端的内存中)
数据库接收到客户端的写请求 (数据在服务器的内存中)
数据库调用系统API将数据写入磁盘 (数据在内核缓冲区中)
操作系统将写缓冲区传输到磁盘控控制器 (数据在磁盘缓存中)
操作系统的磁盘控制器将数据写入实际的物理媒介 中 (数据在磁盘中)



修改



# 7.集群主从复制

## 7-1：Redis的结构

Redis的主从结构可以采用一主多从或者级联结构，
Redis主从复制可以根据是否是全量分为全量同步和增量同步

## 7-2：Redis主从复制的特点

1. redis采用异步方式复制数据到slave节点，
   从redis2.8开始，slave节点会周期性地
   确认自己每次复制的数据量；
2. 一个master节点可以配置多个slave节点；
3. slave节点可以连接其他的slave节点；
4. slave节点做复制的时候，不会阻塞master节点的正常工作；
5. slave节点做复制的时候，也不会阻塞对自己的查询操作，
   它会用旧数据集来提供服务，
   但在复制完成时，需要删除旧数据集，
   加载新数据集，这时会暂停对外服务；
6. slave节点主要用来横向扩容，做读写分离，
   扩容的slave节点可以提高读的吞吐量；
7. 如果采用主从架构，必须开启master节点的持久化，
   不建议用slave节点作master节点的数据热备，
   因为如果一旦关掉master的持久化，
   可能在master宕机重启时数据是空的，
   然后一经复制，slave节点也会随之丢失。

# 10.事务

## 10-1：Redis事务的概念

Redis 事务的本质是一组命令的集合。
事务支持一次执行多个命令，一个事务中所有命令都会被序列化。
在事务执行过程，会按照顺序串行化执行队列中的命令，
其他客户端提交的命令请求不会插入到事务执行命令序列中。

## 10-2：Redis事务的三个阶段

开启：以MULTI开始一个事务
入队：将多个命令入队到事务中，
     接到这些命令并不会立即执行，
     而是放到等待执行的事务队列里面
执行：由EXEC命令触发事务

## 10-3：Redis事务相关命令

multi，标记一个事务块的开始，返回 ok
exec，执行所有事务块内，事务块内所有命令执行的先后顺序的返回值，
      操作被，返回空值 nil
discard，取消事务，放弃执行事务块内的所有命令，返回 ok
watch，监视 key 在事务执行之前是否被其他指令改动，
       若已修改则事务内的指令取消执行，返回 ok
unwatch，取消 watch 命令对 key 的监视，返回 ok

## 10-4：Redis的ACID

Redis只`一致性`和`隔离性`两个特性，其他特性是不支持的。

### 10-4-1：原子性

单个 Redis 命令的执行是原子性的，
但 Redis 没有在事务上增加任何维持原子性的机制，
所以 Redis 事务的执行并不是原子性的
如果一个事务队列中的所有命令都被成功地执行，
那么称这个事务执行成功
另一方面，如果Redis服务器进程在执行事务的过程中被停止 
比如接到 KILL 信号、宿主机器停机，等等，那么事务执行失败
事务失败时，Redis 也不会进行任何的重试或者回滚动作，
不满足要么全部全部执行，要么都不执行的条件

### 10-4-2：一致性

首先，如果一个事务的指令全部被执行，
那么数据库的状态是满足数据库完整性约束的
其次，如果一个事务中有的指令有错误，
那么数据库的状态是满足数据完整性约束的
最后，如果事务运行到某条指令时，
进程被kill掉了，
如果当前redis采用的是内存模式，
那么重启之后redis数据库是空的，
那么满足一致性条件
如果当前采用RDB模式存储的，
在执行事务时，Redis不会中断事务去执行保存RDB的工作，
只有在事务执行之后，
保存 RDB 的工作才有可能开始。
所以当 RDB 模式下的 Redis 服务器进程在事务中途被杀死时，
事务内执行的命令，不管成功了多少，
都不会被保存到 RDB 文件里。 
恢复数据库需要使用现有的 RDB 文件，
而这个 RDB 文件的数据保存的是最近一次的数据库快照，
所以它的数据可能不是最新的，
但只要 RDB 文件本身没有因为 其他问题而出错，
那么还原后的数据库就是一致的
如果当前采用的是AOF存储的，
那么可能事务的内容还未写入到AOF文件，
那么此时肯定是满足一致性的，
如果事务的内容有部分写入到AOF文件中，
那么需要用工具把AOF中事务执行部分成功的指令移除，
这时，移除之后的AOF文件也是满足一致性的
所以，redis事务满足一致性约束

### 10-4-3：一致性

Redis 是单进程程序，并且它保证在执行事务时，
不会对事务进行中断，
事务可以运行直到执行完所有事务队列中的命令为止。
因此，Redis 的事务是总是带有隔离性的。

### 10-4-4：持久性

因为事务不过是用队列包裹起了一组 Redis 命令，
并没有提供任何额外的持久性功能，
所以事务的持久性由 Redis 所使用的持久化模式决定
在单纯的内存模式下，事务肯定是不持久的
在 RDB 模式下，
服务器可能在事务执行之后、
RDB 文件更新之前的这段时间失败，
所以 RDB 模式下的 Redis 事务也是不持久的
在 AOF 的“总是 SYNC ”模式下，
事务的每条命令在执行成功之后，
都会立即调用 fsync 或 fdatasync 
将事务数据写入到 AOF 文件。
但是，这种保存是由后台线程进行的，
主线程不会阻塞直到保存成功，
所以从命令执行成功到数据保存到硬盘之间，
还是有一段非常小的间隔，
所以这种模式下的事务也是不持久的。
其他 AOF 模式也和“总是 SYNC ”模式类似，
所以它们都是不持久的。

# 11.Redis应用

## 11-1：为什么Redis 变慢了

1. 使用复杂度高的命令
   通过查看慢日志记录，
   我们就可以知道在什么时间执行哪些命令比较耗时，
   如果你的业务经常使用O(n)以上复杂度的命令，
   例如sort、sunion、zunionstore，
   或者在执行O(n)命令时操作的数据量比较大，
   这些情况下Redis处理数据时就会很耗时。
   最好不使用这些复杂度较高的命令，
   并且一次不要获取太多的数据，
   每次尽量操作少量的数据，
   让Redis可以及时处理返回。
2. 存储大key
   针对大key的问题，
   Redis官方在4.0版本推出了lazy-free的机制，
   用于异步释放大key的内存
   降低对Redis性能的影响。
   即使这样，我们也不建议使用大key，
   大key在集群的迁移过程中，也会影响到迁移的性能，
3. 集中过期
   平时在使用Redis时没有延时比较大的情况，
   但在某个时间点突然出现一波延时，
   而且报慢的时间点很有规律，
   例如某个整点，或者间隔多久就会发生一次。
   如果出现这种情况，
   就需要考虑是否存在大量key集中过期的情况。
   在集中过期时增加一个随机时间，
   把这些需要过期的key的时间打散即可。
4. 实例内存达到上限
   有时我们把Redis当做纯缓存使用，
   就会给实例设置一个内存上限maxmemory，
   然后开启LRU淘汰策略。
   当实例的内存达到了maxmemory后，
   你会发现之后的每次写入新的数据，有可能变慢了。
   导致变慢的原因是，
   当Redis内存达到maxmemory后，
   每次写入新的数据之前，
   必须先踢出一部分数据，
   让内存维持在maxmemory之下。
   这个踢出旧数据的逻辑也是需要消耗时间的，
   而具体耗时的长短，要取决于配置的淘汰策略
5. fork耗时严重
   如果你的Redis开启了自动生成RDB和AOF重写功能，
   那么有可能在后台生成RDB和AOF重写时导致Redis的访问延迟增大，
   而等这些任务执行完毕后，延迟情况消失。
   生成RDB和AOF都需要父进程fork出一个子进程进行数据的持久化，
   在fork执行过程中，父进程需要拷贝内存页表给子进程，
   如果整个实例内存占用很大，
   那么需要拷贝的内存页表会比较耗时，
   此过程会消耗大量的CPU资源，在完成fork之前，
   整个实例会被阻塞住，无法处理任何请求，
   如果此时CPU资源紧张，那么fork的时间会更长，
   甚至达到秒级。这会严重影响Redis的性能。
   所以使用Redis时建议部署在物理机上，降低fork的影响。
6. 绑定CPU
   绑定CPU的Redis，在进行数据持久化时，
   fork出的子进程，子进程会继承父进程的CPU使用偏好，
   而此时子进程会消耗大量的CPU资源进行数据持久化，
   子进程会与主进程发生CPU争抢，
   这也会导致主进程的CPU资源不足访问延迟增大。
   所以在部署Redis进程时，
   如果需要开启RDB和AOF重写机制，
   一定不能进行CPU绑定操作！
7. 开启AOF
   当执行AOF文件重写时会因为fork执行耗时
   导致Redis延迟增大，除了这个之外，
   如果开启AOF机制，设置的策略不合理，
   也会导致性能问题。
8. 使用Swap
   如果你发现Redis突然变得非常慢，
   每次访问的耗时都达到了几百毫秒甚至秒级，
   那此时就检查Redis是否使用到了Swap，
   这种情况下Redis基本上已经无法提供高性能的服务。
   我们知道，操作系统提供了Swap机制，
   目的是为了当内存不足时，
   可以把一部分内存中的数据换到磁盘上，
   以达到对内存使用的缓冲。
   但当内存中的数据被换到磁盘上后，
   访问这些数据就需要从磁盘中读取，
   这个速度要比内存慢太多！
9. 网卡负载过高
   Redis也稳定运行了很长时间，
   但在某个时间点之后开始，
   访问Redis开始变慢了，而且一直持续到现在，
   检查一下机器的网卡流量，
   是否存在网卡流量被跑满的情况。
   网卡负载过高，在网络层和TCP层就会出现数据发送延迟、
   数据丢包等情况。Redis的高性能除了内存之外，
   就在于网络IO，请求量突增会导致网卡负载变高。

# 12.锁

## 12-1：redis加锁的几种实现

redis能用的的加锁命令分表是INCR、SETNX、SET
1. 第一种锁命令INCR
这种加锁的思路是， key 不存在，那么 key 的值会先被初始化为0 ，然后再执行INCR操作进行加一。 
然后其它用户在执行 INCR 操作进行加一时，如果返回的数大于 1 ，说明这个锁正在被使用当中。
2. 第二种锁SETNX
这种加锁的思路是，如果 key 不存在，将 key 设置为 value 
如果 key 已存在，则 SETNX 不做任何动作
3. 第三种锁SET
之前方法都需要设置 key 过期。如果请求执行因为某些原因意外退出了，
导致创建了锁但是没有删除锁，那么这个锁将一直存在，以至于以后缓存再也得不到更新。
于是乎我们需要给锁加一个过期时间以防不测。 
但是借助 Expire 来设置就不是原子性操作了。
所以还可以通过事务来确保原子性，
使用 SET 命令本身已经从版本 2.6.12 开始包含了设置过期时间的功能。

## 12-2：分布式锁

### 12-2-1：什么是分布式锁？

当多个进程不在同一个系统中，用分布式锁控制多个进程对资源的访问。

#### 12-2-1-1：分布式锁使用场景

比如说线程A和线程B都共享某个变量X。
如果是单机情况下（单JVM），线程之间共享内存，
只要使用线程锁就可以解决并发问题。
如果是分布式情况下（多JVM），
线程A和线程B很可能不是在同一JVM中，
这样线程锁就无法起到作用了，
这时候就要用到分布式锁来解决。

#### 12-2-1-2：如何实现分布式锁

1. 互斥性
   在任意时刻，只有一个客户端能持有锁。
2. 不能死锁
   客户端在持有锁的期间崩溃而没有主动解锁，
   也能保证后续其他客户端能加锁。
3. 容错性
   只要大部分的Redis节点正常运行
   客户端就可以加锁和解锁。

### 12-2-2：分布式锁常见的三种实现方式：

1. 数据库乐观锁；
2. 基于Redis的分布式锁；
3. 基于ZooKeeper的分布式锁。

#### 12-2-2-1：如何实现加锁解锁

可以直接通过
```java
set key value px milliseconds nx
```
命令实现加锁， 
通过Lua脚本实现解锁。
```java
if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
```
#### 12-2-2-2：加锁代码分析

首先，set()加入了NX参数，
可以保证如果已有key存在，
则函数不会调用成功，
也就是只有一个客户端能持有锁，
满足互斥性。
其次，由于我们对锁设置了过期时间，
即使锁的持有者后续发生崩溃而没有解锁，
锁也会因为到了过期时间而自动解锁（即key被删除），
不会发生死锁。最后，
因为我们将value赋值为requestId，
用来标识这把锁是属于哪个请求加的，
那么在客户端在解锁的时候就可以进行校验
是否是同一个客户端。

#### 12-2-2-3：解锁代码分析

将Lua代码传到jedis.eval()方法里，
并使参数KEYS[1]赋值为lockKey，
ARGV[1]赋值为requestId。在执行的时候，
首先会获取锁对应的value值，
检查是否与requestId相等，
如果相等则解锁（删除key）。

#### 12-2-2-4：redlock算法

这个场景是假设有一个 redis cluster，
有 5 个 redis master 实例。然后执行如下步骤获取一把锁：

1. 获取当前时间戳，单位是毫秒；
2. 轮流尝试在每个 master 节点上创建锁，
   过期时间较短，一般就几十毫秒；
3. 尝试在大多数节点上建立一个锁，
   比如 5 个节点就要求是 3 个节点 n / 2 + 1；
4. 客户端计算建立好锁的时间，
   如果建立锁的时间小于超时时间，就算建立成功了；
5. 要是锁建立失败了，
   那么就依次之前建立过的锁删除；
6. 只要别人建立了一把分布式锁，
   你就得不断轮询去尝试获取锁。
