# 1.MySQL

## 1-1：为什么要使用数据库

因为文件保存数据存在几点缺陷比如
文件的安全性问题。
文件不利于查询和对数据的管理。
文件不利于存放海量数据
文件在程序中控制不方便
为了解决上述问题，专家们设计出更加利于管理数据的东西，数据库

## 1-2: 什么是SQL？

结构化查询语言
其实就是定义了操作所有关系型数据库的规则

## 1-3：什么是MySQL?

Mysql是一种关系型数据库管理系统，

# 2. 关系型数据库与非关系型数据库

## 2-1：非关系型数据库和关系型数据库定义

关系型数据库：  指采用了关系模型来组织数据的数据库。
非关系型数据库：指非关系型的，分布式的，且一般不保证遵循ACID原则的数据存储系统。

## 2-2：关系型数据库优缺点
`优点`
1.容易理解：二维表结构是非常贴近逻辑世界的一个概念，
           关系模型相对网状、层次等其他模型来说更容易理解
2.使用方便：通用的SQL语言使得操作关系型数据库非常方便
3.易于维护：丰富的完整性
           实体完整性、参照完整性和用户定义的完整性
           大大减低了数据冗余和数据不一致的概率
`存在的问题`
1.网站的用户并发性非常高，
  往往达到每秒上万次读写请求，
  对于传统关系型数据库来说，硬盘I/O是一个很大的瓶颈
2.网站每天产生的数据量是巨大的，
  对于关系型数据库来说，
  在一张包含海量数据的表中查询，效率是非常低的
3.在基于web的结构当中，
  数据库是最难进行横向扩展的，
  当一个应用系统的用户量和访问量与日俱增的时候，
  数据库却没有办法像web server和app server
  那样简单的通过添加更多的硬件和服务节点来扩展性能和负载能力。
  当需要对数据库系统进行升级和扩展时，往往需要停机维护和数据迁移。
4.性能欠佳：在关系型数据库中，
           导致性能欠佳的最主要原因是多表的关联查询，
           以及复杂的数据分析类型的复杂SQL报表查询。
           为了保证数据库的ACID特性，
           必须尽量按照其要求的范式进行设计，
           关系型数据库中的表都是存储一个格式化的数据结构。

## 2-3：非关系型数据库优缺点

`优点`
1. 用户可以根据需要去添加自己需要的字段，
  为了获取用户的不同信息，不像关系型数据库中，
  要对多表进行关联查询。
  仅需要根据id取出相应的value就可以完成查询。
2. 适用于SNS(Social Networking Services)中，
   例如facebook，微博。系统的升级，功能的增加，
   往往意味着数据结构巨大变动，这一点关系型数据库难以应付，
   需要新的结构化数据存储。
   由于不可能用一种数据结构化存储应付所有的新的需求，
   因此，非关系型数据库严格上不是一种数据库，
   应该是一种数据结构化存储方法的集合。
`不足：`
   只适合存储一些较为简单的数据，
   对于需要进行较复杂查询的数据，
   关系型数据库显的更为合适。不适合持久存储海量数据

## 2-4：非关系型数据库和关系型数据库区别

1.成本：Nosql数据库简单易部署，
       基本都是开源软件，不需要像使用Oracle那样花费大量成本购买使用，
       相比关系型数据库价格便宜。
2.查询速度：Nosql数据库将数据存储于缓存之中，
           而且不需要经过SQL层的解析，
           关系型数据库将数据存储在硬盘中，
           自然查询速度远不及Nosql数据库。
3.存储数据的格式：Nosql的存储格式是key,value形式、文档形式、图片形式等等，
                所以可以存储基础类型以及对象或者是集合等各种格式，
                而数据库则只支持基础类型。
4.扩展性：关系型数据库有类似join这样的多表查询机制的限制导致扩展很艰难。
         Nosql基于键值对，数据之间没有耦合性，所以非常容易水平扩展。
5.持久存储：Nosql不使用于持久存储，海量数据的持久存储，还是需要关系型数据库
6.数据一致性：非关系型数据库一般强调的是数据最终一致性，
              不像关系型数据库一样强调数据的强一致性，
              从非关系型数据库中读到的有可能还是处于一个中间态的数据，
            Nosql不提供对事务的处理。

# 3.三大范式

## 3-1：数据库三大范式是什么

第一范式: 每个列都不可以再拆分. 
第二范式: 非主键列完全依赖于主键,而不能是依赖于主键的一部分. 
第三范式: 非主键列只依赖于主键,不依赖于其他非主键.

## 3-2：三大范式举例

# 4.数据库的数据类型

## 4-1：mysql的数据类型

整数类型：BIT、BOOL、TINY INT、
         SMALL INT、MEDIUM INT、 
         INT、 BIG INT
浮点数类型：FLOAT、DOUBLE、DECIMAL
字符串类型：CHAR、VARCHAR、TINY TEXT、
           TEXT、MEDIUM TEXT、LONGTEXT、
           TINY BLOB、BLOB、MEDIUM BLOB、LONG BLOB
日期类型：Date、DateTime、TimeStamp、Time、Year

## 4-2：varchar与char的区别

char长度固定，varchar长度可以变化

比如说字符串abc
char（10）就是占用10个字节，
varchar（10）只占用3个字节，10只是最大值

### 4-2-1：varchar(50)中50的涵义

varchar(50)中50的涵义最多存放50个字符

## 4-3：int(20)中20的涵义

int(M)只是用来显示数据的宽度，
比如说int（20），mysql会自动补0

## 4-4：FLOAT和DOUBLE的区别是什么？

1. 在内存中占有的字节数不同
　　单精度浮点数在机内存占4个字节
　　双精度浮点数在机内存占8个字节
2. 有效数字位数不同
　　单精度浮点数有效数字8位
　　双精度浮点数有效数字16位
3. 数值取值范围
4. 在程序中处理速度不同
　　一般来说，CPU处理单精度浮点数的速度比处理双精度浮点数快

## 4-5：MySQL INT和CHAR隐式类型转换需要注意什么？

1. 当查询字段是INT类型，
   如果查询条件为CHAR，
   将查询条件转换为INT，
   如果是字符串前导都是数字，
   将截取前导数字用来比较，
   如果没有前导数字，则转换为0。
2. 当查询字段是CHAR/VARCHAR类型，
   如果查询条件为INT，
   将查询字段转换为INT再进行比较，
   可能会造成全表扫描。

# 5.SQL生命周期

1. 建立服务器与数据库连接
2. 数据库拿到SQL
3. 解析执行
4. 读取数据到内存，进行业务逻辑处理
5. 发给客户端
6. 关闭连接，释放资源

# 6.MySQL预编译

指的是数据库驱动在发送 sql 语句和参数
给 DBMS 之前对 sql 语句进行编译，
这样 DBMS 执行 sql 时，就不需要重新编译。

## 6-1：预编译出现的原因

1、很多情况下，一条SQL语句可能会反复执行，或者每次执行的时候只有个别的值不同
2、比如query的where条件的值不同，
   update的set的值不同,insert的values值不同，都会造成SQL语句的不同。
3、每次因为这些值的不同就进行词法语义解析、优化、制定执行计划，就会很影响效率。

## 6-2：预编译的好处

1、预编译之后的 SQL 多数情况下可以直接执行，DBMS 不需要再次编译。
2、越复杂的SQL，编译的复杂度将越大，预编译阶段可以合并多次操作为一个操作。
3、相同的预编译 SQL 可以重复利用。
   把一个 SQL 预编译后产生的 PreparedStatement 对象缓存下来，
　 下次对于同一个 SQL，
   可以直接使用这个缓存的 PreparedState 对象。
4、可以将这类SQL语句中的值用占位符替代，不需要每次编译，可以直接执行，
　　只需执行的时候，直接将每次请求的不同的值设置到占位符的位置。
5、预编译可以视为将sql语句模板化或者说参数化。


# 7.SQL注入

## 7-1：SQL注入简介

通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，
最终达到欺骗服务器执行恶意的SQL命令。
它不是利用操作系统的BUG来实现攻击，
而是针对程序员编程时的疏忽，
通过SQL语句，实现无帐号登录，甚至篡改数据库。

## 7-2：SQL注入攻击实例

  比如在一个登录界面，要求输入用户名和密码：
  可以这样输入实现免帐号登录：
  用户名： ‘or 1 = 1 –
  密 码：空白
  点登陆,如若没有做特殊处理,那么这个非法用户就很得意的登陆进去了.
  从理论上说，后台认证程序中的SQL语句还是很正常的
  ```sql
  String sql = "select * from user_table where username=
  ' "+userName+" ' and password=' "+password+" '";
  ```
  但是当输入了上面的用户名和密码，上面的SQL语句变化了：
  ```SQL
  SELECT * FROM user_table WHERE username=
  '’or 1 = 1 -- and password='’
  ```
  条件后面username=”or 1=1 用户名等于 ” 或1=1 
  那么这个条件一定会成功；
  然后后面加两个-，这意味着注释，
  它将后面的语句注释，
  让他们不起作用，
  这样语句永远都能正确执行，
  用户轻易骗过系统，获取合法身份。

## 7-3：SQL注入解决方案

1. `PreparedStatement最直接方法`

  采用预编译语句集，它内置了处理SQL注入的能力，
  只要使用它的setXXX方法传值即可。
使用好处：
  (1).代码的可读性和可维护性.
  (2).PreparedStatement尽最大可能提高性能.
  (3).最重要的一点是极大地提高了安全性.
原理：
  sql注入只对sql语句的准备(编译)过程有破坏作用
  而PreparedStatement已经准备好了,执行阶段只是把输入串作为数据处理,
  而不再对sql语句进行解析,准备,因此也就避免了sql注入问题.

2. `使用正则表达式过滤传入的参数`
3. `字符串过滤`
  比较通用的一个方法：
 （||之间的参数可以根据自己程序的需要添加）
4. jsp中调用该函数检查是否包函非法字符
5. JSP页面判断代码：
  使用JavaScript在客户端进行不安全字符屏蔽
  检查是否含有”‘”,”\\”,”/”

# 8.sql编写

## 8-0：SQL的分类

DDL-------数据定义语言
DQL-------数据查询语言
DML-------数据操纵语言
DCL-------数据控制语言

## 8-1：有什么查询

主要的查询分为了基础查询、条件查询、
               排序查询、子查询、
               分页查询、多表查询

### 8-1-1：基础查询

### 8-1-4：子查询

子查询比如说在select嵌套select

#### 8-1-4-1：子查询的三种情况

1. 子查询结果只要是单行单列， 肯定在 WHERE 后面作为条件
2. 子查询结果是多行单列，结果类似于一个数组，父查询使用 in 运算符
3. 子查询结果只要是多列，肯定在 From 后面作为表

### 8-1-6：多表查询

先对第一个和第二个表按照两表连接做查询，然后用查询结果和第三个表做连接查询，以此类推

#### 8-1-6-1：笛卡尔积问题

就是两张表的记录
进行一个相乘的操作查询出来的结果就是笛卡尔积,
如果左表有n条记录,右表有m条记录,
笛卡尔积查询出有n*m条记录,
其中往往包含了很多错误的数据,所以这种查询方式并不常用。

#### 8-1-6-2：笛卡尔积的解决方案

添加上连接条件

##### 8-1-6-2-1：五种关联（连接）查询

1. 交叉连接(CROSS JOIN)
2. 内连接(INNER JOIN)
3. 外连接(LEFT JOIN/RIGHT JOIN)
4. 联合查询(UNION 与 UNION ALL)
5. 全连接(FULL JOIN)
-----------------------------------------------------------
6. 内连接: 只连接匹配的行
7. 左外连接: 包含左边表的全部行，以及右边表中全部匹配的行
8. 右外连接: 包含右边表的全部行，以及左边表中全部匹配的行
9. 全外连接: 包含左、右两个表的全部行。
10. 交叉连接: 生成笛卡尔积－它不使用任何匹配或者选取条件，
            而是直接将一个数据源中的每个行与另一个数据源
            的每个行都一一匹配


## 8-2：常见函数

分为了单行函数与分组函数

### 8-2-1：单行函数


### 8-2-3：聚合函数

AVG()          返回某列的平均值
COUNT()     返回某列的行数
MAX()         返回某列的最大值
MIN()          返回某列的最小值
SUM()         返回某列值之和




## 8-3：关键字/语句

1. from:需要从哪个数据表检索数据
2. join：联合多表查询返回记录时，并生成一张临时表
3. on：在生成临时表时使用的条件
4. where:过滤表中数据的条件
5. group by:如何将上面过滤出的数据分组
6. having:对上面已经分组的数据进行过滤的条件
7. select:查看结果集中的哪个列，或列的计算结果
8. order by :按照什么样的顺序来查看返回的数据
9. limit：限制查询结果返回的数量

### 8-3-1：truncate、 delete区别

1、TRUNCATE在各种表上无论是大的还是小的都非常快。
   如果有ROLLBACK命令DELETE将被撤销，而TRUNCATE则不会被撤销。
2、truncate不能进行回滚操作。
3、truncate不触发任何delete触发器。
4、当表被truncate后，这个表和索引所占用的空间会恢复到初始大小，
   而delete操作不会减少表或索引所占用的空间。
5、不能truncate一个带有外键的表，如果要删除首先要取消外键，然后再删除。
    DELETE语句执行删除的过程是每次从表中删除一行，
    并且同时将该行的的删除操作作为事务记录
    在日志中保存以便进行进行回滚操作。

### 8-3-2：mysql的having用法

having字句可以让我们筛选成组后的各种数据，
where字句在聚合前先筛选记录，也就是说作用在group by和having字句前。
而 having子句在聚合后对组记录进行筛选
我的理解就是真实表中没有此数据，这些数据是通过一些函数生存。

### 8-3-3：mysql中 in 和 exists 区别

1. exists()适合B表比A表数据大的情况
2. 当A表数据与B表数据一样大时,in与exists效率差不多,可任选一个使用

### 8-3-4：WHERE子句和HAVING子句的执行速度

在 WHERE 子句和 HAVING 子句中都可以使用的条件，最好写在 WHERE 子
句中的另一个理由与性能即执行速度有关系。由于性能不在本书介绍的范围之内，
因此暂不进行说明。通常情况下，为了得到相同的结果，将条件写在 WHERE 子句
中要比写在 HAVING 子句中的处理速度更快，返回结果所需的时间更短。
为了理解其中原因，就要从 DBMS 的内部运行机制来考虑。使用 COUNT 函
数等对表中的数据进行聚合操作时，DBMS 内部就会进行排序处理。排序处理是
会大大增加机器负担的高负荷的处理 A。因此，只有尽可能减少排序的行数，才能
提高处理速度。
通过 WHERE 子句指定条件时，由于排序之前就对数据进行了过滤，因此能够
减少排序的数据量。但 HAVING 子句是在排序之后才对数据进行分组的，因此与
在 WHERE 子句中指定条件比起来，需要排序的数据量就会多得多。虽然 DBMS
的内部处理不尽相同，但是对于排序处理来说，基本上都是一样的。
此外， WHERE 子句更具速度优势的另一个理由是，可以对 WHERE 子句指定条
件所对应的列创建索引，这样也可以大幅提高处理速度。创建索引是一种非常普遍
的提高 DBMS 性能的方法，效果也十分明显，这对 WHERE 子句来说也十分有利。

### 8-3-5：UNION与UNION ALL的区别？

union：对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序；
union All：对两个结果集进行并集操作，包括重复行，不进行排序；

### 8-3-6：count(*)、count(1)、count(column)的区别

count(*)对行的数目进行计算,
包含NULL，count(1)
这个用法和count(*)的结果是一样的
count(column)对特定的列的值具有的行数进行计算,
不包含NULL值。


## 8-4：增删改查（CURD）--日志

### 8-4-1：一条sql执行过程

1. `连接Mysql`
   客户端连接MySql服务时是半双工通信，
   客户端和服务端交互发送数据时必须一次发送完毕，
   在传输特别大的数据包时系统性能开销非常大，
   所以当客户端使用insert等语句发送大量的数据包时服务端就会拒绝连接，
   原因是服务端默认限制客户端发送的数据包大小不能超过4MB，
   这点可以通过修改MySql参数来更改大小限制，
   或者将需要发送的数据包在客户端进行分批发送处理。
   同理，在服务端返回给客户端数据时也要避免大量的数据包传输，
   所以要避免使用不带Limit的查询语句进行批量查询，
   或者可以先使用count做数据量预估，根据数据量进行分批查询。
2. `缓存与解析器`
   当缓存是打开的情况下，MySql服务端拿到Sql语句后，
   首先会到缓存判断是否有完全一致
   的Sql语句查询记录（判断时Sql语句连空格都不能有误差），
   有就将相应的结果集返回给客户端，
   当缓存中不存在时，会将Sql语句交给解析器来处理，
   解析器通过关键字将SQL语句进行解析，并生成一棵对应的“解析树”，
   接着会验证Sql语句是否有词法、语法等错误，
   例如，它将验证是否使用错误的关键字，
   或者使用关键字的顺序是否正确等，
   再或者它还会验证引号是否能前后正确匹配。
3. `预处理器（Preprocessor）`
   预处理器会对解析树行进一步检查解析树是否合法，
   例如，这里将检查数据表和数据列是否存在，
   还会解析名字和别名，
   看看它们是否有歧义。
   接着预处理器会验证权限。
   这通常很快，除非服务器上有非常多的权限配置。
4. `优化器（查询优化器 Query Optimizer）`
   一条Sql语句并不是只有一种执行路径。
   当优化器拿到预处理器发来的解析树后，
   会根据解析树生成不同的执行路径，
   这些执行路径就是常说的执行计划（Execution Plan），
   优化器会对这些执行计划计算对应的开销（cost），
   当得到不同的执行计划与相应的开销后，
   优化器将它认为最佳的执行计划去交给下一个部件去执行
5. `查询执行引擎`
   当优化器将执行计划交到查询执行引擎手里时，
   剩下的任务就简单多了，
   查询执行引擎调用相应的API接口来操作存储引擎，
   将存储引擎返回的查询结果返回给客户端，
   如果缓存开启的情况也会在缓存中进行缓存。
6. `存储引擎`
   存储引擎就有很多了，像Mysql5.5版本前默认使用的MyIsan存储引擎，
   5.5版本后默认使用的InnoDB存储引擎，

### 8-4-2：一条sql更新/删除/增加语句时怎么执行的

1.执行器先取到ID=2这行。因为ID是主键，引擎直接用树搜索找到这一行。
  如果ID=2这一行所在的数据页本来就在内存中，
  就直接返回给执行器；
  否则需要先从磁盘读入内存，然后再返回。
2.执行器拿到引擎给的行数据，把这个值加1，
  比如原来N，现在是N+1，得到新的一行数据，
  再调用引擎接口写入这行数据。
3.引擎将这行新数据更新到内存中，
  同时将这个`更新/删除/增加`操作记录在redo log里面，
  此时redo log处于prepare状态。
  然后告知执行器执行完成了，随时可以提交事务。
4.执行器生成这个操作的binlog，并把binlog写入磁盘中。
5.执行器调用引擎的提交事务接口，
  引擎把刚刚写入的redo log改成提交（commit）状态，
  更新完成。

#### 8-4-2-1：日志由来

因为MySQL整体来看，其实就有两块：
一块是Server层，它主要做的是MySQL功能层面的事情；
还有一块是引擎层，负责存储相关的具体事宜。
而redo log是InnoDB引擎特有的日志，
而Server层也有自己的日志，称为binlog（归档日志）。

##### 8-4-2-1-1：什么是binlog

binlog其实就是记录了数据库表结构和表数据`变更`
我们的数据是保存在数据库里边的嘛，
假设我们对某个商品的某个字段的内容改了（`数据库变更`），
而用户检索的出来数据是走搜索引擎的。
为了让用户能搜到最新的数据，我们需要把引擎的数据也改掉。
数据库的变更，搜索引擎的数据也需要变更。

binlog：存储着每条变更的SQL语句

###### 8-4-2-1-1-1：binlog一般用来做什么

主要有两个作用：复制和恢复数据
MySQL一般都是一主多从结构的，
从服务器需要与主服务器的数据保持一致，这就是通过binlog来实现的
数据库的数据消失了，我们可以通过binlog来对数据进行恢复。
因为binlog他记录了数据库的变更，所以用binlog进行赋值和恢复数据

###### 8-4-2-1-1-2：MySQL的binlog有几种录入格式

有三种格式,statement,row和mixed.

**Statement：每一条会修改数据的sql都会记录在binlog中。**
`优点`：不需要记录每一行的变化，
        减少了binlog日志量，节约了IO，提高性能。
        相比row能节约多少性能 与日志量，
        这个取决于应用的SQL情况，
        正常同一条记录修改或者插入row格式所产生的
        日志量还小于Statement产生的日志量，
        但是考虑到如果带条件的update操作，
        以及整表删除，alter表等操作，
        ROW格式会产生大量日志，
        因此在考虑是否使用ROW格式日志时
        应该根据应用的实际情况，
        其所产生的日志量会增加多少，
        以及带来的IO性能问题。
`缺点`：由于记录的只是执行语句，
        为了这些语句能在slave上正确运行，
        因此还必须记录每条语句在执行的时候的
        一些相关信息，以保证所有语句能
        在slave得到和在master端执行时候相同的结果。
**Row:不记录sql语句上下文相关信息，仅保存哪条记录被修改。**
`优点`：binlog中可以不记录执行的sql语句的上下文相关的信息，
       仅需要记录那一条记录被修改成什么了。
       所以rowlevel的日志内容会非常清楚的记录下
       每一行数据修改的细节。而且不会出现某些特定情况下
       的存储过程，或function，
       以及trigger的调用和触发无法被正确复制的问题
`缺点`：所有的执行的语句当记录到日志中的时候，
       都将以每行记录的修改来记录，
       这样可能会产生大量的日志内容。
       比如一条update语句，修改多条记录，
       则binlog中每一条修改都会有记录，
       这样造成binlog日志量会很大，
       特别是当执行alter table之类的语句的时候，
       由于表结构修改，每条记录都发生改变，
       那么该表每一条记录都会记录到日志中。
**Mixedlevel: 以上两种level的混合使用。**
一般的语句修改使用statment格式保存binlog，
如一些函数，statement无法完成主从复制的操作，
则采用row格式保存binlog,MySQL会根据执行的每一条具体
的sql语句来区分对待记录的日志形式，
也就是在Statement和Row之间选择一种。

##### 8-4-2-1-2：redo log

Mysql的基本存储结构是页(记录都存在页里边)，
所以MySQL是先把这条记录所在的页找到，
然后把该页加载到内存中，将对应记录进行修改。
当我们修改的时候，写完内存了，但数据还没真正写到磁盘的时候。
此时我们的数据库挂了，我们可以根据redo log来对数据进行恢复。
因为redo log是顺序IO，所以写入的速度很快，
并且redo log记载的是物理变化（xxxx页做了xxx修改），
文件的体积很小，恢复速度很快。

##### 8-4-2-1-3：bin log和redo log比较

1. `存储内容来说`
   binlog记载的是update/delete/insert这样的SQL语句，
   而redo log记载的是物理修改的内容（xxxx页修改了xxx）。
2. `功能`
   redo log的作用是为持久化而生的。写完内存，
   如果数据库挂了，
   那我们可以通过redo log来恢复内存还没来得及刷到磁盘的数据，
   将redo log加载到内存里边，
   那内存就能恢复到挂掉之前的数据了。
   binlog的作用是复制和恢复而生的。
   主从服务器需要保持数据的一致性，
   通过binlog来同步数据。
   如果整个数据库的数据都被删除了，
   binlog存储着所有的数据变更情况，
   那么可以通过binlog来对数据进行恢复。
3. `第三方面来说，写入内容来说`
   redo log事务开始的时候，
   就开始记录每次的变更信息，
   而binlog是在事务提交的时候才记录。

###### 8-4-2-1-3-1：我写其中的某一个log，失败了，那会怎么办？

`如果说是先写redo log，再写binlog，`
如果写redo log失败了，
那我们就认为这次事务有问题，回滚，不再写binlog。
如果写redo log成功了，
写binlog，写binlog写一半了，但失败了
我们还是会对这次的事务回滚，
将无效的binlog给删除
（因为binlog会影响从库的数据，所以需要做删除操作）
如果写redo log和binlog都成功了，那这次算是事务才会真正成功。

##### 8-4-2-1-4：两阶段提交意义

“两阶段提交”是为了让两份日志之间的逻辑一致。
由于redo log和binlog是两个独立的逻辑，如果不用两阶段提交
会出现错误
比如说
`先写redo log后写binlog。`
假设在redo log写完，binlog还没有写完的时候，
MySQL进程异常重启。redo log写完之后，
系统即使崩溃，仍然能够把数据恢复回来，
所以恢复后这一行c的值是1。
但是由于binlog没写完就crash了，
这时候binlog里面就没有记录这个语句。
因此，之后备份日志的时候，
存起来的binlog里面就没有这条语句。
然后发现，如果需要用这个binlog来恢复临时库的话，
由于这个语句的binlog丢失，
这个临时库就会少了这一次更新，
恢复出来的这一行c的值就是0，
与原库的值不同。
如果
`先写binlog后写redo log。`
如果在binlog写完之后crash，
由于redo log还没写，
崩溃恢复以后这个事务无效，
所以这一行c的值是0。
但是binlog里面已经记录了“把c从0改成1”这个日志。
所以，在之后用binlog来恢复的时候就多了一个事务出来，
恢复出来的这一行c的值就是1，
与原库的值不同。

###### 8-4-2-1-4-1：MySQL如何保证redo log和binlog的数据是一致的

MySQL通过两阶段提交来保证redo log和binlog的数据是一致的。
`阶段1：InnoDBredo log 写盘，InnoDB 事务进入 prepare 状态`
`阶段2：binlog 写盘，InooDB 事务进入 commit 状态`
每个事务binlog的末尾，会记录一个 XID event，
标志着事务是否提交成功，
也就是说，恢复过程中，
binlog 最后一个 XID event 之后的内容都应该被 purge。

###### 8-4-2-1-4-2：如果整个数据库的数据都被删除了，那我可以用redo log的记录来恢复吗？

不能
因为功能的不同，redo log 存储的是物理数据的变更，
如果我们内存的数据已经刷到了磁盘了，那redo log的数据就无效了。
所以redo log不会存储着历史所有数据的变更，文件的内容会被覆盖的。

### 8-4-3：一条sql查询语句时怎么执行的

1. 先连接到这个数据库上，这时候就是连接器。
       连接器负责跟客户端建立连接、获取权限、维持和管理连接。
2. 连接建立完成后，就可以执行select语句了。进行查询缓存。
   MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。
   之前执行过的语句及其结果可能会以key-value对的形式，
   被直接缓存在内存中。key是查询的语句，value是查询的结果。
   如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端。
   如果语句不在查询缓存中，就会继续后面的执行阶段。
   执行完成后，执行结果会被存入查询缓存中。
   可以看到，如果查询命中缓存，MySQL不需要执行后面的复杂操作，
   就可以直接返回结果，这个效率会很高。
3. 如果没有命中查询缓存，就要开始真正执行语句了。
   MySQL需要知道你要做什么，因此需要对SQL语句做解析。
4. 经过了分析器，MySQL就知道你要做什么了。在开始执行之前，
   还要先经过优化器的处理。优化器是在表里面有多个索引的时候，
   决定使用哪个索引；
   或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。
5. 于是就进入了执行器阶段，开始执行语句。
   开始执行的时候，要先判断一下你对这个表user有没有执行查询的权限，
   如果没有，就会返回没有权限的错误，
   如果有权限，就打开表继续执行。
   打开表的时候，执行器就会根据表的引擎定义，
   去使用这个引擎提供的接口

#### 8-4-3-1：mysql有关权限的表都有哪几个

1. user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。
2. db权限表：记录各个帐号在各个数据库上的操作权限。
3. table_priv权限表：记录数据表级的操作权限。
4. columns_priv权限表：记录数据列级的操作权限。
5. host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。
              这个权限表不受GRANT和REVOKE语句的影响。

### 8-4-4：MySQL查询字段区不区分大小写？

不区分

#### 8-4-4-1：如何解决需要区分英文大小写的场景

解决方案一

MySQL默认的字符检索策略：utf8_general_ci，表示不区分大小写。
可以使用utf8_general_cs，表示区分大小写，
也可以使用utf8_bin，表示二进制比较，同样也区分大小写 。
创建表时，直接设置表的collate属性为utf8_general_cs
或者utf8_bin；
如果已经创建表，则直接修改字段的Collation
属性为utf8_general_cs或者utf8_bin。

```sql
CREATE TABLE testt(
id INT PRIMARY KEY,
name VARCHAR(32) NOT NULL
) ENGINE = INNODB COLLATE =utf8_bin;

-- 修改表结构的Collation属性
ALTER TABLE TABLENAME 
MODIFY COLUMN COLUMNNAME VARCHAR(50) BINARY CHARACTER 
SET utf8 COLLATE utf8_bin DEFAULT NULL;
```

解决方案二

直接修改sql语句，在要查询的字段前面加上binary关键字

```sql
-- 在每一个条件前加上binary关键字
select * from user where 
binary username = 'admin' 
and binary password = 'admin';

-- 将参数以binary('')包围
select * from user 
where username 
like binary('admin') 
and password like binary('admin');
```

## 8-5：常见约束

NOT NULL: 用于控制字段的内容一定不能为空（NULL）。
UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束。
PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。
FOREIGN KEY: 用于预防破坏表之间连接的动作，
             也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。
CHECK: 用于控制字段的值范围。

### 8-5-1：字段为什么要求定义为not null?

null值会占用更多的字节,且会在程序中造成很多与预期不符的情况


## 8-6：键

### 8-6-1：超键、候选键、主键、外键分别是什么？

超键：一个属性可以为作为一个超键，
     多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。
候选键：是最小超键，即没有冗余元素的超键。
主键：一个数据列只能有一个主键，且主键的取值不能缺失，
     即不能为空值（Null）
外键：在一个表中存在的另一个表的主键称此表的外键。

### 8-6-2：为什么用自增列作为主键

如果表使用自增主键，那么每次插入新的记录，
记录就会顺序添加到当前索引节点的后续位置，
当一页写满，就会自动开辟一个新的页
如果使用非自增主键，由于每次插入主键的值近似于随机，
因此每次新纪录都要被插到现有索引页得中间某个位置，
此时MySQL不得不为了将新记录插到合适位置而移动数据，
甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，
此时又要从磁盘上读回来，这增加了很多开销，
同时频繁的移动、分页操作造成了大量的碎片，
得到了不够紧凑的索引结构，
后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。

#### 8-6-2-1：主键使用自增ID还是UUID?

推荐使用自增ID,不要使用UUID.

因为在InnoDB存储引擎中,主键索引是作为聚簇索引存在的,
也就是说,主键索引的B+树叶子节点上存储了
主键索引以及全部的数据(按照顺序),
如果主键索引是自增ID,
那么只需要不断向后排列即可,
如果是UUID,由于到来的ID与原来的大小不确定,
会造成非常多的数据插入,数据移动,
然后导致产生很多的内存碎片,
进而造成插入性能的下降.

#### 8-6-2-1：为什么MySQL不推荐使用uuid或者雪花id作为主键？

自增的主键的值是顺序的,
所以Innodb把每一条记录都存储在一条记录的后面。
当达到页面的最大填充因子时候：

①下一条记录就会写入新的页中，
一旦数据按照这种顺序的方式加载，
主键页就会近乎于顺序的记录填满，
提升了页面的最大填充率，不会有页的浪费

②新插入的行一定会在原有的最大数据行下一行,
mysql定位和寻址很快，
不会为计算新行的位置而做出额外的消耗

③减少了页分裂和碎片的产生

因为uuid相对顺序的自增id来说是毫无规律可言的,
新行的值不一定要比之前的主键的值要大,
所以innodb无法做到总是把新行插入到索引的最后,
而是需要为新行寻找新的合适的位置从而来分配新的空间。
这个过程需要做很多额外的操作，
数据的毫无顺序会导致数据分布散乱，
将会导致一些问题：
比如说
①写入的目标页很可能已经刷新到磁盘上并且从缓存上移除，
或者还没有被加载到缓存中，
innodb在插入之前不得不先找到
并从磁盘读取目标页到内存中，
这将导致大量的随机IO
②因为写入是乱序的,innodb不得不频繁的做页分裂操作,
以便为新的行分配空间,页分裂导致移动大量的数据，
一次插入最少需要修改三个页以上
③由于频繁的页分裂，页会变得稀疏并被不规则的填充，
最终会导致数据会有碎片
在把随机值（uuid和雪花id）
载入到聚簇索引(innodb默认的索引类型)以后,
有时候会需要做一次OPTIMEIZE TABLE来重建表并优化页的填充，
这将又需要一定的时间消耗。

#### 8-6-2-2：使用自增id的缺点

①别人一旦爬取你的数据库,
 就可以根据数据库的自增id获取到你的业务增长信息，
 很容易分析出你的经营情况
②对于高并发的负载，
  innodb在按主键进行插入的时候会造成明显的锁争用，
  主键的上界会成为争抢的热点，
  因为所有的插入都发生在这里，
  并发插入会导致间隙锁竞争
③Auto_Increment锁机制
 会造成自增锁的抢夺,有一定的性能损失
、
#### 8-6-2-3：数据库主键自增怎么获取主键值

使用函数  LAST_INSERT_ID()
比如说如查看最新一次自增得到的id：  select  LAST_INSERT_ID();
或者在mybatis中
设置userGeneratedKeys属性值为true:使用自动增长的主键。
使用keyProperty设置把主键值设置给哪一个属性

```java
<insert id="addEmp" 
        parameterType="com.neuedu.mybatis.bean.Employee" 
        useGeneratedKeys="true" keyProperty="id" databaseId="mysql">
　　　insert into tbl_employee(last_name,email,gender)
　　　values(#{lastName},#{gender},#{email})
</insert>
```

### 8-6-3：为什么要尽量设定一个主键?

主键是数据库确保数据行在整张表唯一性的保障,
即使业务上本张表没有主键,
也建议添加一个自增长的ID列作为主键.
设定了主键之后,
在后续的删改查的时候可能
更加快速以及确保操作数据范围安全.

## 8-7：视图

视图是虚拟的表

1. 重用SQL语句；
2. 简化复杂的SQL操作（可以方便的重用它而不必知道它的基本查询细节）；
3. 使用表的组成部分而不是整个表；
4. 保护数据（可以给用户授予表的部分访问权限而不是整个表的访问权限）；
5. 更改数据格式和表示（视图可返回与底层表的表示和格式不同的数据）。

## 8-8：存储过程

预先用SQL语句写好并用一个指定的名称存储起来，只需调用execute,即可自动完成命令。

### 8-8-1：存储过程有哪些优缺点？

1. 一般SQL语句每执行一次就编译一次,使用存储过程创建进行编译，可提高数据库执行速度。
2. 当对数据库进行复杂操作时
   (如对多个表进行Update,Insert,Query,Delete时），
   可将此复杂操作用存储过程封装起来。
3. 存储过程可以重复使用,可减少数据库开发人员的工作量
4. 安全性高,可设定只有某此用户才具有对指定存储过程的使用权

## 8-9：触发器

数据库触发器是在数据库中发生特定操作时运行的特殊存储过程

### 8-9-1：触发器的使用场景有哪些？

1. 复杂的审计
   可以使用触发器来跟踪对表所做的更改。
   比如说认为这是涉及敏感操作的信息，进行了更改。
2. 执行业务规则
   每次添加或修改客户记录时检查客户状态。

## 8-10：窗口函数

### 8-10-1：什么是窗口函数

具体定义记不太清楚，因为
经常会遇到需要在每组内排名，比如说
排名问题：每个部门按业绩来排名
或者找出每个部门排名前N的员工进行奖励

### 8-10-2：窗口函数的定义

```sql
<窗口函数> over (partition by <用于分组的列名>
                order by <用于排序的列名>)
```


## 8-11：sql实战

### 8-11-1：去重重复数据

### 8-11-2：MySQL 如何高效率随机获取N条数据？

ID连续的情况下（注意不能带where，否则结果不好）：

```sql
SELECT *
FROM `mm_account` AS t1 
JOIN (SELECT ROUND(RAND() * (SELECT MAX(id) FROM `mm_account`)) 
AS id) AS t2
WHERE t1.id >= t2.id
ORDER BY t1.id ASC LIMIT 4;
```

ID不连续的情况下：

```sql
SELECT * FROM `mm_account` 
WHERE id >= 
(SELECT floor(RAND() * (SELECT MAX(id) FROM `mm_account`)))  
and city="city_91" and showSex=1
ORDER BY id LIMIT 4;
```

如果有一个字段叫id，最快的方法如下（随机获取5条）：

```sql
SELECT * FROM mm_account 
WHERE id >= 
((SELECT MAX(id) FROM mm_account)-
(SELECT MIN(id) FROM mm_account)) * RAND() 
+ (SELECT MIN(id) FROM mm_account)
limit 5;
```
如果带where语句，上面就不适合了，带where语句请看下面：
```sql
SELECT *
FROM `mm_account` AS t1 
JOIN (SELECT ROUND(RAND() * (
(SELECT MAX(id) 
FROM `mm_account` where id<1000 )
-(SELECT MIN(id) FROM `mm_account` 
where id<1000 ))+(SELECT MIN(id) 
FROM `mm_account` where id<1000 )) 
AS id) AS t2
WHERE t1.id >= t2.id
ORDER BY t1.id LIMIT 5;
```

# 9.事务

## 9-1：什么是事务

事务是逻辑上的⼀组操作，要么都执⾏，要么都不执⾏。

## 9-2：数据库事务特性

1. 原⼦性（Atomicity）：事务是最⼩的执⾏单位，
                       不允许分割。事务的原⼦性确保动作要么全部完成，
                       要么完全不起作⽤；
2. ⼀致性（Consistency）： 执⾏事务前后，数据保持⼀致，
                          多个事务对同⼀个数据读取的结果是相同的；
3. 隔离性（Isolation）： 并发访问数据库时，
                       ⼀个⽤户的事务不被其他事务所⼲扰，
                       各并发事务之间数据库是独⽴的；
4. 持久性（Durability）： ⼀个事务被提交之后。
                         它对数据库中数据的改变是持久的，
                         即使数据库发⽣故障也不应该对其有任何影响。

### 9-2-1：ACID靠什么保证的(底层原理)

`A原子性`由undo log日志保证，
         它记录了需要回滚的日志信息，
         事务回滚时撤销已经执行成功的sql
`C一致性`一般由代码层面来保证
`I隔离性`由MVCC来保证
`D持久性`由内存+redo log来保证，
         mysql修改数据同时在内存和redo log记录这次操作，
         事务提交的时候通过redo log刷盘，
         宕机的时候可以从redo log恢复

#### 9-2-1-1：什么是undo log

undo log主要有两个作用：回滚和多版本控制(MVCC)
在数据修改的时候，不仅记录了redo log，还记录undo log，
如果因为某些原因导致事务失败或回滚了，可以用undo log进行回滚
undo log主要存储的也是逻辑日志，比如我们要insert一条数据了，
那undo log会记录的一条对应的delete日志。我们要update一条记录时，
它会记录一条对应相反的update记录。
因为回滚，跟需要修改的操作相反就好，这样就能达到回滚的目的。因为支持回滚操作，
所以我们就能保证：“一个事务包含多个操作，这些操作要么全部执行，要么全都不执行”。【原子性】
因为undo log存储着修改之前的数据，相当于一个前版本，MVCC实现的是读写不阻塞，
读的时候只要返回前一个版本的数据就行了。

##### 9-2-1-1-1：Undo Log缺陷如何解决？

每个事务提交前将数据和Undo Log写入磁盘，
这样会导致大量的磁盘IO，因此性能很低。
因此引入了另外一种机制来实现持久化，
即Redo Log。
Redo Log记录的是新数据的备份。
在事务提交前，只要将Redo Log持久化即可，
不需要将数据持久化。当系统崩溃时，
虽然数据没有持久化，但是Redo Log已经
持久化。系统可以根据Redo Log的内容，
将所有数据恢复到最新的状态。

#### 9-2-1-2：Java如何保证原子性

1. 第一个方法是循环CAS
   只能保证一个共享变量的原子操作。
   当对一个共享变量执行操作时，
   我们可以使用循环CAS的方式来保证原子操作，
   但是对多个共享变量操作时，
   循环CAS就无法保证操作的原子性，这个时候就可以用锁
   或者有一个取巧的办法，
   就是把多个共享变量合并成一个共享变量来操作。
   比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij
2. 锁
   锁机制保证了只有获得锁的线程能够操作锁定的内存区域。

#### 9-2-1-3：数据库崩溃时事务的恢复机制

为了满足事务的原子性，在操作任何数据之前，
首先将数据备份到一个地方，这个存储数据备份的地方称为UndoLog。
然后进行数据的修改。
如果出现了错误或者用户执行了回滚，
系统可以利用Undo Log中的备份将数据恢复到事务开始之前的状态。

## 9-3：在并发环境下,事务会发生哪些问题?

1. 脏读
    A事务读取B事务尚未提交的更改数据，并在这个数据的基础上进行操作，
    这时候如果事务B回滚，那么A事务读到的数据是不被承认的。
2. 不可重复读
    不可重复读是指A事务读取了B事务已经提交的更改数据。假
    如A在取款事务的过程中，B往该账户转账100，A两次读取的余额发生不一致。
3. 幻读
    A事务读取B事务提交的新增数据,会引发幻读问题。幻读一般发生在计算统计数据的事务中，
    例如银行系统在同一个事务中两次统计存款账户的总金额，
    在两次统计中，刚好新增了一个存款账户，存入了100，这时候两次统计的总金额不一致。 
4. 第一类丢失更新
    A事务撤销时，把已经提交的B事务的更新数据覆盖了。 
5. 第二类丢失更新
    A事务覆盖B事务已经提交的数据，造成B事务所做的操作丢失 。

### 9-3-1：不可重复读和幻读的区别

不可重复读是指读到了已经提交的事务的更改数据（修改或删除），
幻读是指读到了其他已经提交事务的新增数据。
对于这两种问题解决采用不同的办法，
防止读到更改数据，只需对操作的数据添加行级锁，
防止操作中的数据发生变化；
二防止读到新增数据，往往需要添加表级锁，
将整张表锁定，防止新增数据（oracle采用多版本数据的方式实现）。

## 9-4：如何解决事务并发问题

采用隔离级别

### 9-4-1：四大隔离级别

1. 读取未提交： 最低的隔离级别，允许读取尚未提交的数据变更， 可能会导致脏读、幻读或不可重复读
2. 读取已提交： 允许读取并发事务已经提交的数据， 可以阻⽌脏读，但是幻读或不可重复读仍有可能发
               ⽣。
3. 可重复读：   对同⼀字段的多次读取结果都是⼀致的，除⾮数据是被本身事务⾃⼰所修改， 可以阻⽌脏
               读和不可重复读，但幻读仍有可能发⽣。
4. 可串⾏化：   最⾼的隔离级别， 该级别可以防⽌脏读、不可重复读以及幻读。

#### 9-4-1-1：隔离级别的原理

1. READ_UNCOMMITED（`读取未提交`） 的原理
   - *事务对当前被读取的数据不加锁；*
   - `事务在更新某数据的瞬间（就是发生更新的瞬间），`
     `必须先对其加行级共享锁，直到事务结束才释放。`
2. READ_COMMITED(`读取已提交`)的原理
   - *事务对当前被读取的数据加 行级共享锁（当读到时才加锁），一旦读完该行，立即释放该行级共享锁；*
   - `事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加 行级排他锁，直到事务结束才释放。`
3. REPEATABLE READ 的原理:
   - *事务在读取某数据的瞬间（就是开始读取的瞬间），必须先对其加 行级共享锁，直到事务结束才释放；*
   - `事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加 行级排他锁，直到事务结束才释放。`
4. SERIALIZABLE 的原理:
   - *事务在读取数据时，必须先对其加 表级共享锁 ，直到事务结束才释放；*
   - `事务在更新数据时，必须先对其加 表级排他锁 ，直到事务结束才释放。`

##### 9-4-1-1-1：为什么要有事物隔离级别

因为事物隔离级别越高，在并发下会产生的问题就越少，
但同时付出的性能消耗也将越大，
因此很多时候必须在并发性和性能之间做一个权衡。
所以设立了几种事物隔离级别，
以便让不同的项目可以根据自己项目的
并发情况选择合适的事物隔离级别，
对于在事物隔离级别之外会产生的并发问题，在代码中做补偿。

#### 9-4-1-2：MySQL 中RC（读已提交）和RR（可重复读）隔离级别的区别

1. RR支持gap lock，而RC则没有gap lock（间隙锁）。
   因为MySQL的RR需要gap lock来解决幻读问题。
   而RC隔离级别则是允许存在不可重复读和幻读的。所以RC的并发一般要好于RR；
2. RC 隔离级别，通过 where 条件过滤之后，不符合条件的记录上的行锁，
   会释放掉；但是RR隔离级别，即使不符合where条件的记录，
   也不会是否行锁和gap lock；所以从锁方面来看，RC的并发应该要好于RR；
3. RC 隔离级别不支持 statement 格式的bin log，
   因为该格式的复制，会导致主从数据的不一致；
   只能使用 mixed 或者 row 格式的bin log
4. RC隔离级别时，事务中的每一条select语句会读取到他自己执行时已经提交了的记录，
   而RR隔离级别时，事务中的一致性读的是以第一条select语句的运行时，
   作为本事务的一致性读的建立时间点的。只能读取该时间点之前已经提交的数据
5. RC隔离级别下的update语句，
   使用的是半一致性读(semi consistent)；
   而RR隔离级别的update语句使用的是当前读；当前读会发生锁的阻塞

#### 9-4-1-3：隔离级别用来做什么

隔离级别用于决定如何控制并发用户读写数据的操作

## 9-5：如何手动处理事务

回滚

## 9-6：事务与日志

### 9-6-1：日志种类

1. 错误日志：记录出错信息，也记录一些警告信息或者正确的信息。
2. 查询日志：记录所有对数据库请求的信息，
            不论这些请求是否得到了正确的执行。
3. 慢查询日志：设置一个阈值，
              将运行时间超过该值的
              所有SQL语句都记录到慢查询的日志文件中。
4. 二进制日志：记录对数据库执行更改的所有操作。
5. 中继日志：中继日志也是二进制日志，用来给slave 库恢复
6. 事务日志：重做日志redo和回滚日志undo

### 9-6-2：事务是如何通过日志来实现的

事务日志是通过redo和innodb的存储引擎日志
缓冲来实现的，当开始一个事务的时候，
会记录该事务的lsn号;
当事务执行时，会往InnoDB存储引擎的日志
的日志缓存里面插入事务日志；
当事务提交时，必须将存储引擎的日志
缓冲写入磁盘，通过innodb_flush_log_at_trx_commit来控制，
也就是写数据前，需要先写日志。这种方式称为“预写日志方式”

# 10.引擎

## 10-1：MySQL存储引擎MyISAM与InnoDB区别

1、MyISAM是非事务安全的，而InnoDB是事务安全的
2、MyISAM锁的粒度是表级的，而 InnoDB支持行级锁
3、MyISAM支持全文类型索引，而InnoDB不支持全文索引
4、MylSAM相对简单，效率上要优于InnoDB，小型应用可以考虑使用MyISAM
5、MyISAM表保存成文件形式，跨平台使用更加方便
6、MylSAM管理非事务表，提供高速存储和检索以及全文搜索能力，如果在应用中执行大
量select 操作可选择
7、InnoDB用于事务处理，具有ACID事务支持等特性，如果在应用中执行大量 insert 和update操作，可选择。
8、InnoDB支持外键（从A表一个列（外键）去检索B表的主键）
9、MyISAM一般是非聚集索引，InnoDB是聚集索引

## 10-2：InnoDB引擎的4大特性

1. 插入缓冲（insert buffer)
2. 二次写(double write)
3. 自适应哈希索引(ahi)
4. 预读(read ahead)
   InnoDB使用两种预读算法来提高I/O性能：线性预读（linear read-ahead）和随机预读（randomread-ahead）
   为了区分这两种预读的方式，我们可以把线性预读放到以extent为单位，
   而随机预读放到以extent中的page为单位。线性预读着眼于将下一个extent提前读取到buffer pool中，
   而随机预读着眼于将当前extent中的剩余的page提前读取到buffer pool中。

## 10-3：MyISAM和InnoDB存储引擎使用的锁

MyISAM采用表级锁(table-level locking)。
InnoDB支持行级锁(row-level locking)和表级锁,默认为行级锁

## 10-4：InnoDB存储引擎的锁的算法

Record lock：单个⾏记录上的锁
Gap lock：间隙锁，锁定⼀个范围，不包括记录本身
Next-key lock： record+gap 锁定⼀个范围，包含记录本身

# 11.锁

## 11-1：隔离级别与锁的关系

SQL使用锁来实现事务的隔离。
事务获取锁这种控制资源，
用于保护数据资源，
防止其他事务对数据进行冲突的或不兼容的访问。
比如说
读未提交，可以通过写操作加“持续-X锁”实现。
读已提交，可以通过写操作加“持续-X”锁，读操作加“临时-S锁”实现。
可重复读，可以通过写操作加“持续-X”锁，读操作加“持续-S锁”实现。

## 11-2：mysql锁的种类

1. 共享/排它锁(Shared and Exclusive Locks)
2. 意向锁(Intention Locks)
3. 记录锁(Record Locks)
4. 间隙锁(Gap Locks)
5. 临键锁(Next-key Locks)
6. 插入意向锁(Insert Intention Locks)
7. 自增锁(Auto-inc Locks)

### 11-2-1：共享/排它锁(Shared and Exclusive Locks)
   
   `共享锁`（Share Locks，记为S锁），读取数据时加S锁
   比如说执行查询某个表的所有信息时，首先锁定第一页，读取之后，释放对第一页的锁定，
   然后锁定第二页。这样，就允许在读操作过程中，修改未被锁定的第一页。

   `排他锁`（eXclusive Locks，记为X锁），修改数据时加X锁
   如果一个事务对对象加了排他锁，其他事务就不能再给它加任何锁了。

### 11-2-2：意向锁(Intention Locks)
   
   未来的某个时刻，事务可能要加共享/排它锁了，先提前声明一个意向。

#### 11-2-2-1：意向锁分类

意向共享锁(IS)，事务有意向对表中的某些行加共享S锁；
意向排它锁(IX)，事务有意向对表中的某些行加排它X锁；

```sql
select ... lock in share mode;　　要设置IS锁；
select ... for update;　　　　　　 要设置IX锁；
```

### 11-2-3：记录锁(Record Locks)
   
   记录锁，它封锁索引记录

### 11-2-4：间隙锁(Gap Locks)

它封锁索引记录中的间隔，
或者第一条索引记录之前的范围，又或者最后一条索引记录之后的范围。

比如说，某一个sql语句会封锁区间(8,15)，以阻止其他事务插入id位于该区间的记录。

间隙锁的主要目的，就是为了防止其他事务在间隔中插入数据，
以导致“不可重复读”。
如果把事务的隔离级别降级为读提交(Read Committed, RC)，间隙锁则会自动失效。

### 11-2-5：临键锁(Next-key Locks)

临键锁，是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。

比如说某个表中id降级为普通索引(key)，
也就是说即使这里声明了要加锁(for update)，
而且命中的是索引，
但是因为索引在这里没有UK约束，
所以innodb会使用临键锁，
临键锁的主要目的，
也是为了避免幻读(Phantom Read)。
如果把事务的隔离级别降级为读已提交，临键锁则也会失效。

### 11-2-6：插入意向锁(Insert Intention Locks)

插入意向锁，是间隙锁(Gap Locks)的一种，
它是专门针对insert操作的。
多个事务，在同一个索引，
同一个范围区间插入记录时，
如果插入的位置不冲突，不会阻塞彼此。
比如说事务A先执行，在10与20两条记录中插入了一行，还未提交：
事务B后执行，也在10与20两条记录中插入了一行：
因为是插入操作，虽然是插入同一个区间，
但是插入的记录并不冲突，
所以使用的是插入意向锁，此处A事务并不会阻塞B事务。

### 11-2-7：自增锁(Auto-inc Locks)

专门针对事务插入AUTO_INCREMENT（自增列）类型的列。
比如说如果一个事务正在往表中插入记录，
所有其他事务的插入必须等待，
以便第一个事务插入的行，是连续的主键值。

## 11-3：行锁和表锁

### 11-3-1:表级锁

表级锁一次会将整个表锁定，所可以很好的避免死锁问题
锁定粒度大，锁冲突概率高、并发度低；

### 11-3-2：行级锁

锁定对象的颗粒度很小，发生锁冲突的概率低、并发度高；
缺点是开销大、加锁慢，行级锁容易发生死锁；

## 11-4：悲观锁与乐观锁

### 11-4-1：悲观锁

是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）
修改持保守态度，因此，在整个数据处理过程中，将数据处于锁定状态。
读取数据时给加锁，其它事务无法修改这些数据。修改删除数据时也要加锁，其它事务无法读取这些数据。

### 11-4-2：乐观锁

乐观锁，大多是基于数据版本（ Version ）记录机制实现。

#### 11-4-2-1：数据版本

为数据增加一个版本标识，在基于数据库表的版本解决方案中，
一般是通过为数据库表增加一个 “version” 字段来实现。
读取出数据时，将此版本号一同读出，之后更新时，
对此版本号加一。

## 11-5：数据库死锁的预防与解除

1. 应尽可能缩短事务。在同一DB中并发执行多个需要长时间运行的事务时，
   发生死锁的概率较大。事务运行时间越长，其持有排它锁（exclusive锁）或更
   新锁（update锁）的时间便越长，
   从而堵塞了其它活动并可能导致死锁。
   保持事务在一个批处理中，
   可以最小化事务的网络通信往返量，
   减少完成事务可能的延迟并释放锁。
   同时，涉及多个表的查询更新操作，
   若比较耗时，尽量不要放在一个事务内处理，
   能分割便分割。若不能分割，便尽可能使之在业务量较小的时间
   (例如子夜或者午餐时间)执行。
2. 应按同一顺序访问数据对象。
   如果所有并发事务按同一顺序访问对象，
   则发生死锁的可能性会降低。
   例如，如果两个并发事务获得Supplier 表上的锁，
   然后获得Part表上的锁，
   则在其中一个事务完成之前，
   另一个事务被阻塞在Supplier表上。
   第一个事务提交或回滚后，第二个事务继续进行。
   不发生死锁。
   将存储过程用于所有的数据修改可以标准化访问对象的顺序。
3. 必须避免编写包含用户交互的事务。
   因为运行没有用户交互的批处理的速度要
   远远快于用户手动响应查询的速度，
   若用户不能及时反馈，则此事务将挂起。
   因而将严重降低系统的吞吐量，
   因为事务持有的任何锁只有在事务提交或回滚时才会释放。
   即使不出现死锁的情况，
   访问同一资源的其它事务也会被阻塞，等待该事务完成。
4. 可使用低隔离级别。
   确定事务是否能在更低的隔离级别上运行。
   执行提交读允许事务读取另一个事务已读取（未修改）的数据，
   而不必等待第一个事务完成。
   使用较低的隔离级别（例如提交读）
   而不使用较高的隔离级别（例如可串行读）
   可以缩短持有共享锁的时间，
   从而降低了锁定争夺。
5. 可考虑体系结构的优化与代码重构，
   提高系统整体的运行效率。
   例如尽可能不采用效率低下的计算模型，
   复杂的业务应采用异步任务调度处理。
6. 可通过程序控制事务提交的时机。
   如果一次检索出了10万条记录但只更改了其中的100条，
   就可以通过代码来执行100个update。或是用分段提交，
   即所有的修改使用多个事务进行提交，
   但这样会使事务不完整，应酌情使用。
7. 宜将经常更新的数据库和查询数据库分开。
   定期将不改变的数据导入查询数据库中，
   这样查询和更新就可以分开进行，而降低死锁机率。
8. 在进行数据库模式设计时，
   应注意外键引用的完整性，并对外键加索引。
   如果更新了父表的主键，由于外键上没有索引，
   所以子表会被锁定；如果删除了父表中的一行，整个子表也会被锁定。

## 11-6：锁类型

页级、表级、行级。
表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高,并发度最低。
行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。
页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般
算法：
next KeyLocks锁，同时锁住记录(数据)，并且锁住记录前面的Gap
Gap锁，不锁记录，仅仅记录前面的Gap
Recordlock锁（锁数据，不锁Gap）
所以其实 Next-KeyLocks=Gap锁+ Recordlock锁

## 11-7：多版本并发控制MVCC

代表多版本并发控制，读不加锁，读写不冲突

MVCC是通过在每行记录后面保存两个隐藏的列来实现的。
这两个列，一个保存了行的创建时间，
一个保存行的过期时间（或删除时间）。
当然存储的并不是实际的时间值，
而是系统版本号（system version number)。
每开始一个新的事务，系统版本号都会自动递增。
事务开始时刻的系统版本号会作为事务的版本号，
用来和查询到的每行记录的版本号进行比较。

MVCC最大的好处，：读不加锁，读写不冲突。
                 在读多写少的OLTP应用中，
                 读写不冲突是非常重要的，
                 极大的增加了系统的并发性能，
在MVCC并发控制中，读操作可以分成两类：快照读 (snapshot read)与当前读 (current read) 。
快照读，读取的是记录的可见版本 (有可能是历史版本)，不用加锁。
当前读，读取的是记录的最新版本，并且，当前读返回的记录，
都会加上锁，保证其他事务不会再并发修改这条记录。

### 11-7-1：哪些读操作是快照读？哪些操作又是当前读呢？

快照读： 简单的select操作，属于快照读，不加锁。(当然，也有例外，下面会分析)
select * from table where ?;
当前读： 特殊的读操作，插入/更新/删除操作，属于当前读，需要加锁。
select * from table where ? lock in share mode;
select * from table where ? for update;
insert into table values (…);
update table set ? where ?;
delete from table where ?;
都属于当前读，读取记录的最新版本。并且，
读取之后，还需要保证其他并发事务不能修改当前记录，
对读取记录加锁。除了第一条语句，对读取记录加S锁 (共享锁)外，
其他的操作，都加的是X锁 (排它锁)。

### 11-7-2：为什么将 插入/更新/删除 操作，都归为当前读

一个Update操作的具体流程。当Update SQL被发给MySQL后，
MySQL Server会根据where条件，读取第一条满足条件的记录，
然后InnoDB引擎会将第一条记录返回，并加锁 (current read)。
待MySQL Server收到这条加锁的记录之后，
会再发起一个Update请求，更新这条记录。
一条记录操作完成，再读取下一条记录，
直至没有满足条件的记录为止。
因此，Update操作内部，就包含了一个当前读。
同理，Delete操作也一样。Insert操作会稍微有些不同，
简单来说，就是Insert操作可能会触发Unique Key的冲突检查，
也会进行一个当前读。

## 11-8：加锁过程

`组合一：id主键+RC`

id是主键，Read Committed隔离级别，
给定SQL：delete from t1 where id = 10; 
只需要将主键上，id = 10的记录加上X锁即可。

`组合二：id唯一索引+RC`

id不是主键，而是一个Unique的二级索引键值。
那么在RC隔离级别下，delete from t1 where id = 10; 
由于id是unique索引，
因此delete语句会选择走id列的索引进行where条件的过滤，
在找到id=10的记录后，首先会将unique索引上的id=10索引记录加上X锁，
同时，会根据读取到的name列，回主键索引(聚簇索引)，
然后将聚簇索引上的name = ‘d’ 对应的主键索引项加X锁。
聚簇索引上的记录也要加锁主要是如果并发的一个SQL，
是通过主键索引来更新：update t1 set id = 100 where name = ‘d’; 
此时，如果delete语句没有将主键索引上的记录加锁，
那么并发的update就会感知不到delete语句的存在，
违背了同一记录上的更新/删除需要串行执行的约束。

`组合三：id非唯一索引+RC`

id列不再唯一，只有一个普通的索引。
假设delete from t1 where id = 10; 语句，
仍旧选择id列上的索引进行过滤where条件，
比如说在id列索引上，满足id = 10查询条件的记录，均已加锁。
同时，这些记录对应的主键索引上的记录也都加上了锁。

`组合四：id无索引+RC`

id列上没有索引，where id = 10;这个过滤条件，没法通过索引进行过滤，
那么只能走全表扫描做过滤。全表扫描时，
由于id列上没有索引，因此只能走聚簇索引，
进行全部扫描。但是，聚簇索引上所有的记录，都被加上了X锁�����
无论记录是否满足条件，全部被加上X锁。既不是加表锁，
也不是在满足条件的记录上加行锁。
由于MySQL的内部实现决定的。如果一个条件无法通过索引快速过滤，
那么存储引擎层面就会将所有记录加锁后返回，
然后由MySQL Server层进行过滤。因此也就把所有的记录，都锁上了。

`组合五：id主键+RR`

id列是主键列，Repeatable Read隔离级别，
针对delete from t1 where id = 10; 这条SQL，
加锁与组合一：[id主键，Read Committed]一致。

`组合六：id唯一索引+RR`

与组合二：[id唯一索引，Read Committed]一致。
两个X锁，id唯一索引满足条件的记录上一个，对应的聚簇索引上的记录一个。

组合七：id非唯一索引+RR


# 12.索引

## 12-1：主键与索引的区别

主键是一种约束，唯一索引是一种索引，两者在本质上是不同的。

1、主键创建后一定包含一个唯一性索引，唯一性索引并不一定就是主键。
2、唯一性索引列允许空值，而主键列不允许为空值。
3、主键列在创建时，已经默认为空值 + 唯一索引了。
4、主键可以被其他表引用为外键，而唯一索引不能。
5、一个表最多只能创建一个主键，但可以创建多个唯一索引。
6、主键更适合那些不容易更改的唯一标识，如自动递增列、身份证号等。
7、在 RBO 模式下，主键的执行计划优先级要高于唯一索引。 两者可以提高查询的速度。


## 12-2：索引的分类

1. 主键索引
2. 单值索引
3. 唯一索引
4. 联合（复合）索引

### 12-2-1：各种索引场景

普通索引：没有任何限制条件的索引，
         该索引可以在任何数据类型中创建。
唯一索引：使用UNIQUE参数可以设置唯一索引。
         创建该索引时，索引列的值必须唯一，
         但允许有空值。通过唯一索引，
         用户可以快速地定位某条记录，
         主键索引是一种特殊的唯一索引。
全文索引：仅可用于 MyISAM 表，
         针对较大的数据，
         生成全文索引耗时耗空间。
空间索引：只能建立在空间数据类型上。
         这样可以提高系统获取空间数据类型的效率。
         仅可用于 MyISAM 表，索引的字段不能为空值。
         使用SPATIAL参数可以设置索引为空间索引。
单列索引：只对应一个字段的索引。
多列索引：在表的多个字段上创建一个索引。
         该索引指向创建时对应的多个字段，
         用户可以通过这几个字段进行查询，
         想使用该索引，
         用户必须使用这些字段中的一个字段。

### 12-2-2：联合索引

Mysql从左到右的使用索引中的字段，
一个查询可以只使用索引中的一部分，
但只能是最左侧部分。
例如索引是key index （a,b,c）。
可以支持a | a,b| a,b,c 3种组合进行查找，
但不支持 b,c进行查找 。
当最左侧字段是常量引用时，索引就十分有效。

#### 12-2-2-2：联合索引失效的条件

创建复合索引时，应该仔细考虑列的顺序。
对索引中的所有列执行搜索或仅对前几列执行搜索时，
复合索引非常有用；
仅对后面的任意列执行搜索时，
复合索引则没有用处。


### 12-1-2：单列索引和联合索引区别

1. 利用索引中的附加列，可以缩小搜索的范围，
   创建复合索引时，应该仔细考虑列的顺序。
   对索引中的所有列执行搜索或仅对前几列执行搜索时，
   复合索引非常有用；仅对后面的任意列执行搜索时，复合索引则没有用处。
   嗯，比如说一个例子吧，
   人名由姓和名构成，假设我要去电话簿查找，首先按姓氏对进行排序，
   然后按名字对有相同姓氏的人进行排序。如果知道姓，这样查找的就快迅速了；
   但如果您只知道名不姓，电话簿将没有用处。
2. 多个单列索引在多条件查询时只会生效第一个索引
   所以多条件联合查询时最好建联合索引

## 12-2：mysql索引的结构

1. B树索引与B+树索引
2. 聚簇索引与非聚簇索引
3. Hash索引
4. 全文索引
5. 空间索引

### 12-2-1：B+树与其他

#### 12-2-1-1：B+树比B树的优势

1. B+树空间利用率更高，可减少I/O次数
   一般来说，索引本身也很大，不可能全部存储在内存中，
   因此索引往往以索引文件的形式存储的磁盘上。这样的话，
   索引查找过程中就要产生磁盘1O消耗。
   而因为B+树的内部节点只是作为索引使用，
   而不像B-树那样每个节点都需要存储硬盘指针。
   也就是说: B+树中每个非叶子节点
   没有指向某个关健字具体信息的指针，
   所以好个节点可以存放更多的关键字数量，
   减少了I/0操作。
2. 增删文件(节点)时，效率更高
   因为B+树的叶子节点包含所有关键字，
   并以有序的链表结构存储，
   这样可很好提高增删效率，
   基于范围查询更好。
3. B+树的查询效率更加稳定
   因为B+树的每次查询过程中，
   都需要遍历从根节点到叶子节点的某条路径。
   所有关键字的查询路径长度相同，
   导致每一次查询的效率相当。

##### 12-2-1-1-1：B树

是一种多路搜索树（并不是二叉的）：
B-树的搜索，从根结点开始，
对结点内的关键字（有序）序列进行二分查找，
如果命中则结束，否则进入查询关键字所属范围的儿子结点；
重复，直到所对应的儿子指针为空，或已经是叶子结点；
关键字集合分布在整颗树中；
任何一个关键字出现且只出现在一个结点中；
搜索有可能在非叶子结点结束；
其搜索性能等价于在关键字全集内做一次二分查找；
自动层次控制；
由于限制了除根结点以外的非叶子结点，
至少含有M/2个儿子，确保了结点的至少利用率。
所以B-树的性能总是等价于二分查找（与M值无关），
也就没有B树平衡的问题；
由于M/2的限制，在插入结点时，
如果结点已满，需要将结点分裂为两个各占M/2的结点；
删除结点时，需将两个不足M/2的兄弟结点合并；

##### 12-2-1-1-2：B+树

B+树只有达到叶子结点才命中（B-树可以在非叶子结点命中），
其性能也等价于在关键字全集做一次二分查找；
所有关键字都出现在叶子结点的链表中（稠密索引），
且链表中的关键字恰好是有序的；
不可能在非叶子结点命中；
非叶子结点相当于是叶子结点的索引（稀疏索引），
叶子结点相当于是存储（关键字）数据的数据层；
更适合文件索引系统；

#### 12-2-1-2：B+树与红黑树比较

1. 更少的查找次数
   复杂度和树高h相关，红黑树的树高h很明显比B+Tee大非常多，
   查找的次数也就更多。
2. 利用磁盘预读特性
   为了减少磁盘IO操作，磁盘往往不是严格按需读取，
   而是每次都会预读。预读过程中，磁盘进行顺序读取，
   顺序读取不需要进行磁盘寻道，
   并且只需要很短的旋转时间，速度会非常快。

#### 12-2-1-3：B+树与hash索引比较

1. 如果是等值查询，那么哈希索引明显有绝对优势，
   因为只需要经过一次算法即可找到相应的键值。
   这个前提是，键值都是唯一的。 
   如果键值不是唯的，就需要先找到该键所在位置，
   然后再根据链表往后扫描，直到找到相应的数据:
2. 如果是范围查询检索，原先是有序的键值，
   经过哈希算法后，有可能变成不连续的了，
   就没办法再利用索引完成范围查询检索:

### 12-2-2：聚簇索引与非聚簇索引概念

聚集索引即索引结构和数据一起存放的索引。主键索引属于聚集索引。
非聚集索引即索引结构和数据分开存放的索引。

#### 12-2-2-1：聚簇索引的优缺点

`一、优点`
    由于数据都是紧密相连，数据库不用从多个数据块中提取数据，
    所以节省了大量的io操作。
`二、缺点`
   1. 对于mysql数据库目前只有innodb数据引擎支持聚簇索引，
      而Myisam并不支持聚簇索引。
   2. 由于数据物理存储排序方式只能有一种，
      所以每个Mysql的表只能有一个聚簇索引。
      一般情况下就是该表的主键。
   3. 为了充分利用聚簇索引的聚簇的特性，
      所以innodb表的主键列尽量选用有序的顺序id，
      而不建议用无序的id，比如uuid这种。

#### 12-2-2-2：非聚簇索引的优缺点

`一、优点`
   更新代价比聚集索引要小，非聚集索引的叶子节点是不存放数据的
`二、缺点`
   非聚集索引也依赖于有序的数据
   可能会二次查询(回表) 
   当查到索引对应的指针或主键后，
   可能还需要根据指针或主键再到数据文件或表中查询。

## 12-3：索引

索引（Index）是帮助 MySQL 高效获取数据的数据结构，是一种排好序的数据结构

### 12-3-1：为什么要用索引（优点）

1. 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。
2. 可以大大加快 数据的检索速度（大大减少的检索的数据量）, 这也是创建索引的最主要的原因。
3. 帮助服务器避免排序和临时表。
4. 将随机IO变为顺序IO
5. 可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。

### 12-3-2：索引这么多优点，为什么不对表中的每一个列创建一个索引呢？（缺点）

1. 当对表中的数据进行增加、删除和修改的时候，
   索引也要动态的维护，这样就降低了数据的维护速度。
2. 索引需要占物理空间，除了数据表占数据空间之外，
   每一个索引还要占一定的物理空间，
   如果要建立聚簇索引，那么需要的空间就会更大。
3. 创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。

### 12-3-3：创建索引原则（使用场景）：

1. `选择唯一性索引`
唯一性索引的值是唯一的，
可以更快速的通过该索引来确定某条记录。
例如，学生表中学号是具有唯一性的字段。
为该字段建立唯一性索引可以很快的确定某个学生的信息。
如果使用姓名的话，可能存在同名现象，从而降低查询速度。
2. `为经常需要排序、分组和联合操作的字段建立索引`
经常需要ORDER BY、GROUP BY、DISTINCT和UNION等操作的字段，
排序操作会浪费很多时间。如果为其建立索引，可以有效地避免排序操作。
3. `为常作为查询条件的字段建立索引`
如果某个字段经常用来做查询条件，
那么该字段的查询速度会影响整个表的查询速度。
因此，为这样的字段建立索引，可以提高整个表的查询速度。
4. `限制索引的数目`
索引的数目不是越多越好。
每个索引都需要占用磁盘空间，索引越多，
需要的磁盘空间就越大。
修改表时，对索引的重构和更新很麻烦。
越多的索引，会使更新表变得很浪费时间。
5. `尽量使用数据量少的索引`
如果索引的值很长，那么查询的速度会受到影响。
例如，对一个CHAR(100)类型的字段
进行全文检索需要的时间肯定要
比对CHAR(10)类型的字段需要的时间要多。
1. `尽量使用前缀来索引`
如果索引字段的值很长，最好使用值的前缀来索引。
例如，TEXT和BLOG类型的字段，
进行全文检索会很浪费时间。
如果只检索字段的前面的若干个字符，这样可以提高检索速度。
7. `删除不再使用或者很少使用的索引`
表中的数据被大量更新，或者数据的使用方式被改变后，
原有的一些索引可能不再需要。
数据库管理员应当定期找出这些索引，
将它们删除，从而减少索引对更新操作的影响。
8. `最左前缀匹配原则`。
mysql会一直向右匹配
直到遇到范围查询(>、<、between、like)就停止匹配，
比如a 1=”” and=”” b=”2” c=”“> 3 and d = 4 
如果建立(a,b,c,d)顺序的索引，
d是用不到索引的，
如果建立(a,b,d,c)的索引则都可以用到，
a,b,d的顺序可以任意调整。
9. `=和in可以乱序。`
比如a = 1 and b = 2 and c = 3 
建立(a,b,c)索引可以任意顺序，
mysql的查询优化器会帮你优化成索引可以识别的形式
10. `尽量选择区分度高的列作为索引。`
区分度的公式是count(distinct col)/count(*)，
表示字段不重复的比例，
比例越大我们扫描的记录数越少，
11.  `索引列不能参与计算，保持列“干净”。`
b+树中存的都是数据表中的字段值，
但进行检索时，需要把所有元素都应用函数才能比较，
显然成本太大。
12.  `尽量的扩展索引，不要新建索引。`
比如表中已经有a的索引，
现在要加(a,b)的索引，那么只需要修改原来的索引即可
因为选择索引的最终目的是为了使查询的速度变快。

#### 12-3-3：最左前缀原则内部原理

修改


### 12-3-4：创建索引的注意事项

1. 限制表上的索引数目。
2. 避免在取值朝一个方向增长的字段（例如：日期类型的字段）上，
   建立索引；对复合索引，避免将这种类型的字段放置在最前面。
   由于字段的取值总是朝一个方向增长，
   新记录总是存放在索引的最后一个叶页中，
   从而不断地引起该叶页的访问竞争、新叶页的分配、中间分支页的拆分。
   此外，如果所建索引是聚集索引，表中数据按照索引的排列顺序存放，
   所有的插入操作都集中在最后一个数据页上进行，从而引起插入“热点”。
3. 对复合索引，按照字段在查询条件中出现的频度建立索引。
   在复合索引中，记录首先按照第一个字段排序。
   对于在第一个字段上取值相同的记录，
   系统再按照第二个字段的取值排序，以此类推。
   因此只有复合索引的第一个字段出现在查询条件中，
   该索引才可能被使用。因此将应用频度高的字段，
   放置在复合索引的前面，
   会使系统最大可能地使用此索引，发挥索引的作用。
4. 删除不再使用，或者很少被使用的索引。表中的数据被大量更新，
   或者数据的使用方式被改变后，原有的一些索引可能不再被需要。
   数据库管理员应当定期找出这些索引，将它们删除，
   从而减少索引对更新操作的影响。

### 12-3-5：索引失效

1. like 以%开头，索引无效；当like前缀没有%，后缀有%时，索引有效。
    主要是因为MYSQL索引失效会变成全表扫描的操作
2. or语句前后没有同时使用索引。
   当or左右查询字段只有一个是索引，
   该索引失效，只有当or左右查询字段均为索引时，才会生效
3. 组合索引，不是使用第一列索引，索引失效。
4. 数据类型出现隐式转化。
   如varchar不加单引号的话可能会自动转换为int型，
   使索引无效，产生全表扫描。
5. 在索引列上使用IS NULL 或IS NOT NULL操作。
   索引是不索引空值的，所以这样的操作不能使用索引，
   可以用其他的办法处理，
   例如：数字类型，判断大于0，字符串类型设置一个默认值，
   判断是否等于默认值即可。
6. 在索引字段上使用not，<>，!=。
   不等于操作符是永远不会用到索引的，
   因此对它的处理只会产生全表扫描。
   优化方法： key<>0 改为 key>0 or key<0。
7. 对索引字段进行计算操作、字段上使用函数。（索引为 emp(ename,empno,sal)）
8. 当全表扫描速度比索引速度快时，mysql会使用全表扫描，此时索引失效。

### 12-3-7：为什么索引能够提高查询速度

修改

### 12-3-8：创建索引的三种方式

```java
#方法一：创建表时
    　　CREATE TABLE 表名 (
                字段名1  数据类型 [完整性约束条件…],
                字段名2  数据类型 [完整性约束条件…],
                [UNIQUE | FULLTEXT | SPATIAL ]   INDEX | KEY
                [索引名]  (字段名[(长度)]  [ASC |DESC]) 
                );
       
       CREATE TABLE t(
                        c1 INT PRIMARY KEY,
                        c2 INT NOT NULL,
                        c3 INT NOT NULL,
                        c4 VARCHAR(10),
                        INDEX (c2,c3) 
                     );

#方法二：CREATE在已存在的表上创建索引
        CREATE  [UNIQUE | FULLTEXT | SPATIAL ]  INDEX  索引名 
                     ON 表名 (字段名[(长度)]  [ASC |DESC]) ;
        
        CREATE INDEX index_name ON table_name (column_list)

#方法三：ALTER TABLE在已存在的表上创建索引
        ALTER TABLE 表名 ADD  [UNIQUE | FULLTEXT | SPATIAL ] INDEX
                             索引名 (字段名[(长度)]  [ASC |DESC]) ;

         alter table table_name add index index_name (column_list) ;    

#删除索引：DROP INDEX 索引名 ON 表名字;
```

# 13.优化方案

## 13-1：explain

通过expalin就能知道MySQL是如何处理你的SQL语句的。
分析你的查询语句或是表结构的性能瓶颈

### 13-1-1：explain应用场景

1. 表的读取顺序
2. 哪些索引可以使用
3. 数据读取操作的操作类型
4. 哪些索引被实际使用
5. 表之间的引用
6. 每张表有多少行被优化器查询

### 13-1-2：如何使用explain

explain关键字+sql语句

### 13-1-3：explain主要包含的信息

#### 13-1-3-0：主要包含信息

   id   select_type    table     partitions
   type possible_keys  key       key_len
   ref  rows           filtered  extra

#### 21-4-1：id

表示查询中执行 select子句 或 操作表 的顺序
`id越大，优先级越高`
一般的话，就得看sql的执行顺序

   1. 情形一
    ```sql
    EXPLAIN
    SELECT * 
    FROM `departments`,`employees`
    WHERE `departments`.`department_id`=`employees`.`department_id`
    AND `departments`.`manager_id`=`employees`.`manager_id`;
    ```
    最后的结果两个表是一起执行
    ```sql
    id	 select_type	  table	   
    1	   SIMPLE	   departments
    1	   SIMPLE	   employees	
    ```
   2. 情形二

    ```sql
    EXPLAIN
    SELECT *
    FROM `departments`
    WHERE `location_id`<(
             SELECT `location_id`
             FROM `employees`
             WHERE `department_id`=90

    );
    ```
    由于存在了子查询，那么必须查到`employees`才可以
    
    ```sql
    id	   select_type	      table	
    1	      PRIMARY	      departments	
    2	      SUBQUERY	      employees
    ```

#### 21-4-2：select_type

## 13-2：为什么要优化

1. 避免网站页面出现访问错误
   由于慢查询造成页面无法加载
   由于阻塞造成数据无法提交
   增加数据库的稳定性
2. 很多数据库问题都是由于低效的查询引起的

## 13-3：数据库的优化（如果mysql数据过多，如何进行处理）

1. `限定数据的范围`
务必禁止不带任何限制数据范围条件的查询语句。
比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内；
2. `读/写分离`
经典的数据库拆分方案，主库负责写，从库负责读；
3. `垂直分区`
根据数据库里面数据表的相关性进行拆分。 
4. `水平分区`
保持数据表结构不变，通过某种策略存储数据分片。
这样每一片数据分散到不同的表或者库中，
达到了分布式的目的。 
水平拆分可以支撑非常大的数据量。

注意：`垂直分区与水平分区`去看*分库分表*

## 13-4：索引优化

1、建立聚集索引
首先聚合索引是提升查询速度的最有效的手段。
基于聚合索引的性质可以知道
数据库的物理存储顺序是按照聚合索引顺序排列的，
而通过聚合索引的B+树，我们可以迅速
的查找到任何一行的全部信息。
2、常查询数据建立索引或者组合索引
3、最左前缀原则
建立组合索引优化查询语句时，一定要考虑到最左前缀原则，否则你的索引建立的可以说毫无意义
4、较长的数据列建立前缀索引;
5、不要建立无意义的索引
对于查询次数很少的语句中的字段的索引、备注描述和大字段的索引等

## 13-5：查询优化

1、使用 Explain进行分析
Explain用来分析SELECT 查询语句，开发人员可以通过分析Explain结果者傥化参驾调
句。
比较重要的字段有:
select_type:查询类型，有简单查询、联合查询、子查询等
key:使用的索引
rows:扫描的行数
2、优化数据访问
（1）减少请求的数据量
只返回必要的列:最好不要使用SELECT*语句。
只返回必要的行:使用 LIMIT 语句来限制返回的数据。
缓存重复查询的数据:使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被
重复查询时，缓存带来的查询性能提升将会是非常明显的。
（2）减少服务器端扫描的行数
最有效的方式是使用索引来覆盖查询。
3、重构查询方式
（1）切分大查询
一个大查询如果一次性执行的话，可能一次锁住很多数据、耗尽系统资源、阻塞很多小的但重要的查询。
DELETE FROM messages WHERE create <DATE sLIB(NOWoINTERVAL 3 MONTH);
rows_affected= O
do {
rows_affected= do_query(
"DELETEFROM messages WHEREcreate<DATE SUB(NOWO.INTERVAL 3 MONTH)
LIMIT10000")
}while rows_affected>0
(2）分解大连接查询
将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样
做的好处有:
让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。
而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。
分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记
录的查询。

## 13-6：慢查询优化

1. 索引没起作用的情况
       1. 使用LIKE关键字的查询语句
          在使用LIKE关键字进行查询的查询语句中，
          如果匹配字符串的第一个字符为“%”，
          索引不会起作用。只有“%”不在第一个位置索引才会起作用。
       2. 使用多列索引的查询语句
          MySQL可以为多个字段创建索引。
          一个索引最多可以包括16个字段。
          对于多列索引，
          只有查询条件使用了
          这些字段中的第一个字段时
          索引才会被使用。
2. 优化数据库结构
      合理的数据库结构不仅可以
      使数据库占用更小的磁盘空间，
      而且能够使查询速度更快。
      数据库结构的设计，
      需要考虑数据冗余、
      查询和更新的速度、
      字段的数据类型是否合理等多方面的内容。
      1. 将字段很多的表分解成多个表 
         对于字段比较多的表，如果有些字段的使用频率很低，
         可以将这些字段分离出来形成新表。
         因为当一个表的数据量很大时，
         会由于使用频率低的字段的存在而变慢。
      2. 增加中间表
         对于需要经常联合查询的表，
         可以建立中间表以提高查询效率。
         通过建立中间表，
         把需要经常联合
         查询的数据插入到中间表中，
         然后将原来的联合查询
         改为对中间表的查询，
         以此来提高查询效率。
3. 分解关联查询
   将一个大的查询分解为多个小查询是很有必要的。
   很多高性能的应用都会对关联查询进行分解，
   就是可以对每一个表进行一次单表查询，
   然后将查询结果在应用程序中进行关联，
   很多场景下这样会更高效，  
4. 优化LIMIT分页

## 13-7：创建时优化

1. 数据类型优化
   1. 尽量使用对应的数据类型。
      比如，不要用字符串类型保存时间，用整型保存IP。
   2. 选择更小的数据类型。能用TinyInt不用Int。
   3. 标识列（identifier column），
      建议使用整型，不推荐字符串类型，
      占用更多空间，而且计算速度比整型慢。
   4. 不推荐ORM系统自动生成的Schema，
      通常具有不注重数据类型，
      使用很大的VarChar类型，索引利用不合理等问题。
   5. 真实场景混用范式和反范式。
      冗余高查询效率高，插入更新效率低；
      冗余低插入更新效率高，查询效率低。
   6. 创建完全的独立的汇总表\缓存表，
      定时生成数据，用于用户耗时时间长的操作。
      对于精确度要求高的汇总操作，
      可以采用 历史结果+最新记录的结果 来达到快速查询的目的。
   7. 数据迁移，表升级的过程中可以使用影子表的方式，
      通过修改原表的表名，达到保存历史数据，
      同时不影响新表使用的目的。
2. 索引优化
   注意每种索引的适用范围和适用限制。
   索引的列如果是表达式的一部分或者是函数的参数，则失效。
   针对特别长的字符串，可以使用前缀索引，根据索引的选择性选择合适的前缀长度。
   使用多列索引的时候，可以通过 AND 和 OR 语法连接。
   重复索引没必要，如（A，B）和（A）重复。
   索引在where条件查询和group by语法查询的时候特别有效。
   将范围查询放在条件查询的最后，防止范围查询导致的右边索引失效的问题。
   索引最好不要选择过长的字符串，而且索引列也不宜为null。

## 13-7：一条SQL语句执行得很慢的原因有哪些

要分两种情形：

1. 大多数情况是正常的，只是偶尔会出现很慢的情况。
   
   * 数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘。
      
      当我们要往数据库插入一条数据、或者要更新一条数据的时候，
      我们知道数据库会在内存中把对应字段的数据更新了，但是更新之后，
      这些更新的字段并不会马上同步持久化到磁盘中去，
      而是把这些更新的记录写入到 redo log 日记中去，等到空闲的时候，
      在通过 redo log 里的日记把最新的数据同步到磁盘中去。

      当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。
      比如说：
       1. redolog写满了：redo log 里的容量是有限的，
          如果数据库一直很忙，更新又很频繁，这个时候 redo log 很快就会被写满了，
          这个时候就没办法等到空闲的时候再把数据同步到磁盘的，只能暂停其他操作，
          全身心来把数据同步到磁盘中去的，而这个时候，
          就会导致我们平时正常的SQL语句突然执行的很慢，
          所以说，数据库在在同步数据到磁盘的时候，就有可能导致我们的SQL语句执行的很慢了。

       2. 内存不够用了：如果一次查询较多的数据，恰好碰到所查数据页不在内存中时，
          需要申请内存，而此时恰好内存不足的时候就需要淘汰一部分内存数据页，
          如果是干净页，就直接释放，如果恰好是脏页就需要刷脏页。

       3. MySQL 认为系统“空闲”的时候：这时系统没什么压力。

       4. MySQL 正常关闭的时候：这时候，MySQL 会把内存的脏页都 flush 到磁盘上，
         这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。

   * 执行的时候，遇到锁，如表锁、行锁。

2. 在数据量不变的情况下，这条SQL语句一直以来都执行的很慢。
   
   * 没有用上索引
   * 数据库选错了索引

### 13-7-1：为什么数据库会选错了索引

系统在执行的时候，会进行预测，
是走 c 索引扫描的行数少，
还是直接扫描全表扫描的行数少
扫描全表的话，那么扫描的次数就是这个表的总行数了，
假设为 n；而如果走索引c的话，
我们通过索引c找到主键之后，
还得再通过主键索引来找我们整行的数据，
需要走两次索引，
而且，我们也不知道符合
这个条件的数据有多少行，
万一真的是n条，
那就惨了，
所以系统是有可能走全表扫描而不走索引的
系统如何进行预判
主要依赖于索引的区分度来判断的，
一个索引上不同的值越多，
意味着出现相同数值的索引越少，
意味着索引的区分度越高。
这个区分度也叫做基数，
系统当然是不会遍历全部来
获得一个索引的基数的，
代价太大了，
索引系统是通过遍历部分数据，
也就是通过采样的方式，
来预测索引的基数的
那么出现失误的地方就是采样，
比如采样的那一部分数据刚好基数很小，
然后就误以为索引的基数很小。
然后，系统就不走索引了，
直接走全部扫描了。
主要是由于统计的失误，
导致系统没有走索引，
而是走了全表扫描。

# 14.慢查询

它用来记录在MySQL中响应时间超过阀值的语句日志记录

# 15.主从复制

## 15-1：什么是主从复制

主从复制，是用来建立一个和主数据库完全一样的数据库环境，
称为从数据库；主数据库一般是准实时的业务数据库。

## 15-2：主从复制的作用（好处，或者说为什么要做主从）：

1、做数据的热备，作为后备数据库，主数据库服务器故障后，
   可切换到从数据库继续工作，避免数据丢失。
2、架构的扩展。业务量越来越大，I/O访问频率过高，
  单机无法满足，此时做多库的存储，降低磁盘I/O访问的频率，
  提高单个机器的I/O性能。
3、读写分离，使数据库能支撑更大的并发。
   在报表中尤其重要。由于部分报表sql语句非常的慢，
   导致锁表，影响前台服务。如果前台使用master，
   报表使用slave，
   那么报表sql将不会造成前台锁，保证了前台速度。

## 15-3：主从复制的原理（重中之重，面试必问）

步骤一：主库db的更新事件(update、insert、delete)被写到binlog
步骤二：从库发起连接，连接到主库
步骤三：此时主库创建一个binlog dump thread，把binlog的内容发送到从库
步骤四：从库启动之后，创建一个I/O线程，
       读取主库传过来的binlog内容并写入到relay log
`具体需要三个线程来操作：`
binlog输出线程。每当有从库连接到主库的时候，
主库都会创建一个线程然后发送binlog内容到从库。
在从库里，当复制开始的时候，
从库就会创建两个线程进行处理：
从库I/O线程。当START SLAVE语句在从库开始执行之后，
从库创建一个I/O线程，
该线程连接到主库并请求主库
发送binlog里面的更新记录到从库上。
从库I/O线程读取主库的binlog输出线程
发送的更新并拷贝这些更新到本地文件，
其中包括relay log文件。
从库的SQL线程。
从库创建一个SQL线程，
这个线程读取从库I/O线程
写到relay log的更新事件并执行。

## 15-4：主从复制的几种方式

1. 同步复制，意思是master的变化，
   必须等待slave-1,slave-2,...,slave-n完成后才能返回。
   不会使用，比如，在WEB前端页面上，用户增加了条记录，
   需要等待很长时间。
2. 异步复制:如同AJAX请求一样。
   master只需要完成自己的数据库操作即可。
   至于slaves是否收到二进制日志，
   是否完成操作，不用关心,MySQL的默认设置。
3. 半同步复制:master只保证slaves中的一个操作成功，
             就返回，其他slave不管。 
             这个功能，是由google为MySQL引入的。


# 16.阻塞

当多个事务都需要对某一资源进行锁定时，
默认情况下会发生阻塞。
被阻塞的请求会一直等待，
直到原来的事务释放相关的锁。
锁定超时期限可以限制，这样就可以限制被
阻塞的请求在超时之前要等待的时间。
比如说
有两个事务
事务A请求资源S1，
事务不对资源S1进行操作
事务A用锁A锁定资源S1，
事务B请求对资源S1进行不兼容的锁定（锁B）,
锁B的请求被阻塞，事务B将进入等待状态
事务A正在释放锁A，事务B等待锁A释放，
事务A的锁A已释放，事务B用锁B锁定资源S1

# 17.数据库池与JDBC

## 17-1：什么是数据库连接池？

因为吧，创建数据库连接是一个很耗时的操作，
也容易对数据库造成安全隐患。
所以，在程序初始化的时候，
集中创建多个数据库连接，并把他们集中管理，
供程序使用，
可以保证较快的数据库读写速度，还更加安全可靠。

### 17-1-1：数据库连接池种类

1, C3P0 C3P0是一个开放源代码的JDBC连接池，
            它在lib目录中与Hibernate[1]一起发布,
            包括了实现jdbc3和jdbc2扩展规范
            说明的Connection 和Statement 池的DataSources 对象。
2,Druid，但它不仅仅是一个数据库连接池，
         它还包含一个ProxyDriver，
         一系列内置的JDBC组件库，一个SQL Parser。

### 17-1-2：传统的连接机制与数据库连接池的运行机制区别

传统统链接: 一般来说，Java应用程序访问数据库的过程是：
　　①装载数据库驱动程序；
　　②通过JDBC建立数据库连接；
　　③访问数据库，执行SQL语句；
　　④断开数据库连接。
使用了数据库连接池的机制：
（1） 程序初始化时创建连接池
（2） 使用时向连接池申请可用连接
（3） 使用完毕，将连接返还给连接池
（4） 程序退出时，断开所有连接，并释放资源

### 17-1-3：说说数据库连接池工作原理

1. 连接池的建立。 
   一般在系统初始化时，连接池会根据系统配置建立，
   并在池中建立几个连接对象，以便使用时能从连接池中获取。
   java 中提供了很多容器类，可以方便的构建连接池，
   例如 Vector（线程安全类），linkedlist 等。
2. 连接池的管理。 
   连接池管理策略是连接池机制的核心，
   连接池内连接的分配和释放对系统的性能有很大的影响。
   主要就是当客户请求数据库连接时，首先查看连接池中是否有空闲连接，
   如果存在空闲连接，则将连接分配给客户使用并作相应处理
   也就是标记该连接为正在使用，引用计数加 1；
   如果没有空闲连接，则查看当前所开的连接数是否已经达到最大连接数，
   如果没有达到最大连接数，就重新创建一个连接给请求的客户；
   如果达到，就按设定的最大等待时间进行等待，
   如果超出最大等待时间，则抛出异常给客户。
   当客户释放数据库连接时，先判断该连接的引用次数是否超过了规定值，
   如果超过了就从连接池中删除该连接，
   并判断当前连接池内总的连接数是否小于最小连接数，
   若小于就将连接池充满；如果没超过就将该连接标记为开放状态，
   可供再次复用。
3. 连接池的关闭。 
   当应用程序退出时，关闭连接池中所有的链接，
   释放连接池相关资源，该过程正好与创建相反。


### 17-1-4：实现方案？

连接池使用集合来进行装载，
返回的Connection是原始Connection的代理，
代理Connection的close方法，
当调用close方法时，不是真正关连接，而是把它代
理的Connection对象放回到连接池中，
等待下一次重复利用。

### 17-1-5：数据库连接池最小连接数和最大连接

`连接池最小连接数`
最小连接数是连接池一直保持的数据连接。
如果应用程序对数据库连接的使用量不大，将会有大量的数据库连接资源被浪费掉。

`连接池最大连接数`
最大连接数是连接池能申请的最大连接数。如果数据连接请求超过此数，后面的数据连接请求将被加入到等待队列中，这会影响之后的数据库操作。

#### 17-1-5-1：最小连接数和最大连接区别



#### 17-1-5-2：最小连接数和最大连接数的设置要考虑到以下几个因素

1. `最小连接数`:是连接池一直保持的数据库连接,
               所以如果应用程序对数据库连接的使用量不大,
               将会有大量的数据库连接资源被浪费.
2. `最大连接数`:是连接池能申请的最大连接数,
               如果数据库连接请求超过次数,
               后面的数据库连接请求将被加入到等待队列中,
               这会影响以后的数据库操作

如果最小连接数与最大连接数相差太大，
那么，最先的连接请求将会获利，
之后超过最小连接数量的连接请求
等价于建立一个新的数据库连接。
不过，这些大于最小连接数的数据库连接
在使用完不会马上被释放，
它将被放到连接池中等待重复使用
或是空闲超时后被释放。


## 17-2：JDBC

### 17-2-1：JDBC数据库连接步骤

1. 注册数据库驱动
2. 建立数据库连接
3. 创建一个Statement
4. 执行SQL语句
5. 处理结果集
6. 关闭数据库连接

### 17-2-2：JDBC原理

JDBC（Java DataBase Connectivity）就是Java数据库连接，就是用Java语言来操作数据库
由SUN提供一套访问数据库的规范（就是一组接口），
并提供连接数据库的协议标准，
然后各个数据库厂商会遵循SUN的规范
提供一套访问自己公司的数据库服务器的API出现。
SUN提供的规范命名为JDBC，
而各个厂商提供的，遵循了JDBC规范的，
可以访问自己数据库的API被称之为驱动！

### 17-2-3：JDBC编程原理

```java
public class TestDB {
    public static void main(String[] args) {
        Connection conn = null;
        Statement stmt = null;
        ResultSet rs = null;
        // MySQL的JDBC连接语句
        // URL编写格式：jdbc:mysql://主机名称：连接端口/数据库的名称?参数=值
        String url = "jdbc:mysql://localhost:3306/student?user=root&password=123456";
        // 数据库执行的语句
        String sql = "insert into stuinfo values('201307020010','zhangsan',21);";//插入一条记录
        //String sql = "create table stuinfo(id char(12),name char(20),age int);";//创建一个表
        // 查询语句
        String cmd = "select * from stuinfo;";
        try {
            Class.forName("com.mysql.jdbc.Driver"); // 加载驱动
            conn = DriverManager.getConnection(url); // 获取数据库连接
            stmt = conn.createStatement(); // 创建执行环境
            stmt.execute(sql); // 执行SQL语句
            // 读取数据
            rs = stmt.executeQuery(cmd); // 执行查询语句，返回结果数据集
            rs.last(); // 将光标移到结果数据集的最后一行，用来下面查询共有多少行记录
            System.out.println("共有" + rs.getRow() + "行记录：");
            rs.beforeFirst(); // 将光标移到结果数据集的开头
            while (rs.next()) { // 循环读取结果数据集中的所有记录
                System.out.println(rs.getRow() + "、 学号:" + rs.getString("id")
                        + "\t姓名:" + rs.getString("name") + "\t年龄:"
                        + rs.getInt("age"));
            }
        } catch (ClassNotFoundException e) {
            System.out.println("加载驱动异常");
            e.printStackTrace();
        } catch (SQLException e) {
            System.out.println("数据库异常");
            e.printStackTrace();
        } finally {
            try {
                if (rs != null)
                    rs.close(); // 关闭结果数据集
                if (stmt != null)
                    stmt.close(); // 关闭执行环境
                if (conn != null)
                    conn.close(); // 关闭数据库连接
            } catch (SQLException e) {
                e.printStackTrace();}}}}
```
#### 17-2-3-1：使用JDBC需要用到哪些类

DirverManager类：是JDBC的管理层，
                 作用bai于用户和驱动之间。
                 该类负责注du册和加载JDBC驱动。
Connection接口：代表与数据库dao的链接，
               并拥有创建SQL语句的方法，
               以完成基本的SQL操作，
               同时为数据库事务提供提交和回滚方法。
Statement接口：用于执行不带参数的简单SQL语句。
               创建Statement实例对象后可以
               调用JDBC提供的3种执行SQL语句的方法：

#### 17-2-3-1：JDBC的DriverManager是用来做什么的？

JDBC的DriverManager是一个工厂类，我们通过它来创建数据库连接。
当JDBC的Driver类被加载进来时，它会自己注册到DriverManager类里面
然后我们会把数据库配置信息传成DriverManager.getConnection()方法，
DriverManager会使用注册到它里面的驱动来获取数据库连接，并返回给调用的程序。

#### 17-2-3-2：statement的实现原理

Statement是用来向数据库发送要执行的SQL语句的

##### 17-2-3-2-1：JDBC中的Statement 和PreparedStatement的区别？

PreparedStatement是预编译的SQL语句，效率高于Statement。
PreparedStatement支持?操作符，相对于Statement更加灵活。
PreparedStatement可以防止SQL注入，安全性高于Statement。
CallableStatement适用于执行存储过程。

##### 17-2-3-2-2：PreparedStatement的缺点是什么，怎么解决这个问题？

PreparedStatement的一个缺点是，我们不能直接用它来执行in条件语句；
需要执行IN条件语句的话，下面有一些解决方案：
分别进行单条查询——这样做性能很差，不推荐。
使用存储过程——这取决于数据库的实现，
不是所有数据库都支持。
动态生成PreparedStatement——这是个好办法，
但是不能享受PreparedStatement的缓存带来的好处了。
在PreparedStatement查询中使用NULL值——
如果你知道输入变量的最大个数的话，这是个不错的办法，
扩展一下还可以支持无限参数。

#### 17-2-3-3：execute，executeQuery，executeUpdate的区别是什么？

`Statement的execute`(String query)方法用来执行任意的SQL查询，
如果查询的结果是一个ResultSet，这个方法就返回true。
如果结果不是ResultSet，比如insert或者
update查询，它就会返回false。
我们可以通过它的getResultSet方法来获取ResultSet，
或者通过getUpdateCount()方法来获取更新的记录条数。
`Statement的executeQuery`(String query)接口用来执行select查询，
并且返回ResultSet。即使查询不到记录返回的ResultSet也不会为null。
我们通常使用executeQuery来执行查询语句，
这样的话如果传进来的是insert或者update语句的话，
它会抛出错误
`Statement的executeUpdate`(String query)方法用来执行
insert或者update/delete（DML）语句，
或者什么也不返回DDL语句。返回值是int类型，
如果是DML语句的话，它就是更新的条数，
如果是DDL的话，就返回0。
只有当你不确定是什么语句的时候才应该使用execute()方法，
否则应该使用executeQuery或者executeUpdate方法。

#### 17-2-3-4：JDBC的ResultSet是什么?

在查询数据库后会返回一个ResultSet，
它就像是查询结果集的一张数据表。
ResultSet对象维护了一个游标，
指向当前的数据行。
开始的时候这个游标指向的是第一行。
如果调用了ResultSet的next()方法游标会下移一行，
如果没有更多的数据了，next()方法会返回false。
可以在for循环中用它来遍历数据集。
默认的ResultSet是不能更新的，
游标也只能往下移。
也就是说你只能从第一行到最后一行遍历一遍。
不过也可以创建可以回滚或者可更新的ResultSet
当生成ResultSet的Statement对象
要关闭或者重新执行或是获取下一个ResultSet的时候，
ResultSet对象也会自动关闭。
可以通过ResultSet的getter方法，
传入列名或者从1开始的序号来获取列数据。

##### 17-2-3-4-1：有哪些不同的ResultSet？

一共有三种ResultSet对象。

1. ResultSet.TYPE_FORWARD_ONLY：
   这是默认的类型，它的游标只能往下移。
2. ResultSet.TYPE_SCROLL_INSENSITIVE：
   游标可以上下移动，一旦它创建后，
   数据库里的数据再发生修改，对它来说是透明的。
3. ResultSet.TYPE_SCROLL_SENSITIVE：
   游标可以上下移动，
   如果生成后数据库还发生了修改操作，
   它是能够感知到的。

##### 17-2-3-4-2：JDBC的RowSet是什么，

RowSet用于存储查询的数据结果，和ResultSet相比，它更具灵活性。
RowSet继承自ResultSet，因此ResultSet能干的，它们也能，
而ResultSet做不到的，它们还是可以。RowSet接口定义在javax.sql包里。

##### 17-2-3-4-3：有哪些不同的RowSet？

A. 连接型RowSet——这类对象与数据库进行连接，
    和ResultSet很类似。
    JDBC接口只提供了一种连接型RowSet，
B. 离线型RowSet——这类对象不需要和数据库进行连接，
   因此它们更轻量级，更容易序列化。
   它们适用于在网络间传递数据。
有四种不同的离线型RowSet的实现。
CachedRowSet——可以通过他们获取连接，
              执行查询并读取ResultSet的数据到RowSet里。
              我们可以在离线时对数据进行维护和更新，
              然后重新连接到数据库里，并回写改动的数据。
WebRowSet继承自CachedRowSet——他可以读写XML文档。
JoinRowSet继承自WebRowSet——它不用连接数据库就可以执行SQL的join操作。
FilteredRowSet继承自WebRowSet——我们可以用它来设置过滤规则，这样只有选中的数据才可见。

##### 17-2-3-4-2：ResultSet有两种并发类型。

1. ResultSet.CONCUR_READ_ONLY:
   ResultSet是只读的，这是默认类型。
2. ResultSet.CONCUR_UPDATABLE:
   我们可以使用ResultSet的更新方法来更新里面的数据。

#### 17-2-3-5：JDBC的DataSource是什么，有什么好处

跟DriverManager相比，它的功能要更强大。
我们可以用它来创建数据库连接，
当然驱动的实现类会实际去完成这个工作。
除了能创建连接外，还能够提供
1. 缓存PreparedStatement以便更快的执行
2. 可以设置连接超时时间
3. 提供日志记录的功能
4. ResultSet大小的最大阈值设置
5. 通过JNDI的支持，可以为servlet容器提供连接池的功能

##### 17-2-3-5-1：如何通过JDBC的DataSource和Apache Tomcat的JNDI来创建连接池？

在META-INF目录下配置context.xml文件
导入Mysql或oracle开发包到tomcat的lib目录下
初始化JNDI->获取JNDI容器->检索以XXX为名字在JNDI容器存放的连接池

#### 17-2-3-6：java.util.Date和java.sql.Date有什么区别？

java.util.Date包含日期和时间，
java.sql.Date只包含日期信息，而没有具体的时间信息。
如果你想把时间信息存储在数据库里，可以考虑使用Timestamp或者DateTime字段

#### 17-2-3-7：SQLWarning是什么，在程序中如何获取SQLWarning？

SQLWarning是SQLException的子类，
通过Connection, Statement, Result的getWarnings
方法都可以获取到它。 
SQLWarning不会中断查询语句的执行，
只是用来提示用户存在相关的警告信息。

#### 17-2-3-8：如果java.sql.SQLException: No suitable driver found该怎么办？

如果你的SQL URL串格式不正确的话，就会抛出这样的异常。
不管是使用DriverManager还是JNDI数据源来创建连接都有可能抛出这种异常。

### 17-2-4：JDBC事务

#### 17-2-4-1：Java中如何进行事务的处理?

Connection类中提供了4个事务处理方法:

setAutoCommit(Boolean autoCommit):设置是否自动提交事务,默认为自动提交,即为true,
                                  通过设置false禁止自动提交事务;
commit():提交事务;
rollback():回滚事务.
savepoint:保存点，savepoint不会结束当前事务，
                 普通提交和回滚都会结束当前事务的


### 17-2-5：JDBC中大数据量的分页解决方法?

最好的办法是利用sql语句进行分页，
这样每次查询出的结果集中就只包含某页的数据内容。

### 17-2-6：常见的JDBC异常有哪些

`java.sql.SQLException`
     这是JDBC异常的基类。
`java.sql.BatchUpdateException`
     当批处理操作执行失败的时候可能会抛出这个异常。
     这取决于具体的JDBC驱动的实现，
     它也可能直接抛出基类异常java.sql.SQLException。
`java.sql.SQLWarning`
     SQL操作出现的警告信息。
`java.sql.DataTruncation`
      字段值由于某些非正常原因被截断了
      （不是因为超过对应字段类型的长度限制）。

### 17-2-7：JDBC中存在哪些不同类型的锁?

乐观锁——只有当更新数据的时候才会锁定记录。
悲观锁——从查询到更新和提交整个过程都会对数据记录进行加锁。



# 18.分库分表

## 18-1：为什么要分库分表？（看法）

数据库数据会随着业务的发展而不断增多，
因此数据操作，如增删改查的开销也会越来越大。
再加上物理服务器的资源有限（CPU、磁盘、内存、IO 等）。
最终数据库所能承载的数据量、数据处理能力都将遭遇瓶颈。
也就是说需要合理的数据库架构来存放不断增长的数据，
这个就是分库分表的设计初衷。
目的就是为了缓解数据库的压力，最大限度提高数据操作的效率。

## 18-2：数据分表

如果单表的数据量过大，
例如千万级甚至更多，那么在操作表的时候就会加大系统的开销。
每次查询会消耗数据库大量资源，
如果需要多表的联合查询，这种劣势就更加明显了。
比如说MySQL来说，在插入数据的时候，会对表进行加锁，分为表锁定和行锁定。
无论是哪种锁定方式，都意味着前面一条数据在操作表或者行的时候，
后面的请求都在排队，当访问量增加的时候，都会影响数据库的效率。

### 18-2-1：垂直分表

就是说，根据业务把一个表中的字段（Field）分到不同的表中。
这些被分出去的数据通常根据业务需要，
例如分出去一些不是经常使用的字段，一些长度较长的字段。
一般被拆分的表的字段数比较多。
主要是避免查询的时候出现因为数据量大而造成的“跨页”问题。
一般这种拆分在数据库设计之初就会考虑，
尽量在系统上线之前考虑调整。已经上线的项目，做这种操作是要慎重考虑的。

#### 18-2-1-1：垂直切分解决了什么问题

垂直切分可以降低单节点数据库的负载。
原来所有数据表都放在一个数据库节点上，
所有的读写请求也都发到这个MySQL上面，
所以数据库的负载太高。
如果把一个节点的数据库拆分成多个MySQL数据库，
这样就可以有效的降低每个MySQL数据库的负载。

#### 18-2-1-2：垂直切分不能解决什么问题

垂直切分不能解决的是缩表，
比如说商品表无论划分给哪个数据库节点，
商品表的记录还是那么多，
不管你把数据库垂直拆分的有多细致，
每个数据表里面的数据量是没有变化的。
MySQL单表记录超过2000万，
读写性能会下降的很快，
因此说垂直切分并不能起到缩表的效果。

### 18-2-2：水平分表

将一个表中的数据，按照关键字（例如：ID）（或取 Hash 之后）
对一个具体的数字取模，得到的余数就是需要存放到的新表的位置。
用这种方式存放数据以后，在访问具体数据的时候需要
通过一个 Mapping Table 获取对应要响应的数据来自哪个数据表

#### 18-2-2-1：水平切分的用途

水平切分可以把数据切分到多张数据表，
可以起到缩表的作用。
但是也不是所有的数据表都要做水平切分。
数据量较大的数据表才需要做数据切分，
比如说电商系统中的，
用户表、商品表、产品表、地址表、订单表等等。
有些数据表就不需要切分，
因为数据量不多，
比如说品牌表、供货商表、仓库表，这些都是不需要切分的。

#### 18-2-2-2：水平切分的缺点

扩容比较麻烦，日积月累，分片迟早有不够用的时候。
这时候不是首先选择增加新的集群分片。
因为一个MySQL分片，需要4~8个MySQL节点（最小规模），
增加一个分片的投入成本是很高的。

### 18-2-3：为什么先做水平切分，后作垂直切分？

随着数据量的增加，
最先应该做的是数据分片，
利用多块硬盘来增大数据IO能力和存储空间，
这么做的成本是最低的。几块硬盘的钱就能收获不错的IO性能。
进入到下一个阶段，数据量继续增大，
这时候我们应该把数据切分到多个MySQL节点上，
用MyCat管理数据切分。当然还要做数据的读写分离等等，
在后台做水平切分的同时，业务系统也可以引入负载均衡、分布式架构等等。
理论上，使用了冷热数据分离之后，
水平切分这种方式可以继续维持很长一段时间，
数据量再大也不怕，定期归档就好了。
数据库到了水平切分的阶段，
数据量的增加已经不是更改架构设计的主要原因了。
反而这个阶段业务系统承受不住了，如果再不对系统做模块拆分，
业务系统也撑不下去了，所以按照模块和业务，
把一个系统拆分成若干子系统。若干子系统之间，
数据相对独立。比如淘宝不会跟支付支付宝分享全部数据，
共享同一套数据表，这也影响各自业务的发展。
所以就要弄垂直切分了，
把数据表归类，拆分成若干个数据库系统。
如果过早的对数据库做了垂直切分，
势必要重新构建若干独立的业务系统，
工作量太巨大。
水平切分并不需要业务系统做大幅度的修改，
因此说应该先从水平切分开始做。

## 18-3：数据分库

因为每个物理数据库支持数据都是有限的，
每一次的数据库请求都会产生一次数据库链接，
当一个库无法支持更多访问的时候，
我们会把原来的单个数据库分成多个，帮助分担压力。
`比如说：`
根据业务不同分库，这种情况都会把主营业务和其他功能分开。
例如可以分为订单数据库，核算数据库，评论数据库。
根据冷热数据进行分库，用数据访问频率来划分，
例如：近一个月的交易数据属于高频数据，
2-6 个月的交易数据属于中频数据，
大于 6 个月的数据属于低频数据。
根据访问数据的地域/时间范围进行分库。
通常数据分库之后，每一个数据库包含多个数据表，
多个数据库会组成一个 Cluster/Group，
提高了数据库的可用性，并且可以把读写做分离。
Master 库主要负责写操作，Slave 库主要负责读操作。
在应用访问数据库的时候会通过一个负载均衡代理，
通过判断读写操作把请求路由到对应的数据库。
如果是读操作，也会根据数据库设置的权重或者平均分配请求。
另外，还有数据库健康监控机制，定时发送心跳检测数据库的健康状况。
如果 Slave 出现问题，会启动熔断机制停止对其的访问；
如果 Master 出现问题，通过选举机制选择新的 Master 代替。

## 18-4：数据库的扩容

### 18-4-1：为什么要数据库扩容

分库之后的数据库会遇到数据扩容或者数据迁移的情况。

### 18-4-2：主从数据库扩容

假设有两个数据库集群，每个集群分别有 M1 S1 和 M2 S2 互为主备。
由于 M1 和 S1 互为主备所以数据是一样的，
M2 和 S2 同样。把原有的 ID %2 模式切换成 ID %4 模式，
也就是把两个数据集群扩充到 4 个数据库集群。
负载均衡器直接把数据路由到原来两个 S1 和 S2 上面，
同时 S1 和 S2 会停止与 M1 和 M2 的数据同步，
单独作为主库（写操作）存在。
这些修改不需要重启数据库服务，
只需要修改代理配置就可以完成。
由于 M1 M2 S1 S2 中会存在一些冗余的数据，
可以后台起服务将这些冗余数据删除，不会影响数据使用。
此时，再考虑数据库可用性，将扩展后的 4 个主库进行主备操作，
针对每个主库都建立对应的从库，
前者负责写操作，后者负责读操作。
下次如果需要扩容也可以按照类似的操作进行。

### 18-4-3：双写数据库扩容

在没有数据库主从配置的情况下的扩容，假设有数据库M1 M2 
需要对目前的两个数据库做扩容，
扩容之后是4个库
新增的库是 M3，M4 路由的方式分别是 ID%2=0 和 ID%2=1。
这个时候新的数据会同时进入 M1 M2 M3 M4 四个库中，
而老数据的使用依旧从 M1 M2 中获取。
与此同时，后台服务对 M1 M3，M2 M4 做数据同步，
可以先做全量同步再做数据校验。
当完成数据同步之后，四个库的数据保持一致了，
修改负载均衡代理的配置为 ID%4 的模式。
此时扩容就完成了，从原来的 2 个数据库扩展成 4 个数据库。
当然会存在部分的数据冗余，
需要像上面一个方案一样通过后台服务删除这些冗余数据，
删除的过程不会影响业务。

## 18-5：分库分表，id如何处理（04期还没有看完）

**方式1——数据库自增id** 
   系统里每次得到一个 id，
   都是往一个库的一个表里
   插入一条没什么业务含义的数据，
   然后获取一个数据库自增的一个id。
   拿到这个 id 之后再往对应的分库分表里去写入。
`好处`
   就是方便简单，谁都会用；
`缺点`
   就是单库生成自增 id，要是高并发的话，就会有瓶颈的；
`改进`
   那么就专门开一个服务出来，
   这个服务每次就拿到当前 id 最大值，
   然后自己递增几个 id，
   一次性返回一批 id，
   然后再把当前最大 id 值
   修改成递增几个 id 之后的一个值；
   但是无论如何都是基于单个数据库。
`适合的场景`
   要不就是单库并发太高，要不就是单库数据量太大；
   除非是并发不高，
   但是数据量太大导致的分库分表扩容，
   可以用这个方案，
   因为可能每秒最高并发最多就几百，
   那么就走单独的一个库和表生成自增主键即可。
**方式2——设置数据库 sequence 或者表自增字段步长**
   可以通过设置数据库 sequence 或者表的自增字段步长来进行水平伸缩。  
   比如说，现在有 8 个服务节点，
   每个服务节点使用一个 sequence 功能来产生 ID，
   每个 sequence 的起始 ID 不同，并且依次递增，步长都是 8。
 `适合的场景`
   在用户防止产生的 ID 重复时，
   这种方案实现起来比较简单，也能达到性能目标。
   但是服务节点固定，步长也固定，
   将来如果还要增加服务节点，就不好搞了。
**方式3——UUID**
 `好处`
   就是本地生成，不要基于数据库来了；
 `缺点`
   就是，UUID 太长了、占用空间大，
   作为主键性能太差了；更重要的是，
   UUID 不具有有序性，
   会导致 B+ 树索引在写的时候
   有过多的随机写操作
   连续的 ID 可以产生部分顺序写，
   还有，由于在写的时候不能
   产生有顺序的append 操作，
   而需要进行 insert 操作，
   将会读取整个 B+ 树节点到内存，
   在插入这条记录后会将整个节点写回磁盘，
   这种操作在记录占用空间比较大的情况下，
   性能下降明显。
 `适合的场景`
   如果是要随机生成个什么文件名、编号之类的，
   可以用 UUID，但是作为主键是不能用 UUID 的。
**方式4——获取系统当前时间**
   这个就是获取当前时间即可，
   但是问题是，并发很高的时候，
   比如一秒并发几千，会有重复的情况，
   这个是肯定不合适的。基本就不太合适。
 `适合的场景`   
   一般如果用这个方案，
   是将当前时间跟很多其他的业务字段拼接起来，
   作为一个 id，
   将别的业务字段值跟当前时间拼接起来，
   组成一个全局唯一的编号。
**方式5——利用 redis 生成 id** 
   性能比较好，灵活方便，
   不依赖于数据库。但是，
   引入了新的组件造成系统更加复杂
   可用性降低，编码更加复杂，
   增加了系统成本。
**方式6——snowflake 算法** 
是把一个 64 位的 long 型的 id，1 个 bit 是不用的，
用其中的 41 bit 作为毫秒数，
用 10 bit 作为工作机器 id，12 bit 作为序列号。

## 18-6：分库分表如何保证主库和分库的事务性

通过在主库中创建一个流水表，
把操作数据库的逻辑映射为一条流水记录。
当整个大事务执行完毕后（流水被插入到流水表）,
然后通过其他方式来执行这段流水，保证最终一致性。

### 18-6-1：什么是流水（53期）

可以理解为一条事务消息
比如说在数据库中创建一张流水表，
使用一条流水记录代表一个业务处理逻辑，
因此，一个流水一定是能最终正确执行的


### 18-6-2：为什么不用事务消息

由于是既有项目进行改造，使用事务消息
需要额外引入消息队列，增加系统的复杂度，
而且也需要额外的逻辑保证和消息队列通讯失败的时候处理
因为事务消息需要手动的commit和rollback，
在spring中事务是有传递性的，
那我们事务消息何时提交又是个大问题，
例如 A.a()本来就是一个事务， 
但是另外一个事务B.b()中又调用了A.a() 
那事务消息提交是放在A.a()还是B.b()中会产生混乱





