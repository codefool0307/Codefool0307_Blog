# 1.MySQL---概念

## 1-1：为什么要使用数据库

因为文件保存数据存在几点缺陷比如
文件的安全性问题。
文件不利于查询和对数据的管理。
文件不利于存放海量数据
文件在程序中控制不方便
为了解决上述问题，专家们设计出更加利于管理数据的东西，数据库

## 1-2: 什么是SQL？

结构化查询语言
其实就是定义了操作所有关系型数据库的规则

## 1-3：什么是MySQL?

Mysql是一种关系型数据库管理系统，

# 2. 数据库---关系（非关系）

关系型数据库：  指采用了关系模型来组织数据的数据库。
非关系型数据库：指非关系型的，分布式的，且一般不保证遵循ACID原则的数据存储系统。

## 2-1：关系型数据库优缺点

`优点`
1.容易理解：二维表结构是非常贴近逻辑世界的一个概念，
           关系模型相对网状、层次等其他模型来说更容易理解
2.使用方便：通用的SQL语言使得操作关系型数据库非常方便
3.易于维护：丰富的完整性
           实体完整性、参照完整性和用户定义的完整性
           大大减低了数据冗余和数据不一致的概率
`存在的问题`
1.网站的用户并发性非常高，
  往往达到每秒上万次读写请求，
  对于传统关系型数据库来说，硬盘I/O是一个很大的瓶颈
2.网站每天产生的数据量是巨大的，
  对于关系型数据库来说，
  在一张包含海量数据的表中查询，效率是非常低的
3.在基于web的结构当中，
  数据库是最难进行横向扩展的，
  当一个应用系统的用户量和访问量与日俱增的时候，
  数据库却没有办法像web server和app server
  那样简单的通过添加更多的硬件和服务节点来扩展性能和负载能力。
  当需要对数据库系统进行升级和扩展时，往往需要停机维护和数据迁移。
4.性能欠佳：在关系型数据库中，
           导致性能欠佳的最主要原因是多表的关联查询，
           以及复杂的数据分析类型的复杂SQL报表查询。
           为了保证数据库的ACID特性，
           必须尽量按照其要求的范式进行设计，
           关系型数据库中的表都是存储一个格式化的数据结构。

## 2-2：非关系型数据库优缺点

`优点`
1. 用户可以根据需要去添加自己需要的字段，
  为了获取用户的不同信息，不像关系型数据库中，
  要对多表进行关联查询。
  仅需要根据id取出相应的value就可以完成查询。
2. 适用于SNS(Social Networking Services)中，
   例如facebook，微博。系统的升级，功能的增加，
   往往意味着数据结构巨大变动，这一点关系型数据库难以应付，
   需要新的结构化数据存储。
   由于不可能用一种数据结构化存储应付所有的新的需求，
   因此，非关系型数据库严格上不是一种数据库，
   应该是一种数据结构化存储方法的集合。
`不足：`
   只适合存储一些较为简单的数据，
   对于需要进行较复杂查询的数据，
   关系型数据库显的更为合适。不适合持久存储海量数据

## 2-3：非关系型数据库和关系型数据库区别

1.成本：Nosql数据库简单易部署，
       基本都是开源软件，不需要像使用Oracle那样花费大量成本购买使用，
       相比关系型数据库价格便宜。
2.查询速度：Nosql数据库将数据存储于缓存之中，
           而且不需要经过SQL层的解析，
           关系型数据库将数据存储在硬盘中，
           自然查询速度远不及Nosql数据库。
3.存储数据的格式：Nosql的存储格式是key,value形式、文档形式、图片形式等等，
                所以可以存储基础类型以及对象或者是集合等各种格式，
                而数据库则只支持基础类型。
4.扩展性：关系型数据库有类似join这样的多表查询机制的限制导致扩展很艰难。
         Nosql基于键值对，数据之间没有耦合性，所以非常容易水平扩展。
5.持久存储：Nosql不使用于持久存储，海量数据的持久存储，还是需要关系型数据库
6.数据一致性：非关系型数据库一般强调的是数据最终一致性，
              不像关系型数据库一样强调数据的强一致性，
              从非关系型数据库中读到的有可能还是处于一个中间态的数据，
            Nosql不提供对事务的处理。

# 3.数据库---三大范式

## 3-1：数据库三大范式是什么

第一范式: 每个列都不可以再拆分. 
第二范式: 非主键列完全依赖于主键,而不能是依赖于主键的一部分. 
第三范式: 非主键列只依赖于主键,不依赖于其他非主键.

## 3-2：三大范式举例

# 4.数据库---数据类型

## 4-1：mysql的数据类型

整数类型：BIT、BOOL、TINY INT、
         SMALL INT、MEDIUM INT、 
         INT、 BIG INT
浮点数类型：FLOAT、DOUBLE、DECIMAL
字符串类型：CHAR、VARCHAR、TINY TEXT、
           TEXT、MEDIUM TEXT、LONGTEXT、
           TINY BLOB、BLOB、MEDIUM BLOB、LONG BLOB
日期类型：Date、DateTime、TimeStamp、Time、Year

## 4-2：varchar与char的区别

char长度固定，varchar长度可以变化

比如说字符串abc
char（10）就是占用10个字节，
varchar（10）只占用3个字节，10只是最大值

### 4-2-1：varchar(50)中50的涵义

varchar(50)中50的涵义最多存放50个字符

## 4-3：int(20)中20的涵义

int(M)只是用来显示数据的宽度，
比如说int（20），mysql会自动补0

## 4-4：FLOAT和DOUBLE的区别是什么？

1. 在内存中占有的字节数不同
　　单精度浮点数在机内存占4个字节
　　双精度浮点数在机内存占8个字节
2. 有效数字位数不同
　　单精度浮点数有效数字8位
　　双精度浮点数有效数字16位
3. 数值取值范围
4. 在程序中处理速度不同
　　一般来说，CPU处理单精度浮点数的速度比处理双精度浮点数快

## 4-5：MySQL INT和CHAR隐式类型转换需要注意什么？

1. 当查询字段是INT类型，
   如果查询条件为CHAR，
   将查询条件转换为INT，
   如果是字符串前导都是数字，
   将截取前导数字用来比较，
   如果没有前导数字，则转换为0。
2. 当查询字段是CHAR/VARCHAR类型，
   如果查询条件为INT，
   将查询字段转换为INT再进行比较，
   可能会造成全表扫描。

# 5.SQL---生命周期

1. 建立服务器与数据库连接
2. 数据库拿到SQL
3. 解析执行
4. 读取数据到内存，进行业务逻辑处理
5. 发给客户端
6. 关闭连接，释放资源

# 快照读/当前读

### 11-7-1：哪些读操作是快照读？哪些操作又是当前读呢？

快照读： 简单的select操作，属于快照读，不加锁。(当然，也有例外，下面会分析)
select * from table where ?;
当前读： 特殊的读操作，插入/更新/删除操作，属于当前读，需要加锁。
select * from table where ? lock in share mode;
select * from table where ? for update;
insert into table values (…);
update table set ? where ?;
delete from table where ?;
都属于当前读，读取记录的最新版本。并且，
读取之后，还需要保证其他并发事务不能修改当前记录，
对读取记录加锁。除了第一条语句，对读取记录加S锁 (共享锁)外，
其他的操作，都加的是X锁 (排它锁)。

1、select快照读（照片）
  当你执行select *之后，
在A与B事务中都会返回4条一样的数据，当执行select的时候，
innodb默认会执行快照读，相当于就是给你目前的状态找了一张照片，
以后执行select 的时候就会返回当前照片里面的数据，
当其他事务提交了也对你不造成影响，和你没关系，
这就实现了可重复读了，照片不是开启事务的时候生成的，
是当你第一次执行select的时候，也就是说，当A开启了事务，
然后没有执行任何操作，这时候B insert了一条数据然后commit,
这时候A执行 select，那么返回的数据中就会有B添加的那条数据......
之后无论再有其他事务commit都没有关系，因为照片已经生成了，
而且不会再生成了，以后都会参考这张照片。

2、update、insert、delete 当前读
当你执行这几个操作的时候默认会执行当前读，
也就是会读取最新的记录，也就是别的事务提交的数据你也可以看到，
这样很好理解啊，假设你要update一个记录，
另一个事务已经delete这条数据并且commit了，这样不是会产生冲突吗，
所以你update的时候肯定要知道最新的信息啊。
比如说update的过程吧，首先会执行当前读，然后把返回的数据加锁，
之后执行update。加锁是防止别的事务在这个时候对这条记录做什么，
默认加的是排他锁，也就是你读都不可以，这样就可以保证数据不会出错了。
数据库采取了一致性非锁定读，别的事务会去读取一个快照数据。
innodb默认隔离级别是RR， 是通过MVVC来实现了，
读方式有两种，执行select的时候是快照读，其余是当前读，
所以，mvvc不能根本上解决幻读的情况

### 11-7-2：为什么将 插入/更新/删除 操作，都归为当前读

一个Update操作的具体流程。当Update SQL被发给MySQL后，
MySQL Server会根据where条件，读取第一条满足条件的记录，
然后InnoDB引擎会将第一条记录返回，并加锁 (current read)。
待MySQL Server收到这条加锁的记录之后，
会再发起一个Update请求，更新这条记录。
一条记录操作完成，再读取下一条记录，
直至没有满足条件的记录为止。
因此，Update操作内部，就包含了一个当前读。
同理，Delete操作也一样。Insert操作会稍微有些不同，
简单来说，就是Insert操作可能会触发Unique Key的冲突检查，
也会进行一个当前读。


# 6.MySQL---预编译

指的是数据库驱动在发送 sql 语句和参数
给 DBMS 之前对 sql 语句进行编译，
这样 DBMS 执行 sql 时，就不需要重新编译。

## 6-1：预编译出现的原因

1、很多情况下，一条SQL语句可能会反复执行，或者每次执行的时候只有个别的值不同
2、比如query的where条件的值不同，
   update的set的值不同,insert的values值不同，都会造成SQL语句的不同。
3、每次因为这些值的不同就进行词法语义解析、优化、制定执行计划，就会很影响效率。

## 6-2：预编译的好处

1、预编译之后的 SQL 多数情况下可以直接执行，DBMS 不需要再次编译。
2、越复杂的SQL，编译的复杂度将越大，预编译阶段可以合并多次操作为一个操作。
3、相同的预编译 SQL 可以重复利用。
   把一个 SQL 预编译后产生的 PreparedStatement 对象缓存下来，
　 下次对于同一个 SQL，
   可以直接使用这个缓存的 PreparedState 对象。
4、可以将这类SQL语句中的值用占位符替代，不需要每次编译，可以直接执行，
　　只需执行的时候，直接将每次请求的不同的值设置到占位符的位置。
5、预编译可以视为将sql语句模板化或者说参数化。

# ——————————————————————————————————————————————————————————————————————————————————————————————————————————————————————

# ——————————————————————————————————————————————————————————————————————————————————————————————————————————————————————

# 7.SQL---注入

## 7-1：SQL注入简介

通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，
最终达到欺骗服务器执行恶意的SQL命令。
它不是利用操作系统的BUG来实现攻击，
而是针对程序员编程时的疏忽，
通过SQL语句，实现无帐号登录，甚至篡改数据库。

## 7-2：SQL注入攻击实例

  比如在一个登录界面，要求输入用户名和密码：
  可以这样输入实现免帐号登录：
  用户名： ‘or 1 = 1 –
  密 码：空白
  点登陆,如若没有做特殊处理,那么这个非法用户就很得意的登陆进去了.
  从理论上说，后台认证程序中的SQL语句还是很正常的
  ```sql
  String sql = "select * from user_table where username=
  ' "+userName+" ' and password=' "+password+" '";
  ```
  但是当输入了上面的用户名和密码，上面的SQL语句变化了：
  ```SQL
  SELECT * FROM user_table WHERE username=
  '’or 1 = 1 -- and password='’
  ```
  条件后面username=”or 1=1 用户名等于 ” 或1=1 
  那么这个条件一定会成功；
  然后后面加两个-，这意味着注释，
  它将后面的语句注释，
  让他们不起作用，
  这样语句永远都能正确执行，
  用户轻易骗过系统，获取合法身份。

## 7-3：SQL注入解决方案

1. `PreparedStatement最直接方法`

  采用预编译语句集，它内置了处理SQL注入的能力，
  只要使用它的setXXX方法传值即可。
使用好处：
  (1).代码的可读性和可维护性.
  (2).PreparedStatement尽最大可能提高性能.
  (3).最重要的一点是极大地提高了安全性.
原理：
  sql注入只对sql语句的准备(编译)过程有破坏作用
  而PreparedStatement已经准备好了,执行阶段只是把输入串作为数据处理,
  而不再对sql语句进行解析,准备,因此也就避免了sql注入问题.

2. `使用正则表达式过滤传入的参数`
3. `字符串过滤`
  比较通用的一个方法：
 （||之间的参数可以根据自己程序的需要添加）
4. jsp中调用该函数检查是否包函非法字符
5. JSP页面判断代码：
  使用JavaScript在客户端进行不安全字符屏蔽
  检查是否含有”‘”,”\\”,”/”

# 8.SQL---分类

DDL-------数据定义语言
DQL-------数据查询语言
DML-------数据操纵语言
DCL-------数据控制语言

## 8-1：有什么查询

主要的查询分为了基础查询、条件查询、
               排序查询、子查询、
               分页查询、多表查询

# SQL---执行顺序

1. from:需要从哪个数据表检索数据
2. join：联合多表查询返回记录时，并生成一张临时表
3. on：在生成临时表时使用的条件
4. where:过滤表中数据的条件
5. group by:如何将上面过滤出的数据分组
6. having:对上面已经分组的数据进行过滤的条件
7. select:查看结果集中的哪个列，或列的计算结果
8. order by :按照什么样的顺序来查看返回的数据
9. limit：限制查询结果返回的数量

# SQL---执行过程

1. `连接Mysql`
   客户端连接MySql服务时是半双工通信，
   客户端和服务端交互发送数据时必须一次发送完毕，
   在传输特别大的数据包时系统性能开销非常大，
   所以当客户端使用insert等语句发送大量的数据包时服务端就会拒绝连接，
   原因是服务端默认限制客户端发送的数据包大小不能超过4MB，
   这点可以通过修改MySql参数来更改大小限制，
   或者将需要发送的数据包在客户端进行分批发送处理。
   同理，在服务端返回给客户端数据时也要避免大量的数据包传输，
   所以要避免使用不带Limit的查询语句进行批量查询，
   或者可以先使用count做数据量预估，根据数据量进行分批查询。
2. `缓存与解析器`
   当缓存是打开的情况下，MySql服务端拿到Sql语句后，
   首先会到缓存判断是否有完全一致
   的Sql语句查询记录（判断时Sql语句连空格都不能有误差），
   有就将相应的结果集返回给客户端，
   当缓存中不存在时，会将Sql语句交给解析器来处理，
   解析器通过关键字将SQL语句进行解析，并生成一棵对应的“解析树”，
   接着会验证Sql语句是否有词法、语法等错误，
   例如，它将验证是否使用错误的关键字，
   或者使用关键字的顺序是否正确等，
   再或者它还会验证引号是否能前后正确匹配。
3. `预处理器（Preprocessor）`
   预处理器会对解析树行进一步检查解析树是否合法，
   例如，这里将检查数据表和数据列是否存在，
   还会解析名字和别名，
   看看它们是否有歧义。
   接着预处理器会验证权限。
   这通常很快，除非服务器上有非常多的权限配置。
4. `优化器（查询优化器 Query Optimizer）`
   一条Sql语句并不是只有一种执行路径。
   当优化器拿到预处理器发来的解析树后，
   会根据解析树生成不同的执行路径，
   这些执行路径就是常说的执行计划（Execution Plan），
   优化器会对这些执行计划计算对应的开销（cost），
   当得到不同的执行计划与相应的开销后，
   优化器将它认为最佳的执行计划去交给下一个部件去执行
5. `查询执行引擎`
   当优化器将执行计划交到查询执行引擎手里时，
   剩下的任务就简单多了，
   查询执行引擎调用相应的API接口来操作存储引擎，
   将存储引擎返回的查询结果返回给客户端，
   如果缓存开启的情况也会在缓存中进行缓存。
6. `存储引擎`
   存储引擎就有很多了，像Mysql5.5版本前默认使用的MyIsan存储引擎，
   5.5版本后默认使用的InnoDB存储引擎，

## 8-4-2：一条sql更新/删除/增加语句时怎么执行的

1.执行器先取到ID=2这行。因为ID是主键，引擎直接用树搜索找到这一行。
  如果ID=2这一行所在的数据页本来就在内存中，
  就直接返回给执行器；
  否则需要先从磁盘读入内存，然后再返回。
2.执行器拿到引擎给的行数据，把这个值加1，
  比如原来N，现在是N+1，得到新的一行数据，
  再调用引擎接口写入这行数据。
3.引擎将这行新数据更新到内存中，
  同时将这个`更新/删除/增加`操作记录在redo log里面，
  此时redo log处于prepare状态。
  然后告知执行器执行完成了，随时可以提交事务。
4.执行器生成这个操作的binlog，并把binlog写入磁盘中。
5.执行器调用引擎的提交事务接口，
  引擎把刚刚写入的redo log改成提交（commit）状态，
  更新完成。




# MySQL---权限表

1. user权限表：记录允许连接到服务器的用户帐号信息，里面的权限是全局级的。
2. db权限表：记录各个帐号在各个数据库上的操作权限。
3. table_priv权限表：记录数据表级的操作权限。
4. columns_priv权限表：记录数据列级的操作权限。
5. host权限表：配合db权限表对给定主机上数据库级操作权限作更细致的控制。
              这个权限表不受GRANT和REVOKE语句的影响。

# SQL---大小写

如何解决需要区分英文大小写的场景

解决方案一

MySQL默认的字符检索策略：utf8_general_ci，表示不区分大小写。
可以使用utf8_general_cs，表示区分大小写，
也可以使用utf8_bin，表示二进制比较，同样也区分大小写 。
创建表时，直接设置表的collate属性为utf8_general_cs
或者utf8_bin；
如果已经创建表，则直接修改字段的Collation
属性为utf8_general_cs或者utf8_bin。

```sql
CREATE TABLE testt(
id INT PRIMARY KEY,
name VARCHAR(32) NOT NULL
) ENGINE = INNODB COLLATE =utf8_bin;

-- 修改表结构的Collation属性
ALTER TABLE TABLENAME 
MODIFY COLUMN COLUMNNAME VARCHAR(50) BINARY CHARACTER 
SET utf8 COLLATE utf8_bin DEFAULT NULL;
```

解决方案二

直接修改sql语句，在要查询的字段前面加上binary关键字

```sql
-- 在每一个条件前加上binary关键字
select * from user where 
binary username = 'admin' 
and binary password = 'admin';

-- 将参数以binary('')包围
select * from user 
where username 
like binary('admin') 
and password like binary('admin');
```

# SQL---关键字


## 8-3-1：truncate、 delete区别

1、TRUNCATE在各种表上无论是大的还是小的都非常快。
   如果有ROLLBACK命令DELETE将被撤销，而TRUNCATE则不会被撤销。
2、truncate不能进行回滚操作。
3、truncate不触发任何delete触发器。
4、当表被truncate后，这个表和索引所占用的空间会恢复到初始大小，
   而delete操作不会减少表或索引所占用的空间。
5、不能truncate一个带有外键的表，如果要删除首先要取消外键，然后再删除。
    DELETE语句执行删除的过程是每次从表中删除一行，
    并且同时将该行的的删除操作作为事务记录
    在日志中保存以便进行进行回滚操作。

## 8-3-3：mysql中 in 和 exists 区别

1. exists()适合B表比A表数据大的情况
2. 当A表数据与B表数据一样大时,in与exists效率差不多,可任选一个使用

## 8-3-4：WHERE子句和HAVING子句的执行速度

在 WHERE 子句和 HAVING 子句中都可以使用的条件，最好写在 WHERE 子
句中的另一个理由与性能即执行速度有关系。由于性能不在本书介绍的范围之内，
因此暂不进行说明。通常情况下，为了得到相同的结果，将条件写在 WHERE 子句
中要比写在 HAVING 子句中的处理速度更快，返回结果所需的时间更短。
为了理解其中原因，就要从 DBMS 的内部运行机制来考虑。使用 COUNT 函
数等对表中的数据进行聚合操作时，DBMS 内部就会进行排序处理。排序处理是
会大大增加机器负担的高负荷的处理 A。因此，只有尽可能减少排序的行数，才能
提高处理速度。
通过 WHERE 子句指定条件时，由于排序之前就对数据进行了过滤，因此能够
减少排序的数据量。但 HAVING 子句是在排序之后才对数据进行分组的，因此与
在 WHERE 子句中指定条件比起来，需要排序的数据量就会多得多。虽然 DBMS
的内部处理不尽相同，但是对于排序处理来说，基本上都是一样的。
此外， WHERE 子句更具速度优势的另一个理由是，可以对 WHERE 子句指定条
件所对应的列创建索引，这样也可以大幅提高处理速度。创建索引是一种非常普遍
的提高 DBMS 性能的方法，效果也十分明显，这对 WHERE 子句来说也十分有利。

## 8-3-8：MySQL，左连接中on和where的区别

1. on的条件是在连接生成临时表时使用的条件,以左表为基准 ,不管on中的条件真否,都会返回左表中的记录
2. where条件是在临时表生成好后,再对临时表过滤。
   此时和left join有区别(返回左表全部记录),条件不为真就全部过滤掉,on后的条件来生成左右表关联的临时表,
   where后的条件是生成临时表后对临时表过滤

## 8-3-5：groupby和having的区别

通过使用GROUP BY 子句，比如说可以让SUM和 COUNT 这些函数对属于一组的数据起作用。
当你指定 GROUP BY A 时，表中所有除A(地区)外的字段，只能通过 SUM, COUNT等聚合函数运算后返回一个值。

HAVING子句可以让我们筛选成组后的各组数据，WHERE子句在聚合前先筛选记录.
也就是说作用在GROUP BY 子句和HAVING子句前.
而 HAVING子句在聚合后对组记录进行筛选。

## 8-3-6：UNION与UNION ALL的区别？

union：对两个结果集进行并集操作，不包括重复行，同时进行默认规则的排序；
union All：对两个结果集进行并集操作，包括重复行，不进行排序；

## 8-3-7：count(*)、count(1)、count(column)的区别

count(*)对行的数目进行计算,
包含NULL，count(1)
这个用法和count(*)的结果是一样的
count(column)对特定的列的值具有的行数进行计算,
不包含NULL值。

# MySQL---约束关键字

NOT NULL: 用于控制字段的内容一定不能为空（NULL）。
UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束。
PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。
FOREIGN KEY: 用于预防破坏表之间连接的动作，
             也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。
CHECK: 用于控制字段的值范围。

## 8-5-1：字段为什么要求定义为not null?

null值会占用更多的字节,且会在程序中造成很多与预期不符的情况

# MySQL---键

## 8-6-1：超键、候选键、主键、外键分别是什么

超键：一个属性可以为作为一个超键，
     多个属性组合在一起也可以作为一个超键。超键包含候选键和主键。
候选键：是最小超键，即没有冗余元素的超键。
主键：一个数据列只能有一个主键，且主键的取值不能缺失，
     即不能为空值（Null）
外键：在一个表中存在的另一个表的主键称此表的外键。

## 8-6-2：为什么用自增列作为主键

如果表使用自增主键，那么每次插入新的记录，
记录就会顺序添加到当前索引节点的后续位置，
当一页写满，就会自动开辟一个新的页
如果使用非自增主键，由于每次插入主键的值近似于随机，
因此每次新纪录都要被插到现有索引页得中间某个位置，
此时MySQL不得不为了将新记录插到合适位置而移动数据，
甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，
此时又要从磁盘上读回来，这增加了很多开销，
同时频繁的移动、分页操作造成了大量的碎片，
得到了不够紧凑的索引结构，
后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。

## 8-6-2-1：主键使用自增ID还是UUID?

推荐使用自增ID,不要使用UUID.

因为在InnoDB存储引擎中,主键索引是作为聚簇索引存在的,
也就是说,主键索引的B+树叶子节点上存储了
主键索引以及全部的数据(按照顺序),
如果主键索引是自增ID,
那么只需要不断向后排列即可,
如果是UUID,由于到来的ID与原来的大小不确定,
会造成非常多的数据插入,数据移动,
然后导致产生很多的内存碎片,
进而造成插入性能的下降.

## 8-6-2-1：为什么MySQL不推荐使用uuid或者雪花id作为主键？

自增的主键的值是顺序的,
所以Innodb把每一条记录都存储在一条记录的后面。
当达到页面的最大填充因子时候：

①下一条记录就会写入新的页中，
一旦数据按照这种顺序的方式加载，
主键页就会近乎于顺序的记录填满，
提升了页面的最大填充率，不会有页的浪费

②新插入的行一定会在原有的最大数据行下一行,
mysql定位和寻址很快，
不会为计算新行的位置而做出额外的消耗

③减少了页分裂和碎片的产生

因为uuid相对顺序的自增id来说是毫无规律可言的,
新行的值不一定要比之前的主键的值要大,
所以innodb无法做到总是把新行插入到索引的最后,
而是需要为新行寻找新的合适的位置从而来分配新的空间。
这个过程需要做很多额外的操作，
数据的毫无顺序会导致数据分布散乱，
将会导致一些问题：
比如说
①写入的目标页很可能已经刷新到磁盘上并且从缓存上移除，
或者还没有被加载到缓存中，
innodb在插入之前不得不先找到
并从磁盘读取目标页到内存中，
这将导致大量的随机IO
②因为写入是乱序的,innodb不得不频繁的做页分裂操作,
以便为新的行分配空间,页分裂导致移动大量的数据，
一次插入最少需要修改三个页以上
③由于频繁的页分裂，页会变得稀疏并被不规则的填充，
最终会导致数据会有碎片
在把随机值（uuid和雪花id）
载入到聚簇索引(innodb默认的索引类型)以后,
有时候会需要做一次OPTIMEIZE TABLE来重建表并优化页的填充，
这将又需要一定的时间消耗。

## 8-6-2-2：使用自增id的缺点

①别人一旦爬取你的数据库,
 就可以根据数据库的自增id获取到你的业务增长信息，
 很容易分析出你的经营情况
②对于高并发的负载，
  innodb在按主键进行插入的时候会造成明显的锁争用，
  主键的上界会成为争抢的热点，
  因为所有的插入都发生在这里，
  并发插入会导致间隙锁竞争
③Auto_Increment锁机制
 会造成自增锁的抢夺,有一定的性能损失

## 8-6-2-3：数据库主键自增怎么获取主键值

使用函数  LAST_INSERT_ID()
比如说如查看最新一次自增得到的id：  select  LAST_INSERT_ID();
或者在mybatis中
设置userGeneratedKeys属性值为true:使用自动增长的主键。
使用keyProperty设置把主键值设置给哪一个属性

```java
<insert id="addEmp" 
        parameterType="com.neuedu.mybatis.bean.Employee" 
        useGeneratedKeys="true" keyProperty="id" databaseId="mysql">
　　　insert into tbl_employee(last_name,email,gender)
　　　values(#{lastName},#{gender},#{email})
</insert>
```

## 8-6-3：为什么要尽量设定一个主键

主键是数据库确保数据行在整张表唯一性的保障,
即使业务上本张表没有主键,
也建议添加一个自增长的ID列作为主键.
设定了主键之后,
在后续的删改查的时候可能
更加快速以及确保操作数据范围安全.

# 关联查询---分类

1. 交叉连接(CROSS JOIN)
2. 内连接(INNER JOIN)
3. 外连接(LEFT JOIN/RIGHT JOIN)
4. 联合查询(UNION 与 UNION ALL)
5. 全连接(FULL JOIN)
-----------------------------------------------------------
6. 内连接: 只连接匹配的行
7. 左外连接: 包含左边表的全部行，以及右边表中全部匹配的行
8. 右外连接: 包含右边表的全部行，以及左边表中全部匹配的行
9. 全外连接: 包含左、右两个表的全部行。
10. 交叉连接: 生成笛卡尔积－它不使用任何匹配或者选取条件，
            而是直接将一个数据源中的每个行与另一个数据源
            的每个行都一一匹配


# 多表查询---概念

对第一个和第二个表按照两表连接做查询，然后用查询结果和第三个表做连接查询，以此类推

# 笛卡尔积---概念

就是两张表的记录
进行一个相乘的操作查询出来的结果就是笛卡尔积,
如果左表有n条记录,右表有m条记录,
笛卡尔积查询出有n*m条记录,
其中往往包含了很多错误的数据,所以这种查询方式并不常用。

## 8-1-6-2：笛卡尔积的解决方案

添加上连接条件

# 视图---概念

视图是虚拟的表

1. 重用SQL语句；
2. 简化复杂的SQL操作（可以方便的重用它而不必知道它的基本查询细节）；
3. 使用表的组成部分而不是整个表；
4. 保护数据（可以给用户授予表的部分访问权限而不是整个表的访问权限）；
5. 更改数据格式和表示（视图可返回与底层表的表示和格式不同的数据）。

# 存储过程---概念

预先用SQL语句写好并用一个指定的名称存储起来，只需调用execute,即可自动完成命令。

### 8-8-1：存储过程有哪些优缺点？

1. 一般SQL语句每执行一次就编译一次,使用存储过程创建进行编译，可提高数据库执行速度。
2. 当对数据库进行复杂操作时
   (如对多个表进行Update,Insert,Query,Delete时），
   可将此复杂操作用存储过程封装起来。
3. 存储过程可以重复使用,可减少数据库开发人员的工作量
4. 安全性高,可设定只有某此用户才具有对指定存储过程的使用权

# 触发器---概念

数据库触发器是在数据库中发生特定操作时运行的特殊存储过程

### 8-9-1：触发器的使用场景有哪些？

1. 复杂的审计
   可以使用触发器来跟踪对表所做的更改。
   比如说认为这是涉及敏感操作的信息，进行了更改。
2. 执行业务规则
   每次添加或修改客户记录时检查客户状态。

# 窗口函数---概念

具体定义记不太清楚，因为
经常会遇到需要在每组内排名，比如说
排名问题：每个部门按业绩来排名
或者找出每个部门排名前N的员工进行奖励

```sql
<窗口函数> over (partition by <用于分组的列名>
                order by <用于排序的列名>)
```


# -----------------------------------------------------------------------------------

# -----------------------------------------------------------------------------------


# 9.事务---概念

事务是逻辑上的⼀组操作，要么都执⾏，要么都不执⾏。

# 事务---事务特性

1. 原⼦性（Atomicity）：事务是最⼩的执⾏单位，
                       不允许分割。事务的原⼦性确保动作要么全部完成，
                       要么完全不起作⽤；
2. ⼀致性（Consistency）： 执⾏事务前后，数据保持⼀致，
                          多个事务对同⼀个数据读取的结果是相同的；
3. 隔离性（Isolation）： 并发访问数据库时，
                       ⼀个⽤户的事务不被其他事务所⼲扰，
                       各并发事务之间数据库是独⽴的；
4. 持久性（Durability）： ⼀个事务被提交之后。
                         它对数据库中数据的改变是持久的，
                         即使数据库发⽣故障也不应该对其有任何影响。

# 事务---ACID底层原理

`A原子性`由undo log日志保证，
         它记录了需要回滚的日志信息，
         事务回滚时撤销已经执行成功的sql
`C一致性`一般由代码层面来保证
`I隔离性`由MVCC来保证
`D持久性`由内存+redo log来保证，
         mysql修改数据同时在内存和redo log记录这次操作，
         事务提交的时候通过redo log刷盘，
         宕机的时候可以从redo log恢复

## -1：原子性

### -1-1:Java如何保证原子性

1. 第一个方法是循环CAS
   只能保证一个共享变量的原子操作。
   当对一个共享变量执行操作时，
   我们可以使用循环CAS的方式来保证原子操作，
   但是对多个共享变量操作时，
   循环CAS就无法保证操作的原子性，这个时候就可以用锁
   或者有一个取巧的办法，
   就是把多个共享变量合并成一个共享变量来操作。
   比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij
2. 锁
   锁机制保证了只有获得锁的线程能够操作锁定的内存区域。

### -1-2:undo log


### -1-3:undo log缺陷如何解决

每个事务提交前将数据和Undo Log写入磁盘，
这样会导致大量的磁盘IO，因此性能很低。
因此引入了另外一种机制来实现持久化，
即Redo Log。
Redo Log记录的是新数据的备份。
在事务提交前，只要将Redo Log持久化即可，
不需要将数据持久化。当系统崩溃时，
虽然数据没有持久化，但是Redo Log已经
持久化。系统可以根据Redo Log的内容，
将所有数据恢复到最新的状态。

# 事务---并发问题

1. 脏读
    A事务读取B事务尚未提交的更改数据，并在这个数据的基础上进行操作，
    这时候如果事务B回滚，那么A事务读到的数据是不被承认的。
2. 不可重复读
    不可重复读是指A事务读取了B事务已经提交的更改数据。假
    如A在取款事务的过程中，B往该账户转账100，A两次读取的余额发生不一致。
3. 幻读
    A事务读取B事务提交的新增数据,会引发幻读问题。幻读一般发生在计算统计数据的事务中，
    例如银行系统在同一个事务中两次统计存款账户的总金额，
    在两次统计中，刚好新增了一个存款账户，存入了100，这时候两次统计的总金额不一致。 
4. 第一类丢失更新
    A事务撤销时，把已经提交的B事务的更新数据覆盖了。 
5. 第二类丢失更新
    A事务覆盖B事务已经提交的数据，造成B事务所做的操作丢失 。

## -1:不可重复读和幻读的区别

不可重复读是指读到了已经提交的事务的更改数据（修改或删除），
幻读是指读到了其他已经提交事务的新增数据。
对于这两种问题解决采用不同的办法，
防止读到更改数据，只需对操作的数据添加行级锁，
防止操作中的数据发生变化；
二防止读到新增数据，往往需要添加表级锁，
将整张表锁定，防止新增数据（oracle采用多版本数据的方式实现）。

# 事务---并发解决方案

## -1：如何解决幻读

1. 通过多版本并发控制
2. 通过next-key当前锁来解决
   主要是将当前数据行与上一条数据和下一条数据之间的间隙锁定，保证此范围内读取数据是一致的





# 事务---隔离级别

1. 读取未提交： 最低的隔离级别，允许读取尚未提交的数据变更， 可能会导致脏读、幻读或不可重复读
2. 读取已提交： 允许读取并发事务已经提交的数据， 可以阻⽌脏读，
              但是幻读或不可重复读仍有可能发⽣。
3. 可重复读：   对同⼀字段的多次读取结果都是⼀致的，除⾮数据是被本身事务⾃⼰所修改， 可以阻⽌脏
               读和不可重复读，但幻读仍有可能发⽣。
4. 可串⾏化：   最⾼的隔离级别， 该级别可以防⽌脏读、不可重复读以及幻读。


## -1:为什么要有事物隔离级别

因为事物隔离级别越高，在并发下会产生的问题就越少，
但同时付出的性能消耗也将越大，
因此很多时候必须在并发性和性能之间做一个权衡。
所以设立了几种事物隔离级别，
以便让不同的项目可以根据自己项目的
并发情况选择合适的事物隔离级别，
对于在事物隔离级别之外会产生的并发问题，在代码中做补偿。

## -2：MySQL 中RC（读已提交）和RR（可重复读）隔离级别的区别

1. RR支持gap lock，而RC则没有gap lock（间隙锁）。
   因为MySQL的RR需要gap lock来解决幻读问题。
   而RC隔离级别则是允许存在不可重复读和幻读的。所以RC的并发一般要好于RR；
2. RC 隔离级别，通过 where 条件过滤之后，不符合条件的记录上的行锁，
   会释放掉；但是RR隔离级别，即使不符合where条件的记录，
   也不会是否行锁和gap lock；所以从锁方面来看，RC的并发应该要好于RR；
3. RC 隔离级别不支持 statement 格式的bin log，
   因为该格式的复制，会导致主从数据的不一致；
   只能使用 mixed 或者 row 格式的bin log
4. RC隔离级别时，事务中的每一条select语句会读取到他自己执行时已经提交了的记录，
   而RR隔离级别时，事务中的一致性读的是以第一条select语句的运行时，
   作为本事务的一致性读的建立时间点的。只能读取该时间点之前已经提交的数据
5. RC隔离级别下的update语句，
   使用的是半一致性读(semi consistent)；
   而RR隔离级别的update语句使用的是当前读；当前读会发生锁的阻塞


# 事务---隔离级别原理

1. READ_UNCOMMITED（`读取未提交`） 的原理
   - *事务对当前被读取的数据不加锁；*
   - `事务在更新某数据的瞬间（就是发生更新的瞬间），`
     `必须先对其加行级共享锁，直到事务结束才释放。`
2. READ_COMMITED(`读取已提交`)的原理
   - *事务对当前被读取的数据加 行级共享锁（当读到时才加锁），一旦读完该行，立即释放该行级共享锁；*
   - `事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加 行级排他锁，直到事务结束才释放。`
3. REPEATABLE READ 的原理:
   - *事务在读取某数据的瞬间（就是开始读取的瞬间），必须先对其加 行级共享锁，直到事务结束才释放；*
   - `事务在更新某数据的瞬间（就是发生更新的瞬间），必须先对其加 行级排他锁，直到事务结束才释放。`
4. SERIALIZABLE 的原理:
   - *事务在读取数据时，必须先对其加 表级共享锁 ，直到事务结束才释放；*
   - `事务在更新数据时，必须先对其加 表级排他锁 ，直到事务结束才释放。`


# 事务---崩溃恢复机制

为了满足事务的原子性，在操作任何数据之前，
首先将数据备份到一个地方，这个存储数据备份的地方称为UndoLog。
然后进行数据的修改。
如果出现了错误或者用户执行了回滚，
系统可以利用Undo Log中的备份将数据恢复到事务开始之前的状态。


# 事务---日志种类

1. 错误日志：记录出错信息，也记录一些警告信息或者正确的信息。
2. 查询日志：记录所有对数据库请求的信息，
            不论这些请求是否得到了正确的执行。
3. 慢查询日志：设置一个阈值，
              将运行时间超过该值的
              所有SQL语句都记录到慢查询的日志文件中。
4. 二进制日志：记录对数据库执行更改的所有操作。
5. 中继日志：中继日志也是二进制日志，用来给slave 库恢复
6. 事务日志：重做日志redo和回滚日志undo

# 事务---日志实现原理

事务日志是通过redo和innodb的存储引擎日志
缓冲来实现的，当开始一个事务的时候，
会记录该事务的lsn号;
当事务执行时，会往InnoDB存储引擎的日志
的日志缓存里面插入事务日志；
当事务提交时，必须将存储引擎的日志
缓冲写入磁盘，通过innodb_flush_log_at_trx_commit来控制，
也就是写数据前，需要先写日志。这种方式称为“预写日志方式”

# 事务---三级封锁协议

1. 一级封锁协议：事务T中如果对数据R有写操作，
              必须在这个事务中对R的第一次读操作前对它加X锁，
              直到事务结束才释放。事务结束包括正常结束（COMMIT）和非正常结束（ROLLBACK）。

2. 二级封锁协议：一级封锁协议加上事务T在读取数据R之前必须先对其加S锁，读完后方可释放S锁。

3. 三级封锁协议 ：一级封锁协议加上事务T在读取数据R之前必须先对其加S锁，直到事务结束才释放。

## 缺陷

一级锁协议就要在第一次读加x锁，
直到事务结束。几乎就要在整个事务加写锁了，效率非常低。
三级封锁协议只是一个理论上的东西，实际数据库常用另一套方法来解决事务并发问题。

# 日志---概念

因为MySQL整体来看，其实就有两块：
一块是Server层，它主要做的是MySQL功能层面的事情；
还有一块是引擎层，负责存储相关的具体事宜。
而redo log是InnoDB引擎特有的日志，
而Server层也有自己的日志，称为binlog（归档日志）。

## 我写其中的某一个log，失败了，那会怎么办？

`如果说是先写redo log，再写binlog，`
如果写redo log失败了，
那我们就认为这次事务有问题，回滚，不再写binlog。
如果写redo log成功了，
写binlog，写binlog写一半了，但失败了
我们还是会对这次的事务回滚，
将无效的binlog给删除
（因为binlog会影响从库的数据，所以需要做删除操作）
如果写redo log和binlog都成功了，那这次算是事务才会真正成功。

## binlog、redolog的区别

. `存储内容来说`
   binlog记载的是update/delete/insert这样的SQL语句，
   而redo log记载的是物理修改的内容（xxxx页修改了xxx）。
2. `功能`
   redo log的作用是为持久化而生的。写完内存，
   如果数据库挂了，
   那我们可以通过redo log来恢复内存还没来得及刷到磁盘的数据，
   将redo log加载到内存里边，
   那内存就能恢复到挂掉之前的数据了。
   binlog的作用是复制和恢复而生的。
   主从服务器需要保持数据的一致性，
   通过binlog来同步数据。
   如果整个数据库的数据都被删除了，
   binlog存储着所有的数据变更情况，
   那么可以通过binlog来对数据进行恢复。
3. `第三方面来说，写入内容来说`
   redo log事务开始的时候，
   就开始记录每次的变更信息，
   而binlog是在事务提交的时候才记录。

# 日志---两段提交

“两阶段提交”是为了让两份日志之间的逻辑一致。
由于redo log和binlog是两个独立的逻辑，如果不用两阶段提交
会出现错误
比如说
`先写redo log后写binlog。`
假设在redo log写完，binlog还没有写完的时候，
MySQL进程异常重启。redo log写完之后，
系统即使崩溃，仍然能够把数据恢复回来，
所以恢复后这一行c的值是1。
但是由于binlog没写完就crash了，
这时候binlog里面就没有记录这个语句。
因此，之后备份日志的时候，
存起来的binlog里面就没有这条语句。
然后发现，如果需要用这个binlog来恢复临时库的话，
由于这个语句的binlog丢失，
这个临时库就会少了这一次更新，
恢复出来的这一行c的值就是0，
与原库的值不同。
如果
`先写binlog后写redo log。`
如果在binlog写完之后crash，
由于redo log还没写，
崩溃恢复以后这个事务无效，
所以这一行c的值是0。
但是binlog里面已经记录了“把c从0改成1”这个日志。
所以，在之后用binlog来恢复的时候就多了一个事务出来，
恢复出来的这一行c的值就是1，
与原库的值不同。

## MySQL如何保证redo log和binlog的数据是一致的

MySQL通过两阶段提交来保证redo log和binlog的数据是一致的。
`阶段1：InnoDBredo log 写盘，InnoDB 事务进入 prepare 状态`
`阶段2：binlog 写盘，InooDB 事务进入 commit 状态`
每个事务binlog的末尾，会记录一个 XID event，
标志着事务是否提交成功，
也就是说，恢复过程中，
binlog 最后一个 XID event 之后的内容都应该被 purge。


# 日志---binlog

binlog其实就是记录了数据库表结构和表数据`变更`
我们的数据是保存在数据库里边的嘛，
假设我们对某个商品的某个字段的内容改了（`数据库变更`），
而用户检索的出来数据是走搜索引擎的。
为了让用户能搜到最新的数据，我们需要把引擎的数据也改掉。
数据库的变更，搜索引擎的数据也需要变更。

binlog：存储着每条变更的SQL语句

# binlog--概念

主要有两个作用：复制和恢复数据
MySQL一般都是一主多从结构的，
从服务器需要与主服务器的数据保持一致，这就是通过binlog来实现的
数据库的数据消失了，我们可以通过binlog来对数据进行恢复。
因为binlog他记录了数据库的变更，所以用binlog进行赋值和恢复数据

## binlog有几种录入格式

有三种格式,statement,row和mixed.

**Statement：每一条会修改数据的sql都会记录在binlog中。**
`优点`：不需要记录每一行的变化，
        减少了binlog日志量，节约了IO，提高性能。
        相比row能节约多少性能 与日志量，
        这个取决于应用的SQL情况，
        正常同一条记录修改或者插入row格式所产生的
        日志量还小于Statement产生的日志量，
        但是考虑到如果带条件的update操作，
        以及整表删除，alter表等操作，
        ROW格式会产生大量日志，
        因此在考虑是否使用ROW格式日志时
        应该根据应用的实际情况，
        其所产生的日志量会增加多少，
        以及带来的IO性能问题。
`缺点`：由于记录的只是执行语句，
        为了这些语句能在slave上正确运行，
        因此还必须记录每条语句在执行的时候的
        一些相关信息，以保证所有语句能
        在slave得到和在master端执行时候相同的结果。
**Row:不记录sql语句上下文相关信息，仅保存哪条记录被修改。**
`优点`：binlog中可以不记录执行的sql语句的上下文相关的信息，
       仅需要记录那一条记录被修改成什么了。
       所以rowlevel的日志内容会非常清楚的记录下
       每一行数据修改的细节。而且不会出现某些特定情况下
       的存储过程，或function，
       以及trigger的调用和触发无法被正确复制的问题
`缺点`：所有的执行的语句当记录到日志中的时候，
       都将以每行记录的修改来记录，
       这样可能会产生大量的日志内容。
       比如一条update语句，修改多条记录，
       则binlog中每一条修改都会有记录，
       这样造成binlog日志量会很大，
       特别是当执行alter table之类的语句的时候，
       由于表结构修改，每条记录都发生改变，
       那么该表每一条记录都会记录到日志中。
**Mixedlevel: 以上两种level的混合使用。**
一般的语句修改使用statment格式保存binlog，
如一些函数，statement无法完成主从复制的操作，
则采用row格式保存binlog,MySQL会根据执行的每一条具体
的sql语句来区分对待记录的日志形式，
也就是在Statement和Row之间选择一种。

# redo log

Mysql的基本存储结构是页(记录都存在页里边)，
所以MySQL是先把这条记录所在的页找到，
然后把该页加载到内存中，将对应记录进行修改。
当我们修改的时候，写完内存了，但数据还没真正写到磁盘的时候。
此时我们的数据库挂了，我们可以根据redo log来对数据进行恢复。
因为redo log是顺序IO，所以写入的速度很快，
并且redo log记载的是物理变化（xxxx页做了xxx修改），
文件的体积很小，恢复速度很快。

## 如果整个数据库的数据都被删除了，那我可以用redo log的记录来恢复吗？

不能
因为功能的不同，redo log 存储的是物理数据的变更，
如果我们内存的数据已经刷到了磁盘了，那redo log的数据就无效了。
所以redo log不会存储着历史所有数据的变更，文件的内容会被覆盖的。

# -----------------------------------------------------------------------------------

# -----------------------------------------------------------------------------------

# 20.索引---概念

索引，类似于书籍的目录，想找到一本书的某个特定的主题，需要先找到书的目录，定位对应的页码。
MySQL 中存储引擎使用先去索引中查找对应的值，然后根据匹配的索引找到对应的数据行。

## -1:索引的优劣势

索引有什么好处？

1. 提高数据的检索速度，降低数据库IO成本：
   使用索引的意义就是通过缩小表中需要查询的记录的数目从而加快搜索的速度。

2. 降低数据排序的成本，降低CPU消耗：
   索引之所以查的快，是因为先将数据排好序，若该字段正好需要排序，则正好降低了排序的成本。
索引有什么坏处？

1. 占用存储空间：索引实际上也是一张表，记录了主键与索引字段，一般以索引文件的形式存储在磁盘上。
2. 降低更新表的速度：表的数据发生了变化，对应的索引也需要一起变更，
   从而减低的更新速度。否则索引指向的物理数据可能不对，这也是索引失效的原因之一。

## 12-4-6：为什么索引能够提高查询速度

因为树的结构最大的优点就是查询性能高，因此所有需要提高查询性能的都可以考虑树。

比如：
1. HashMap 中的数据冲突时，链表转化成红黑树；
2. 数据库索引使用的 B+ 树；

索引能够提高查询速度我觉得主要源自

1. 数据存储在磁盘（SSD跟CPU性能也不在一个量级），而磁盘处理数据很慢；
   提高磁盘性能主要通过减少 I/O 次数，以及单次 I/O 有效数据量；
2. 索引通过多阶（一个节点保存多个数据，指向多个子节点）使树的结构更矮胖，从而减少 I/O 次数；
3. 索引通过 B+ 树，把业务数据与索引数据分离，来提高单次 I/O 有效数据量，从而减少 I/O 次数；
4. 索引通过树数据的有序和「二分查找」（多阶树可以假设为多分查找），大大缩小查询范围；
5. 索引针对的是单个字段或部分字段，数据量本身比一条记录的数据量要少的多，
   这样即使通过扫描的方式查询索引也比扫描数据库表本身快的多；

## -2:创建索引原则

1、最适合索引的列是出现在 WHERE 子句中的列，或连接子句中的列，而不是出现在 SELECT 关键字后的列。
2、索引列的基数越大，索引效果越好。
3、根据情况创建复合索引，复合索引可以提高查询效率。
  因为复合索引的基数会更大。
4、避免创建过多的索引，索引会额外占用磁盘空间，降低写操作效率。
5、主键尽可能选择较短的数据类型，可以有效减少索引的磁盘占用提高查询效率。
6、对字符串进行索引，应该定制一个前缀长度，可以节省大量的索引空间。

## -4：创建索引的注意事项

1、应尽量避免在 WHERE 子句中使用 != 或 <> 操作符，
  否则将引擎放弃使用索引而进行全表扫描。
  优化器将无法通过索引来确定将要命中的行数,因此需要搜索该表的所有行。

2、应尽量避免在 WHERE 子句中使用 OR 来连接条件，
   否则将导致引擎放弃使用索引而进行全表扫描，
   如：SELECT id FROM t WHERE num = 10 OR num = 20 。

3、应尽量避免在 WHERE 子句中对字段进行表达式操作，
   这将导致引擎放弃使用索引而进行全表扫描。

4、应尽量避免在 WHERE 子句中对字段进行函数操作，
   这将导致引擎放弃使用索引而进行全表扫描。

5、不要在 WHERE 子句中的 = 左边进行函数、算
  术运算或其他表达式运算，否则系统将可能无法正确使用索引。

6、复合索引遵循前缀原则。

7、如果 MySQL 评估使用索引比全表扫描更慢，会放弃使用索引。
  如果此时想要索引，可以在语句中添加强制索引。

8、列类型是字符串类型，查询时一定要给值加引号，否则索引失效。

9、LIKE 查询，% 不能在前，因为无法使用索引。
   如果需要模糊匹配，可以使用全文索引。

## -3:索引的使用场景

1、对非常小的表，大部分情况下全表扫描效率更高。
2、对中大型表，索引非常有效。
3、特大型的表，建立和使用索引的代价随着增长，可以使用分区技术来解决。

## -4：索引失效

1. like 以%开头，索引无效；当like前缀没有%，后缀有%时，索引有效。
    主要是因为MYSQL索引失效会变成全表扫描的操作
2. or语句前后没有同时使用索引。
   当or左右查询字段只有一个是索引，
   该索引失效，只有当or左右查询字段均为索引时，才会生效
3. 组合索引，不是使用第一列索引，索引失效。
4. 数据类型出现隐式转化。
   如varchar不加单引号的话可能会自动转换为int型，
   使索引无效，产生全表扫描。
5. 在索引列上使用IS NULL 或IS NOT NULL操作。
   索引是不索引空值的，所以这样的操作不能使用索引，
   可以用其他的办法处理，
   例如：数字类型，判断大于0，字符串类型设置一个默认值，
   判断是否等于默认值即可。
6. 在索引字段上使用not，<>，!=。
   不等于操作符是永远不会用到索引的，
   因此对它的处理只会产生全表扫描。
   优化方法： key<>0 改为 key>0 or key<0。
7. 对索引字段进行计算操作、字段上使用函数。（索引为 emp(ename,empno,sal)）
8. 当全表扫描速度比索引速度快时，mysql会使用全表扫描，此时索引失效。


# 21.索引---分类

1、普通索引：最基本的索引，没有任何约束。
2、唯一索引：与普通索引类似，但具有唯一性约束。
3、主键索引：特殊的唯一索引，不允许有空值。
4、复合索引：将多个列组合在一起创建索引，可以覆盖多个列。
5、外键索引：只有InnoDB类型的表才可以使用外键索引，保证数据的一致性、完整性和实现级联操作。
6、全文索引：MySQL 自带的全文索引只能用于 InnoDB、MyISAM ，
           并且只能对英文进行全文检索，一般使用全文索引引擎。

# 22.索引---创建方式

```java
#方法一：创建表时
    　　CREATE TABLE 表名 (
                字段名1  数据类型 [完整性约束条件…],
                字段名2  数据类型 [完整性约束条件…],
                [UNIQUE | FULLTEXT | SPATIAL ]   INDEX | KEY
                [索引名]  (字段名[(长度)]  [ASC |DESC]) 
                );
       
       CREATE TABLE t(
                        c1 INT PRIMARY KEY,
                        c2 INT NOT NULL,
                        c3 INT NOT NULL,
                        c4 VARCHAR(10),
                        INDEX (c2,c3) 
                     );

#方法二：CREATE在已存在的表上创建索引
        CREATE  [UNIQUE | FULLTEXT | SPATIAL ]  INDEX  索引名 
                     ON 表名 (字段名[(长度)]  [ASC |DESC]) ;
        
        CREATE INDEX index_name ON table_name (column_list)

#方法三：ALTER TABLE在已存在的表上创建索引
        ALTER TABLE 表名 ADD  [UNIQUE | FULLTEXT | SPATIAL ] INDEX
                             索引名 (字段名[(长度)]  [ASC |DESC]) ;

         alter table table_name add index index_name (column_list) ;    

#删除索引：DROP INDEX 索引名 ON 表名字;
```

## -1:三条 SQL 如何建索引，只建一条怎么建？

```sql
WHERE a = 1 AND b = 1
WHERE b = 1
WHERE b = 1 ORDER BY time DESC
```

以顺序 b , a, time 建立复合索引，CREATE INDEX table1_b_a_time ON index_test01(b, a, time)。
对于第一条 SQL ，因为最新 MySQL 版本会优化 WHERE 子句后面的列顺序，以匹配复合索引顺序。

# 23.索引---属性



# 24.索引---本质

因为索引的本质他就是数据结构，由于，我们都希望查询数据的速度尽可能快一些，
所以设计了很多的查询算法，比如说顺序查找、二分查找、二叉树查找等等，但是由于数据
本身的组织结构不可能完全满足各种数据结构（例如，理论上不可能同时将两列都按顺序进行组织），
所以，在数据之外，数据库系统还维护着满足特定查找算法的数据结构，
这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。
所以才有了索引这个概念


# 25.索引---索引方式

1. B-Tree 索引。
2. Hash 索引。

## -1:B-tree索引和hash索引的区别

1. 哈希索引就是采用一定的哈希算法，
   把键值换算成新的哈希值
   检索时不需要类似B+树那样从根节点到叶子节点逐级查找，
   只需一次哈希算法即可立刻定位到相应的位置，速度非常快。

2. 在MySQL中，只有HEAP/MEMORY引擎表才能显式支持哈希索引

3. 最重要的区别是：
    1）如果是等值查询，那么哈希索引明显有绝对优势，
       在键值都是唯一的时候，
       因为只需要经过一次算法即可找到相应的键值；
       如果键值不是唯一的，就需要先找到该键所在位置，
       然后再根据链表往后扫描，直到找到相应的数据；
    2).从示意图中也能看到，如果是范围查询检索，
       这时候哈希索引就毫无用武之地了，因为原先是有序的键值，
       经过哈希算法后，有可能变成不连续的了，就没办法再利用索引完成范围查询检索；
    3).同理，哈希索引也没办法利用索引完成排序，
       以及like ‘xxx%’ 这样的部分模糊查询（这种部分模糊查询，其实本质上也是范围查询）；
    4).哈希索引也不支持多列联合索引的最左匹配规则；
    5).B+树索引的关键字检索效率比较平均，
       不像B树那样波动幅度大，在有大量重复键值情况下，
       哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题。

## -2:B-Tree 索引

B-Tree是为磁盘这些外存储设备设计的一种平衡查找树
B-Tree 结构的数据可以让系统高效的找到数据所在的磁盘块

是一种多路搜索树（并不是二叉的）：
B-树的搜索，从根结点开始，
对结点内的关键字（有序）序列进行二分查找，
如果命中则结束，否则进入查询关键字所属范围的儿子结点；
重复，直到所对应的儿子指针为空，或已经是叶子结点；
关键字集合分布在整颗树中；
任何一个关键字出现且只出现在一个结点中；
搜索有可能在非叶子结点结束；
其搜索性能等价于在关键字全集内做一次二分查找；
自动层次控制；
由于限制了除根结点以外的非叶子结点，
至少含有M/2个儿子，确保了结点的至少利用率。
所以B-树的性能总是等价于二分查找（与M值无关），
也就没有B树平衡的问题；
由于M/2的限制，在插入结点时，
如果结点已满，需要将结点分裂为两个各占M/2的结点；
删除结点时，需将两个不足M/2的兄弟结点合并；

## -3:B+Tree 索引

B+Tree 是在 B-Tree 基础上的一种优化，使其更适合实现外存储索引结构，
InnoDB存储引擎就是用 B+Tree 实现其索引结构。

B-Tree 结构图中可以看到，每个节点中不仅包含数据的 key 值，还有 data 值。
而每一个页的存储空间是有限的，
如果 data 数据较大时将会导致每个节点（即一个页）能存储的 key 的数量很小，
当存储的数据量很大时同样会导致 B-Tree 的深度较大，
增大查询时的磁盘 I/O 次数，进而影响查询效率。
在 B+Tree 中，所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，
而非叶子节点上只存储 key 值信息，这样可以大大加大每个节点存储的 key 值数量，
降低 B+Tree 的高度。

## -4:B+Tree与B-Tree区别

1. 非叶子节点只存储键值信息。
2. 所有叶子节点之间都有一个链指针。
3. 数据记录都存放在叶子节点中。

# 26.索引----最左匹配特性

当 B+Tree 的数据项是复合的数据结构，
比如索引 (name, age, sex) 的时候，B+Tree 是按照从左到右的顺序来建立搜索树的。

```java
  1. 比如当 (张三, 20, F) 这样的数据来检索的时候，
     B+Tree 会优先比较 name 来确定下一步的所搜方向，
     如果 name 相同再依次比较 age 和 sex ，最后得到检索的数据。
   2. 当 (20, F) 这样的没有 name 的数据来的时候，
      B+Tree 就不知道下一步该查哪个节点，
      因为建立搜索树的时候 name 就是第一个比较因子，
      必须要先根据 name 来搜索才能知道下一步去哪里查询。
   3. 当 (张三, F) 这样的数据来检索时，B+Tree 可以用 name 来指定搜索方向，
      但下一个字段 age 的缺失，所以只能把名字等于张三的数据都找到，
      然后再匹配性别是 F 的数据了。
```

# 27.索引---B-tree索引分类

1. 主键索引
2. 非主键索引

主键索引的叶子节点存的数据是整行数据( 即具体数据 )。
        在 InnoDB 里，主键索引也被称为聚集索引（clustered index）。---引入存储引擎
        MyISAM 的索引方式也叫做非聚集索引
非主键索引的叶子节点存的数据是整行数据的主键，键值是索引。
        在 InnoDB 里，非主键索引也被称为辅助索引（secondary index）。---引入存储引擎

# 28.索引---B+tree比较

#### 12-3-1-2：B+树与红黑树比较

1. 更少的查找次数
   复杂度和树高h相关，红黑树的树高h很明显比B+Tee大非常多，
   查找的次数也就更多。
2. 利用磁盘预读特性
   为了减少磁盘IO操作，磁盘往往不是严格按需读取，
   而是每次都会预读。预读过程中，磁盘进行顺序读取，
   顺序读取不需要进行磁盘寻道，
   并且只需要很短的旋转时间，速度会非常快。

#### 12-3-1-3：B+树与hash索引比较

1. 如果是等值查询，那么哈希索引明显有绝对优势，
   因为只需要经过一次算法即可找到相应的键值。
   这个前提是，键值都是唯一的。 
   如果键值不是唯的，就需要先找到该键所在位置，
   然后再根据链表往后扫描，直到找到相应的数据:
2. 如果是范围查询检索，原先是有序的键值，
   经过哈希算法后，有可能变成不连续的了，
   就没办法再利用索引完成范围查询检索:

## 12-3-1-1：B+树比B树的优势

1. B+树空间利用率更高，可减少I/O次数
   一般来说，索引本身也很大，不可能全部存储在内存中，
   因此索引往往以索引文件的形式存储的磁盘上。这样的话，
   索引查找过程中就要产生磁盘1O消耗。
   而因为B+树的内部节点只是作为索引使用，
   而不像B-树那样每个节点都需要存储硬盘指针。
   也就是说: B+树中每个非叶子节点
   没有指向某个关健字具体信息的指针，
   所以好个节点可以存放更多的关键字数量，
   减少了I/0操作。
2. 增删文件(节点)时，效率更高
   因为B+树的叶子节点包含所有关键字，
   并以有序的链表结构存储，
   这样可很好提高增删效率，
   基于范围查询更好。
3. B+树的查询效率更加稳定
   因为B+树的每次查询过程中，
   都需要遍历从根节点到叶子节点的某条路径。
   所有关键字的查询路径长度相同，
   导致每一次查询的效率相当。


# 29.索引---引擎器索引

MyISAM 索引的实现，和 InnoDB 索引的实现是一样使用 B+Tree ，

## -1:两种引擎器索引区别

差别在于 MyISAM 索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。

## -2:MyISAM 索引实现

MyISA索引的实现主要依赖B+树

MyISAM 中索引检索的算法为首先按照 B+Tree 搜索算法搜索索引，
如果指定的 Key 存在，则取出其 data 域的值，
然后以 data 域的值为地址，读取相应数据记录。

1）主键索引：
   MyISAM引 擎使用B+Tree作为索引结构，叶节点的data域存放的是数据记录的地址
2）辅助索引：
    在 MyISAM 中，主索引和辅助索引在结构上没有任何区别，只是主索引要求 key 是唯一的，
    而辅助索引的 key 可以重复。

## -3:InnoDB索引实现

## -4:MyISAM 索引与 InnoDB 索引的区别

1. InnoDB 索引是聚簇索引，MyISAM 索引是非聚簇索引。
2. InnoDB 的主键索引的叶子节点存储着行数据，因此主键索引非常高效。
3. MyISAM 索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。
4. InnoDB 非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。

# 30.索引---聚簇/非聚簇索引

## -1:聚簇索引优缺点

`一、优点`
    由于数据都是紧密相连，数据库不用从多个数据块中提取数据，
    所以节省了大量的io操作。
`二、缺点`
   1. 对于mysql数据库目前只有innodb数据引擎支持聚簇索引，
      而Myisam并不支持聚簇索引。
   2. 由于数据物理存储排序方式只能有一种，
      所以每个Mysql的表只能有一个聚簇索引。
      一般情况下就是该表的主键。
   3. 为了充分利用聚簇索引的聚簇的特性，
      所以innodb表的主键列尽量选用有序的顺序id，
      而不建议用无序的id，比如uuid这种。

## -2:聚簇索引注意事项

为什么主键需要自增id
1. 插入速度严重依赖于插入顺序，按照主键的顺序插入是最快的方式，
   否则将会出现页分裂，严重影响性能。
   因此，对于 InnoDB 表，我们一般都会定义一个自增的 ID 列为主键。

2. 更新主键的代价很高，因为将会导致被更新的行移动。
    因此，对于InnoDB 表，我们一般定义主键为不可更新

3. 二级索引访问需要两次索引查找，第一次找到主键值，第二次根据主键值找到行数据。

4. 主键 ID 建议使用整型。因为，每个主键索引的 B+Tree 节点的键值
   可以存储更多主键 ID ，每个非主键索引的 B+Tree 节点的数据可以存储更多主键 ID 。

## -3：非聚簇索引的优缺点

`一、优点`
   更新代价比聚集索引要小，非聚集索引的叶子节点是不存放数据的
`二、缺点`
   非聚集索引也依赖于有序的数据
   可能会二次查询(回表) 
   当查到索引对应的指针或主键后，
   可能还需要根据指针或主键再到数据文件或表中查询。

# 31.索引---覆盖索引

指的是基于非主键索引查询，但是查询字段只有主键 ID ，那么在二级索引中就可以查找到。

# -----------------------------------------------------------------------------------

# -----------------------------------------------------------------------------------

# 引擎----概念

数据库引擎:用于存储、处理、保护数据的核心服务。
当你访问数据库时，不管是手工访问，还是程序访问，
都不是直接读写数据库文件，而是通过数据库引擎去访问数据库文件

# 引擎---分类

1. MyISAM
2. InnoDB
3. Memory

## -1:MySQL存储引擎MyISAM与InnoDB区别

1、MyISAM是非事务安全的，而InnoDB是事务安全的
2、MyISAM锁的粒度是表级的，而 InnoDB支持行级锁
3、MyISAM支持全文类型索引，而InnoDB不支持全文索引
4、MylSAM相对简单，效率上要优于InnoDB，小型应用可以考虑使用MyISAM
5、MyISAM表保存成文件形式，跨平台使用更加方便
6、MylSAM管理非事务表，提供高速存储和检索以及全文搜索能力，如果在应用中执行大
量select 操作可选择
7、InnoDB用于事务处理，具有ACID事务支持等特性，如果在应用中执行大量 insert 和update操作，可选择。
8、InnoDB支持外键（从A表一个列（外键）去检索B表的主键）
9、MyISAM一般是非聚集索引，InnoDB是聚集索引

# 引擎器----InnoDB

InnoDB具有四大特性：
1. 插入缓冲（insert buffer)
2. 二次写(double write)
3. 自适应哈希索引(ahi)
4. 预读(read ahead)
   InnoDB使用两种预读算法来提高I/O性能：线性预读（linear read-ahead）和随机预读（randomread-ahead）
   为了区分这两种预读的方式，我们可以把线性预读放到以extent为单位，
   而随机预读放到以extent中的page为单位。线性预读着眼于将下一个extent提前读取到buffer pool中，
   而随机预读着眼于将当前extent中的剩余的page提前读取到buffer pool中。

# 引擎器

# 引擎器---MyISAM


# 引擎器---两种引擎所使用的锁

MyISAM采用表级锁(table-level locking)。
InnoDB支持行级锁(row-level locking)和表级锁,默认为行级锁

# 引擎所用的锁---MyISAM

只有表锁，表锁

# 引擎所用的锁---InnoDB


## 三种算法

1. Record Lock(记录锁): 单个行记录上的锁。
                       Record Lock总是会去锁住索引记录，
                       如果InnoDB存储引擎表在建立的时候没有设置任何一个索引，
                       那么这时InnoDB存储引擎会使用隐式的主键来进行锁定。
2. Gap Lock（间隙锁）：间隙锁，锁定一个范围，但不包含记录本身。
3. Next-Key Lock（临键锁）：Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身。


## -1:InnoDB引擎什么时候使用表锁

1. 第一种情况是：
   事务需要更新大部分或全部数据，表又比较大，
   如果使用默认的行锁，不仅这个事务执行效率低，
   而且可能造成其他事务长时间锁等待和锁冲突，
   这种情况下可以考虑使用表锁来提高该事务的执行速度。

2. 第二种情况是：
   事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚。
   这种情况也可以考虑一次性锁定事务涉及的表，
   从而避免死锁、减少数据库因事务回滚带来的开销。

# ——————————————————————————————————————————————————————————————————————————————————————————————————————————————————————

# ——————————————————————————————————————————————————————————————————————————————————————————————————————————————————————

# 锁---概念

数据库锁出现的目的：处理并发问题
并发控制的主要采用的技术手段：乐观锁、悲观锁和时间戳。

![1](https://blog.csdn.net/qq_35688140/article/details/102229891?utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.base&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromMachineLearnPai2%7Edefault-1.base)

# 锁---锁种类

数据库锁，主要分为了乐观锁和悲观锁

其中乐观锁就很简单了

悲观锁住要分为了
   1. 表级锁
      - 共享锁（s锁）
      - 排他锁（x锁）
      - 意向锁（是解决行锁与表锁冲突）
   2. 行级锁
      - 共享锁
      - 排他锁
      - 更新锁
   3. 页级锁

# 悲观锁---概念

每次去拿数据的时候都认为别人会修改，
所以每次在拿数据的时候都会上锁，
这样别人拿这个数据就会block（阻塞），直到它拿锁。

# 乐观锁---概念

每次去拿数据的时候都认为别人不会修改，所以，不会上锁。
但是在更新的时候会判断一下在此期间别人有没有更新这个数据，可以使用版本号等机制。

# 乐观锁---实现方式

1. 版本号
2. 时间戳
3. 待更新字段
4. 所有字段

## 版本号---概念

就是给数据增加一个版本标识，在数据库上就是表中增加一个version字段，
每次更新把这个字段加1，读取数据的时候把version读出来，
更新的时候比较version，如果还是开始读取的version就可以更新了，
如果现在的version比老的version大，说明有其他事务更新了该数据，并增加了版本号，
这时候得到一个无法更新的通知，
用户自行根据这个通知来决定怎么处理，比如重新开始一遍。
主要是判断version和更新两个动作需要作为一个原子单元执行，
否则在你判断可以更新以后正式更新之前有别的事务修改了version，
这个时候你再去更新就可能会覆盖前一个事务做的更新，
造成第二类丢失更新，----------**事务---并发问题**
所以可以使用update … where … and version=”old version”这样的语句，
根据返回结果是0还是非0来得到通知，如果是0说明更新没有成功，
因为version被改了，如果返回非0说明更新成功。

## 时间戳（timestamp）

和版本号基本一样，只是通过时间戳来判断而已，
注意时间戳要使用数据库服务器的时间戳不能是业务系统的时间。

## 待更新字段

和版本号方式相似，只是不增加额外字段，直接使用有效数据字段做版本控制信息，
因为有时候我们可能无法改变旧系统的数据库表结构。
假设有个待更新字段叫count,先去读取这个count,
更新的时候去比较数据库中count的值是不是我期望的值（即开始读的值），
如果是就把我修改的count的值更新到该字段，否则更新失败。
java的基本类型的原子类型对象如AtomicInteger就是这种思想。

## 所有字段

和待更新字段类似，只是使用所有字段做版本控制信息，
只有所有字段都没变化才会执行更新。

## 乐观锁几种方式的区别

新系统设计可以使用version方式和timestamp方式，需要增加字段，
应用范围是整条数据，不论那个字段修改都会更新version,
也就是说两个事务更新同一条记录的两个不相关字段也是互斥的，不能同步进行。
旧系统不能修改数据库表结构的时候使用数据字段作为版本控制信息，
不需要新增字段，
待更新字段方式只要其他事务修改的字段
和当前事务修改的字段没有重叠就可以同步进行，并发性更高。

# 行锁、表锁---概念

行锁--锁的作用范围是行级别。
表锁--锁的作用范围是整张表。

# 共享锁（读锁）---概念

用于所有的只读数据操作。共享锁是非独占的，允许多个并发事务读取其锁定的资源。

性质
   1. 多个事务可封锁同一个共享页；
   2. 任何事务都不能修改该页；
   3. 通常是该页被读取完毕，S锁立即被释放。

# 排他锁---概念

表示对数据进行写操作。如果一个事务对对象加了排他锁，其他事务就不能再给它加任何锁了

性质
1. 仅允许一个事务封锁此页；
2. 其他任何事务必须等到X锁被释放才能对该页进行访问；
3. X锁一直到事务结束才能被释放。

# 更新锁---概念

在修改操作的初始化阶段用来锁定可能要被修改的资源，这样可以避免使用共享锁造成的死锁现象。

因为当使用共享锁时，修改数据的操作分为两步：
   1. 首先获得一个共享锁，读取数据，
   2. 然后将共享锁升级为排他锁，再执行修改操作。

这样如果有两个或多个事务同时对一个事务申请了共享锁，
在修改数据时，这些事务都要将共享锁升级为排他锁。
这时，这些事务都不会释放共享锁，而是一直等待对方释放，这样就造成了死锁。
如果一个数据在修改前直接申请更新锁，在数据修改时再升级为排他锁，就可以避免死锁。

# 锁---死锁

如果一个资源被锁定，它总会在以后某个时间被释放。而死锁发生在当多个进程访问同一数据库时，
其中每个进程拥有的锁都是其他进程所需的，由此造成每个进程都无法继续下去。
比如说进程 A 等待进程 B 释放他的资源，B 又等待 A 释放他的资源，这样就互相等待就形成死锁。

## -1:死锁必备条件

1. 互斥条件：指进程对所分配到的资源进行排它性使用，
            在一段时间内某资源只由一个进程占用。如果此时还有其它进程请求资源，
            则请求者只能等待，直至占有资源的进程用毕释放。

2. 请求和保持条件：指进程已经保持至少一个资源，但又提出了新的资源请求，
                 而该资源已被其它进程占有，此时请求进程阻塞，
                 但又对自己已获得的其它资源保持不放。

3. 不剥夺条件：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。

4. 环路等待条件：指在发生死锁时，必然存在一个进程——资源的环形链，
               即进程集合 {P0，P1，P2，•••，Pn} 
               中的 P0 正在等待一个 P1 占用的资源；
               P1 正在等待 P2 占用的资源，……，
               Pn 正在等待已被 P0 占用的资源。

## -2:预防与解除

1. 应尽可能缩短事务。在同一DB中并发执行多个需要长时间运行的事务时，
   发生死锁的概率较大。事务运行时间越长，其持有排它锁（exclusive锁）或更
   新锁（update锁）的时间便越长，
   从而堵塞了其它活动并可能导致死锁。
   保持事务在一个批处理中，
   可以最小化事务的网络通信往返量，
   减少完成事务可能的延迟并释放锁。
   同时，涉及多个表的查询更新操作，
   若比较耗时，尽量不要放在一个事务内处理，
   能分割便分割。若不能分割，便尽可能使之在业务量较小的时间
   (例如子夜或者午餐时间)执行。
2. 应按同一顺序访问数据对象。
   如果所有并发事务按同一顺序访问对象，
   则发生死锁的可能性会降低。
   例如，如果两个并发事务获得Supplier 表上的锁，
   然后获得Part表上的锁，
   则在其中一个事务完成之前，
   另一个事务被阻塞在Supplier表上。
   第一个事务提交或回滚后，第二个事务继续进行。
   不发生死锁。
   将存储过程用于所有的数据修改可以标准化访问对象的顺序。
3. 必须避免编写包含用户交互的事务。
   因为运行没有用户交互的批处理的速度要
   远远快于用户手动响应查询的速度，
   若用户不能及时反馈，则此事务将挂起。
   因而将严重降低系统的吞吐量，
   因为事务持有的任何锁只有在事务提交或回滚时才会释放。
   即使不出现死锁的情况，
   访问同一资源的其它事务也会被阻塞，等待该事务完成。
4. 可使用低隔离级别。
   确定事务是否能在更低的隔离级别上运行。
   执行提交读允许事务读取另一个事务已读取（未修改）的数据，
   而不必等待第一个事务完成。
   使用较低的隔离级别（例如提交读）
   而不使用较高的隔离级别（例如可串行读）
   可以缩短持有共享锁的时间，
   从而降低了锁定争夺。
5. 可考虑体系结构的优化与代码重构，
   提高系统整体的运行效率。
   例如尽可能不采用效率低下的计算模型，
   复杂的业务应采用异步任务调度处理。
6. 可通过程序控制事务提交的时机。
   如果一次检索出了10万条记录但只更改了其中的100条，
   就可以通过代码来执行100个update。或是用分段提交，
   即所有的修改使用多个事务进行提交，
   但这样会使事务不完整，应酌情使用。
7. 宜将经常更新的数据库和查询数据库分开。
   定期将不改变的数据导入查询数据库中，
   这样查询和更新就可以分开进行，而降低死锁机率。
8. 在进行数据库模式设计时，
   应注意外键引用的完整性，并对外键加索引。
   如果更新了父表的主键，由于外键上没有索引，
   所以子表会被锁定；如果删除了父表中的一行，整个子表也会被锁定。


# 锁---隔离级别与锁

SQL使用锁来实现事务的隔离。
事务获取锁这种控制资源，
用于保护数据资源，
防止其他事务对数据进行冲突的或不兼容的访问。
比如说
读未提交，可以通过写操作加“持续-X锁”实现。
读已提交，可以通过写操作加“持续-X”锁，读操作加“临时-S锁”实现。
可重复读，可以通过写操作加“持续-X”锁，读操作加“持续-S锁”实现。

# 锁---MVCC

代表多版本并发控制，读不加锁，读写不冲突

MVCC是通过在每行记录后面保存两个隐藏的列来实现的。
这两个列，一个保存了行的创建时间，
一个保存行的过期时间（或删除时间）。
当然存储的并不是实际的时间值，
而是系统版本号（system version number)。
每开始一个新的事务，系统版本号都会自动递增。
事务开始时刻的系统版本号会作为事务的版本号，
用来和查询到的每行记录的版本号进行比较。

MVCC最大的好处，：读不加锁，读写不冲突。
                 在读多写少的OLTP应用中，
                 读写不冲突是非常重要的，
                 极大的增加了系统的并发性能，
在MVCC并发控制中，读操作可以分成两类：快照读 (snapshot read)与当前读 (current read) 。
快照读，读取的是记录的可见版本 (有可能是历史版本)，不用加锁。
当前读，读取的是记录的最新版本，并且，当前读返回的记录，
都会加上锁，保证其他事务不会再并发修改这条记录。

# 锁---加锁

## 11-8：加锁过程

`组合一：id主键+RC`

id是主键，Read Committed隔离级别，
给定SQL：delete from t1 where id = 10; 
只需要将主键上，id = 10的记录加上X锁即可。

`组合二：id唯一索引+RC`

id不是主键，而是一个Unique的二级索引键值。
那么在RC隔离级别下，delete from t1 where id = 10; 
由于id是unique索引，
因此delete语句会选择走id列的索引进行where条件的过滤，
在找到id=10的记录后，首先会将unique索引上的id=10索引记录加上X锁，
同时，会根据读取到的name列，回主键索引(聚簇索引)，
然后将聚簇索引上的name = ‘d’ 对应的主键索引项加X锁。
聚簇索引上的记录也要加锁主要是如果并发的一个SQL，
是通过主键索引来更新：update t1 set id = 100 where name = ‘d’; 
此时，如果delete语句没有将主键索引上的记录加锁，
那么并发的update就会感知不到delete语句的存在，
违背了同一记录上的更新/删除需要串行执行的约束。

`组合三：id非唯一索引+RC`

id列不再唯一，只有一个普通的索引。
假设delete from t1 where id = 10; 语句，
仍旧选择id列上的索引进行过滤where条件，
比如说在id列索引上，满足id = 10查询条件的记录，均已加锁。
同时，这些记录对应的主键索引上的记录也都加上了锁。

`组合四：id无索引+RC`

id列上没有索引，where id = 10;这个过滤条件，没法通过索引进行过滤，
那么只能走全表扫描做过滤。全表扫描时，
由于id列上没有索引，因此只能走聚簇索引，
进行全部扫描。但是，聚簇索引上所有的记录，都被加上了X锁�����
无论记录是否满足条件，全部被加上X锁。既不是加表锁，
也不是在满足条件的记录上加行锁。
由于MySQL的内部实现决定的。如果一个条件无法通过索引快速过滤，
那么存储引擎层面就会将所有记录加锁后返回，
然后由MySQL Server层进行过滤。因此也就把所有的记录，都锁上了。

`组合五：id主键+RR`

id列是主键列，Repeatable Read隔离级别，
针对delete from t1 where id = 10; 这条SQL，
加锁与组合一：[id主键，Read Committed]一致。

`组合六：id唯一索引+RR`

与组合二：[id唯一索引，Read Committed]一致。
两个X锁，id唯一索引满足条件的记录上一个，对应的聚簇索引上的记录一个。

组合七：id非唯一索引+RR

# ——————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————
# ——————————————————————————————————————————————————————————————————————————————————————————————————————————————————————————

# 13.优化---原因

1. 避免网站页面出现访问错误
   由于慢查询造成页面无法加载
   由于阻塞造成数据无法提交
   增加数据库的稳定性
2. 很多数据库问题都是由于低效的查询引起的

# 优化---方案

1. explain优化
2. 数据库优化
3. 索引优化
4. 查询优化
5. 创建时优化
6. 分页查询优化

# 优化方案---explain优化

通过expalin就能知道MySQL是如何处理你的SQL语句的。
分析你的查询语句或是表结构的性能瓶颈

## -1：explain应用场景

1. 表的读取顺序
2. 哪些索引可以使用
3. 数据读取操作的操作类型
4. 哪些索引被实际使用
5. 表之间的引用
6. 每张表有多少行被优化器查询

## -2：如何使用explain

explain关键字+sql语句

## -3：explain主要包含的信息
   
   id   select_type    table     partitions
   type possible_keys  key       key_len
   ref  rows           filtered  extra

# 优化方案---数据库优化

1. `限定数据的范围`
务必禁止不带任何限制数据范围条件的查询语句。
比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内；
2. `读/写分离`
经典的数据库拆分方案，主库负责写，从库负责读；
3. `垂直分区`
根据数据库里面数据表的相关性进行拆分。 
4. `水平分区`
保持数据表结构不变，通过某种策略存储数据分片。
这样每一片数据分散到不同的表或者库中，
达到了分布式的目的。 
水平拆分可以支撑非常大的数据量。

注意：`垂直分区与水平分区`去看*分库分表*

# 优化方案---索引优化

1、建立聚集索引
   首先聚合索引是提升查询速度的最有效的手段。
   基于聚合索引的性质可以知道
   数据库的物理存储顺序是按照聚合索引顺序排列的，
   而通过聚合索引的B+树，我们可以迅速
   的查找到任何一行的全部信息。
2、常查询数据建立索引或者组合索引
3、最左前缀原则
   建立组合索引优化查询语句时，一定要考虑到最左前缀原则，否则你的索引建立的可以说毫无意义
4、较长的数据列建立前缀索引;
5、不要建立无意义的索引
   对于查询次数很少的语句中的字段的索引、备注描述和大字段的索引等

# 优化方案---查询优化

1、使用 Explain进行分析
   Explain用来分析SELECT 查询语句，
 
2、优化数据访问
   （1）减少请求的数据量
         只返回必要的列:最好不要使用SELECT*语句。
         只返回必要的行:使用 LIMIT 语句来限制返回的数据。
         缓存重复查询的数据:使用缓存可以避免在数据库中进行查询，特别在要查询的数据经常被
         重复查询时，缓存带来的查询性能提升将会是非常明显的。
   （2）减少服务器端扫描的行数
         最有效的方式是使用索引来覆盖查询。
3、重构查询方式
（1）切分大查询
一个大查询如果一次性执行的话，可能一次锁住很多数据、耗尽系统资源、阻塞很多小的但重要的查询。
DELETE FROM messages WHERE create <DATE sLIB(NOWoINTERVAL 3 MONTH);
rows_affected= O
do {
rows_affected= do_query(
"DELETEFROM messages WHEREcreate<DATE SUB(NOWO.INTERVAL 3 MONTH)
LIMIT10000")
}while rows_affected>0
(2）分解大连接查询
将一个大连接查询分解成对每一个表进行一次单表查询，然后在应用程序中进行关联，这样
做的好处有:
让缓存更高效。对于连接查询，如果其中一个表发生变化，那么整个查询缓存就无法使用。
而分解后的多个查询，即使其中一个表发生变化，对其它表的查询缓存依然可以使用。
分解成多个单表查询，这些单表查询的缓存结果更可能被其它查询使用到，从而减少冗余记
录的查询。

## 13-6：慢查询优化

1. 索引没起作用的情况
       1. 使用LIKE关键字的查询语句
          在使用LIKE关键字进行查询的查询语句中，
          如果匹配字符串的第一个字符为“%”，
          索引不会起作用。只有“%”不在第一个位置索引才会起作用。
       2. 使用多列索引的查询语句
          MySQL可以为多个字段创建索引。
          一个索引最多可以包括16个字段。
          对于多列索引，
          只有查询条件使用了
          这些字段中的第一个字段时
          索引才会被使用。
2. 优化数据库结构
      合理的数据库结构不仅可以
      使数据库占用更小的磁盘空间，
      而且能够使查询速度更快。
      数据库结构的设计，
      需要考虑数据冗余、
      查询和更新的速度、
      字段的数据类型是否合理等多方面的内容。
      1. 将字段很多的表分解成多个表 
         对于字段比较多的表，如果有些字段的使用频率很低，
         可以将这些字段分离出来形成新表。
         因为当一个表的数据量很大时，
         会由于使用频率低的字段的存在而变慢。
      2. 增加中间表
         对于需要经常联合查询的表，
         可以建立中间表以提高查询效率。
         通过建立中间表，
         把需要经常联合
         查询的数据插入到中间表中，
         然后将原来的联合查询
         改为对中间表的查询，
         以此来提高查询效率。
3. 分解关联查询
   将一个大的查询分解为多个小查询是很有必要的。
   很多高性能的应用都会对关联查询进行分解，
   就是可以对每一个表进行一次单表查询，
   然后将查询结果在应用程序中进行关联，
   很多场景下这样会更高效，  
4. 优化LIMIT分页

# 优化方案---创建时优化

1. 数据类型优化
   1. 尽量使用对应的数据类型。
      比如，不要用字符串类型保存时间，用整型保存IP。
   2. 选择更小的数据类型。能用TinyInt不用Int。
   3. 标识列（identifier column），
      建议使用整型，不推荐字符串类型，
      占用更多空间，而且计算速度比整型慢。
   4. 不推荐ORM系统自动生成的Schema，
      通常具有不注重数据类型，
      使用很大的VarChar类型，索引利用不合理等问题。
   5. 真实场景混用范式和反范式。
      冗余高查询效率高，插入更新效率低；
      冗余低插入更新效率高，查询效率低。
   6. 创建完全的独立的汇总表\缓存表，
      定时生成数据，用于用户耗时时间长的操作。
      对于精确度要求高的汇总操作，
      可以采用 历史结果+最新记录的结果 来达到快速查询的目的。
   7. 数据迁移，表升级的过程中可以使用影子表的方式，
      通过修改原表的表名，达到保存历史数据，
      同时不影响新表使用的目的。
2. 索引优化
   注意每种索引的适用范围和适用限制。
   索引的列如果是表达式的一部分或者是函数的参数，则失效。
   针对特别长的字符串，可以使用前缀索引，根据索引的选择性选择合适的前缀长度。
   使用多列索引的时候，可以通过 AND 和 OR 语法连接。
   重复索引没必要，如（A，B）和（A）重复。
   索引在where条件查询和group by语法查询的时候特别有效。
   将范围查询放在条件查询的最后，防止范围查询导致的右边索引失效的问题。
   索引最好不要选择过长的字符串，而且索引列也不宜为null。

# 优化方案---分页查询优化

因为分页查询方式会从数据库第一条记录开始扫描，
所以越往后，查询速度越慢，而且查询的数据越多，也会拖慢总查询速度。

1. 使用子查询优化，这种方式先定位偏移位置的 id，然后往后查询，这种方式适用于 id 递增的情况。
2. 使用 id 限定优化，这种方式假设数据表的id是连续递增的，
   则我们根据查询的页数和查询的记录数可以算出查询的id的范围，可以使用 id between and 来查询：
3. 使用临时表优化，这种应该不属于查询优化，对于使用 id 限定优化中的问题，
   需要 id 是连续递增的，但是在一些场景下，
   比如使用历史表的时候，或者出现过数据缺失问题时，
   可以考虑使用临时存储的表来记录分页的id，
   使用分页的id来进行 in 查询。
   这样能够极大的提高传统的分页查询速度，尤其是数据量上千万的时候。

# ——————————————————————————————————————————————————————————————————————————————————————————————————————————————————————

# ——————————————————————————————————————————————————————————————————————————————————————————————————————————————————————

# MySQL实际应用

## -1:一条SQL语句执行得很慢的原因有哪些

要分两种情形：

1. 大多数情况是正常的，只是偶尔会出现很慢的情况。
   
   * 数据库在刷新脏页，例如 redo log 写满了需要同步到磁盘。
      
      当我们要往数据库插入一条数据、或者要更新一条数据的时候，
      我们知道数据库会在内存中把对应字段的数据更新了，但是更新之后，
      这些更新的字段并不会马上同步持久化到磁盘中去，
      而是把这些更新的记录写入到 redo log 日记中去，等到空闲的时候，
      在通过 redo log 里的日记把最新的数据同步到磁盘中去。

      当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。
      比如说：
       1. redolog写满了：redo log 里的容量是有限的，
          如果数据库一直很忙，更新又很频繁，这个时候 redo log 很快就会被写满了，
          这个时候就没办法等到空闲的时候再把数据同步到磁盘的，只能暂停其他操作，
          全身心来把数据同步到磁盘中去的，而这个时候，
          就会导致我们平时正常的SQL语句突然执行的很慢，
          所以说，数据库在在同步数据到磁盘的时候，就有可能导致我们的SQL语句执行的很慢了。

       2. 内存不够用了：如果一次查询较多的数据，恰好碰到所查数据页不在内存中时，
          需要申请内存，而此时恰好内存不足的时候就需要淘汰一部分内存数据页，
          如果是干净页，就直接释放，如果恰好是脏页就需要刷脏页。

       3. MySQL 认为系统“空闲”的时候：这时系统没什么压力。

       4. MySQL 正常关闭的时候：这时候，MySQL 会把内存的脏页都 flush 到磁盘上，
         这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。

   * 执行的时候，遇到锁，如表锁、行锁。

2. 在数据量不变的情况下，这条SQL语句一直以来都执行的很慢。
   
   * 没有用上索引
   * 数据库选错了索引

### -1-2：为什么数据库会选错了索引

系统在执行的时候，会进行预测，
是走 c 索引扫描的行数少，
还是直接扫描全表扫描的行数少
扫描全表的话，那么扫描的次数就是这个表的总行数了，
假设为 n；而如果走索引c的话，
我们通过索引c找到主键之后，
还得再通过主键索引来找我们整行的数据，
需要走两次索引，
而且，我们也不知道符合
这个条件的数据有多少行，
万一真的是n条，
那就惨了，
所以系统是有可能走全表扫描而不走索引的
系统如何进行预判
主要依赖于索引的区分度来判断的，
一个索引上不同的值越多，
意味着出现相同数值的索引越少，
意味着索引的区分度越高。
这个区分度也叫做基数，
系统当然是不会遍历全部来
获得一个索引的基数的，
代价太大了，
索引系统是通过遍历部分数据，
也就是通过采样的方式，
来预测索引的基数的
那么出现失误的地方就是采样，
比如采样的那一部分数据刚好基数很小，
然后就误以为索引的基数很小。
然后，系统就不走索引了，
直接走全部扫描了。
主要是由于统计的失误，
导致系统没有走索引，
而是走了全表扫描。


## 13-10:MySQL 数据库 CPU 飙升到 500% 的话，怎么处理？

1. 先看看是不是IO压力较大，可以使用iostat命令，查看哪个进程占用了磁盘IO

## 8-11-2：MySQL 如何高效率随机获取N条数据？

ID连续的情况下（注意不能带where，否则结果不好）：

```sql
SELECT *
FROM `mm_account` AS t1 
JOIN (SELECT ROUND(RAND() * (SELECT MAX(id) FROM `mm_account`)) 
AS id) AS t2
WHERE t1.id >= t2.id
ORDER BY t1.id ASC LIMIT 4;
```

ID不连续的情况下：

```sql
SELECT * FROM `mm_account` 
WHERE id >= 
(SELECT floor(RAND() * (SELECT MAX(id) FROM `mm_account`)))  
and city="city_91" and showSex=1
ORDER BY id LIMIT 4;
```

如果有一个字段叫id，最快的方法如下（随机获取5条）：

```sql
SELECT * FROM mm_account 
WHERE id >= 
((SELECT MAX(id) FROM mm_account)-
(SELECT MIN(id) FROM mm_account)) * RAND() 
+ (SELECT MIN(id) FROM mm_account)
limit 5;
```
如果带where语句，上面就不适合了，带where语句请看下面：
```sql
SELECT *
FROM `mm_account` AS t1 
JOIN (SELECT ROUND(RAND() * (
(SELECT MAX(id) 
FROM `mm_account` where id<1000 )
-(SELECT MIN(id) FROM `mm_account` 
where id<1000 ))+(SELECT MIN(id) 
FROM `mm_account` where id<1000 )) 
AS id) AS t2
WHERE t1.id >= t2.id
ORDER BY t1.id LIMIT 5;
```


# 14.慢查询---概念

它用来记录在MySQL中响应时间超过阀值的语句日志记录

# 15.主从复制---概念

主从复制，是用来建立一个和主数据库完全一样的数据库环境，
称为从数据库；主数据库一般是准实时的业务数据库。

## 15-1：主从复制的好处

1、做数据的热备，作为后备数据库，主数据库服务器故障后，
   可切换到从数据库继续工作，避免数据丢失。
2、架构的扩展。业务量越来越大，I/O访问频率过高，
  单机无法满足，此时做多库的存储，降低磁盘I/O访问的频率，
  提高单个机器的I/O性能。
3、读写分离，使数据库能支撑更大的并发。
   在报表中尤其重要。由于部分报表sql语句非常的慢，
   导致锁表，影响前台服务。如果前台使用master，
   报表使用slave，
   那么报表sql将不会造成前台锁，保证了前台速度。

# 主从复制---原理

步骤一：主库db的更新事件(update、insert、delete)被写到binlog
步骤二：从库发起连接，连接到主库
步骤三：此时主库创建一个binlog dump thread，把binlog的内容发送到从库
步骤四：从库启动之后，创建一个I/O线程，
       读取主库传过来的binlog内容并写入到relay log
`具体需要三个线程来操作：`
binlog输出线程。每当有从库连接到主库的时候，
主库都会创建一个线程然后发送binlog内容到从库。
在从库里，当复制开始的时候，
从库就会创建两个线程进行处理：
从库I/O线程。当START SLAVE语句在从库开始执行之后，
从库创建一个I/O线程，
该线程连接到主库并请求主库
发送binlog里面的更新记录到从库上。
从库I/O线程读取主库的binlog输出线程
发送的更新并拷贝这些更新到本地文件，
其中包括relay log文件。
从库的SQL线程。
从库创建一个SQL线程，
这个线程读取从库I/O线程
写到relay log的更新事件并执行。

# 主从复制---方式

1. 同步复制，意思是master的变化，
   必须等待slave-1,slave-2,...,slave-n完成后才能返回。
   不会使用，比如，在WEB前端页面上，用户增加了条记录，
   需要等待很长时间。
2. 异步复制:如同AJAX请求一样。
   master只需要完成自己的数据库操作即可。
   至于slaves是否收到二进制日志，
   是否完成操作，不用关心,MySQL的默认设置。
3. 半同步复制:master只保证slaves中的一个操作成功，
             就返回，其他slave不管。 
             这个功能，是由google为MySQL引入的。


# 16.阻塞---概念

当多个事务都需要对某一资源进行锁定时，
默认情况下会发生阻塞。
被阻塞的请求会一直等待，
直到原来的事务释放相关的锁。
锁定超时期限可以限制，这样就可以限制被
阻塞的请求在超时之前要等待的时间。
比如说
有两个事务
事务A请求资源S1，
事务不对资源S1进行操作
事务A用锁A锁定资源S1，
事务B请求对资源S1进行不兼容的锁定（锁B）,
锁B的请求被阻塞，事务B将进入等待状态
事务A正在释放锁A，事务B等待锁A释放，
事务A的锁A已释放，事务B用锁B锁定资源S1

# ——————————————————————————————————————————————————————————————————————————————————————————————————————————————————————

# ——————————————————————————————————————————————————————————————————————————————————————————————————————————————————————

# 17.数据库池---概念

因为吧，创建数据库连接是一个很耗时的操作，
也容易对数据库造成安全隐患。
所以，在程序初始化的时候，
集中创建多个数据库连接，并把他们集中管理，
供程序使用，
可以保证较快的数据库读写速度，还更加安全可靠。



### 17-1-5：数据库连接池最小连接数和最大连接

`连接池最小连接数`
最小连接数是连接池一直保持的数据连接。
如果应用程序对数据库连接的使用量不大，将会有大量的数据库连接资源被浪费掉。

`连接池最大连接数`
最大连接数是连接池能申请的最大连接数。如果数据连接请求超过此数，后面的数据连接请求将被加入到等待队列中，这会影响之后的数据库操作。


#### 17-1-5-2：最小连接数和最大连接数的设置要考虑到以下几个因素

1. `最小连接数`:是连接池一直保持的数据库连接,
               所以如果应用程序对数据库连接的使用量不大,
               将会有大量的数据库连接资源被浪费.
2. `最大连接数`:是连接池能申请的最大连接数,
               如果数据库连接请求超过次数,
               后面的数据库连接请求将被加入到等待队列中,
               这会影响以后的数据库操作

如果最小连接数与最大连接数相差太大，
那么，最先的连接请求将会获利，
之后超过最小连接数量的连接请求
等价于建立一个新的数据库连接。
不过，这些大于最小连接数的数据库连接
在使用完不会马上被释放，
它将被放到连接池中等待重复使用
或是空闲超时后被释放。


# 数据库连接池---种类

1, C3P0 C3P0是一个开放源代码的JDBC连接池，
            它在lib目录中与Hibernate[1]一起发布,
            包括了实现jdbc3和jdbc2扩展规范
            说明的Connection 和Statement 池的DataSources 对象。
2,Druid，但它不仅仅是一个数据库连接池，
         它还包含一个ProxyDriver，
         一系列内置的JDBC组件库，一个SQL Parser。

# 数据库连接池---原理

1. 连接池的建立。 
   一般在系统初始化时，连接池会根据系统配置建立，
   并在池中建立几个连接对象，以便使用时能从连接池中获取。
   java 中提供了很多容器类，可以方便的构建连接池，
   例如 Vector（线程安全类），linkedlist 等。
2. 连接池的管理。 
   连接池管理策略是连接池机制的核心，
   连接池内连接的分配和释放对系统的性能有很大的影响。
   主要就是当客户请求数据库连接时，首先查看连接池中是否有空闲连接，
   如果存在空闲连接，则将连接分配给客户使用并作相应处理
   也就是标记该连接为正在使用，引用计数加 1；
   如果没有空闲连接，则查看当前所开的连接数是否已经达到最大连接数，
   如果没有达到最大连接数，就重新创建一个连接给请求的客户；
   如果达到，就按设定的最大等待时间进行等待，
   如果超出最大等待时间，则抛出异常给客户。
   当客户释放数据库连接时，先判断该连接的引用次数是否超过了规定值，
   如果超过了就从连接池中删除该连接，
   并判断当前连接池内总的连接数是否小于最小连接数，
   若小于就将连接池充满；如果没超过就将该连接标记为开放状态，
   可供再次复用。
3. 连接池的关闭。 
   当应用程序退出时，关闭连接池中所有的链接，
   释放连接池相关资源，该过程正好与创建相反。

## -1:传统的连接机制与数据库连接池的运行机制区别

传统统链接: 一般来说，Java应用程序访问数据库的过程是：
　　①装载数据库驱动程序；
　　②通过JDBC建立数据库连接；
　　③访问数据库，执行SQL语句；
　　④断开数据库连接。
使用了数据库连接池的机制：
（1） 程序初始化时创建连接池
（2） 使用时向连接池申请可用连接
（3） 使用完毕，将连接返还给连接池
（4） 程序退出时，断开所有连接，并释放资源

# JDBC---概念


# JDBC---步骤

1. 注册数据库驱动
2. 建立数据库连接
3. 创建一个Statement
4. 执行SQL语句
5. 处理结果集
6. 关闭数据库连接

```java
public class TestDB {
    public static void main(String[] args) {
        Connection conn = null;
        Statement stmt = null;
        ResultSet rs = null;
        // MySQL的JDBC连接语句
        // URL编写格式：jdbc:mysql://主机名称：连接端口/数据库的名称?参数=值
        String url = "jdbc:mysql://localhost:3306/student?user=root&password=123456";
        // 数据库执行的语句
        String sql = "insert into stuinfo values('201307020010','zhangsan',21);";//插入一条记录
        //String sql = "create table stuinfo(id char(12),name char(20),age int);";//创建一个表
        // 查询语句
        String cmd = "select * from stuinfo;";
        try {
            Class.forName("com.mysql.jdbc.Driver"); // 加载驱动
            conn = DriverManager.getConnection(url); // 获取数据库连接
            stmt = conn.createStatement(); // 创建执行环境
            stmt.execute(sql); // 执行SQL语句
            // 读取数据
            rs = stmt.executeQuery(cmd); // 执行查询语句，返回结果数据集
            rs.last(); // 将光标移到结果数据集的最后一行，用来下面查询共有多少行记录
            System.out.println("共有" + rs.getRow() + "行记录：");
            rs.beforeFirst(); // 将光标移到结果数据集的开头
            while (rs.next()) { // 循环读取结果数据集中的所有记录
                System.out.println(rs.getRow() + "、 学号:" + rs.getString("id")
                        + "\t姓名:" + rs.getString("name") + "\t年龄:"
                        + rs.getInt("age"));
            }
        } catch (ClassNotFoundException e) {
            System.out.println("加载驱动异常");
            e.printStackTrace();
        } catch (SQLException e) {
            System.out.println("数据库异常");
            e.printStackTrace();
        } finally {
            try {
                if (rs != null)
                    rs.close(); // 关闭结果数据集
                if (stmt != null)
                    stmt.close(); // 关闭执行环境
                if (conn != null)
                    conn.close(); // 关闭数据库连接
            } catch (SQLException e) {
                e.printStackTrace();}}}}
```
## 17-2-3-1：使用JDBC需要用到哪些类

DirverManager类：是JDBC的管理层，
                 作用bai于用户和驱动之间。
                 该类负责注du册和加载JDBC驱动。
Connection接口：代表与数据库dao的链接，
               并拥有创建SQL语句的方法，
               以完成基本的SQL操作，
               同时为数据库事务提供提交和回滚方法。
Statement接口：用于执行不带参数的简单SQL语句。
               创建Statement实例对象后可以
               调用JDBC提供的3种执行SQL语句的方法






# JDBC---原理

JDBC（Java DataBase Connectivity）就是Java数据库连接，就是用Java语言来操作数据库
由SUN提供一套访问数据库的规范（就是一组接口），
并提供连接数据库的协议标准，
然后各个数据库厂商会遵循SUN的规范
提供一套访问自己公司的数据库服务器的API出现。
SUN提供的规范命名为JDBC，
而各个厂商提供的，遵循了JDBC规范的，
可以访问自己数据库的API被称之为驱动！

# JDBC---常见异常

`java.sql.SQLException`
     这是JDBC异常的基类。
`java.sql.BatchUpdateException`
     当批处理操作执行失败的时候可能会抛出这个异常。
     这取决于具体的JDBC驱动的实现，
     它也可能直接抛出基类异常java.sql.SQLException。
`java.sql.SQLWarning`
     SQL操作出现的警告信息。
`java.sql.DataTruncation`
      字段值由于某些非正常原因被截断了
      （不是因为超过对应字段类型的长度限制）。

# JDBC---事务

Connection类中提供了4个事务处理方法:

setAutoCommit(Boolean autoCommit):设置是否自动提交事务,默认为自动提交,即为true,
                                  通过设置false禁止自动提交事务;
commit():提交事务;
rollback():回滚事务.
savepoint:保存点，savepoint不会结束当前事务，
                 普通提交和回滚都会结束当前事务的


## 17-2-5：JDBC中大数据量的分页解决方法?

最好的办法是利用sql语句进行分页，
这样每次查询出的结果集中就只包含某页的数据内容。

# ————————————————————————————————————————————————————————————————————————————————————————————————————————————————

# ————————————————————————————————————————————————————————————————————————————————————————————————————————————————

# 18.分库分表---原因

1. 从性能方面来说，由于关系型数据库大多采用 B+ 树类型的索引，
   在数据量超过阈值的情况下，索引深度的增加也将使得磁盘访问的 IO 次数增加，
   进而导致查询性能的下降。同时，高并发访问请求也使得集中式数据库成为系统的最大瓶颈。

2. 从可用性的方面来讲，服务化的无状态型，能够达到较小成本的随意扩容，
   这必然导致系统的最终压力都落在数据库之上。
   而单一的数据节点，或者简单的主从架构，已经越来越难以承担。
   数据库的可用性，已成为整个系统的关键。

3. 从运维成本方面考虑，当一个数据库实例中的数据达到阈值以上，
   对于 DBA 的运维压力就会增大。数据备份和恢复的时间成本都将随着数据量的大小而愈发不可控。
   一般来讲，单一数据库实例的数据的阈值在 1TB 之内，是比较合理的范围。

## -1:那么为什么不选择 NoSQL 呢？

NoSQL对SQL的不兼容性以及生态圈的不完善，

# 分库分表---概念

因为我们通过数据分片的方式来提升性能瓶颈和可用性，
而数据分片的有效手段就是对关系型数据库进行分库和分表。
通过分库和分表进行数据的拆分来使得各个表的数据量保持在阈值以下，
以及对流量进行疏导应对高访问量，是应对高并发和海量数据系统的有效手段

# 分库分表---拆分方式

1. 垂直分片
2. 水平分片

## -1:垂直分片

它的核心理念是专库专用。 
在拆分之前，一个数据库由多个数据表构成，
每个表对应着不同的业务。
而拆分之后，则是按照业务将表进行归类，
分布到不同的数据库中，从而将压力分散至不同的数据库。

就是说，根据业务把一个表中的字段（Field）分到不同的表中。
这些被分出去的数据通常根据业务需要，
例如分出去一些不是经常使用的字段，一些长度较长的字段。
一般被拆分的表的字段数比较多。
主要是避免查询的时候出现因为数据量大而造成的“跨页”问题。
一般这种拆分在数据库设计之初就会考虑，
尽量在系统上线之前考虑调整。已经上线的项目，做这种操作是要慎重考虑的。

### -1-1:垂直分片优缺点

`优点：`

1. 复杂度降低，易于维护。
2. 单库或单表压力降低。 相互之间的影响也会降低。

`缺点：`

1. 部分表关联无法在数据库级别完成，需要在程序中完成。
2. 单表大数据量仍然存在性能瓶颈。
3. 单表或单库高热点访问依旧对 DB 压力非常大。
4. 事务处理相对更为复杂，需要分布式事务的介入。
5. 拆分达到一定程度之后，扩展性会遇到限制。

### 18-2-1-1：垂直切分解决了什么问题

垂直切分可以降低单节点数据库的负载。
原来所有数据表都放在一个数据库节点上，
所有的读写请求也都发到这个MySQL上面，
所以数据库的负载太高。
如果把一个节点的数据库拆分成多个MySQL数据库，
这样就可以有效的降低每个MySQL数据库的负载。

### 18-2-1-2：垂直切分不能解决什么问题

垂直切分不能解决的是缩表，
比如说商品表无论划分给哪个数据库节点，
商品表的记录还是那么多，
不管你把数据库垂直拆分的有多细致，
每个数据表里面的数据量是没有变化的。
MySQL单表记录超过2000万，
读写性能会下降的很快，
因此说垂直切分并不能起到缩表的效果。

## -2:水平分片

它不再将数据根据业务逻辑分类，而是通过某个字段（或某几个字段），
根据某种规则将数据分散至多个库或表中，每个分片仅包含数据的一部分。

将一个表中的数据，按照关键字（例如：ID）（或取 Hash 之后）
对一个具体的数字取模，得到的余数就是需要存放到的新表的位置。
用这种方式存放数据以后，在访问具体数据的时候需要
通过一个 Mapping Table 获取对应要响应的数据来自哪个数据表

### -2-1:水平分片的优缺点

水平拆分的优点：

解决单表单库大数据量和高热点访问性能遇到瓶颈的问题。
应用程序端整体架构改动相对较少。
事务处理相对简单。
只要切分规则能够定义好，基本上较难遇到扩展性限制。
水平拆分缺点：

拆分规则相对更复杂，很难抽象出一个能够满足整个数据库的切分规则。
后期数据的维护难度有所增加，人为手工定位数据更困难。
产品逻辑将变复杂。比如按年来进行历史数据归档拆分，
这个时候在页面设计上就需要约束用户必须要先选择年，然后才能进行查询。

### 18-2-2-1：水平切分的用途

水平切分可以把数据切分到多张数据表，
可以起到缩表的作用。
但是也不是所有的数据表都要做水平切分。
数据量较大的数据表才需要做数据切分，
比如说电商系统中的，
用户表、商品表、产品表、地址表、订单表等等。
有些数据表就不需要切分，
因为数据量不多，
比如说品牌表、供货商表、仓库表，这些都是不需要切分的。

## 18-2-3：为什么先做水平切分，后作垂直切分？

随着数据量的增加，
最先应该做的是数据分片，
利用多块硬盘来增大数据IO能力和存储空间，
这么做的成本是最低的。几块硬盘的钱就能收获不错的IO性能。
进入到下一个阶段，数据量继续增大，
这时候我们应该把数据切分到多个MySQL节点上，
用MyCat管理数据切分。当然还要做数据的读写分离等等，
在后台做水平切分的同时，业务系统也可以引入负载均衡、分布式架构等等。
理论上，使用了冷热数据分离之后，
水平切分这种方式可以继续维持很长一段时间，
数据量再大也不怕，定期归档就好了。
数据库到了水平切分的阶段，
数据量的增加已经不是更改架构设计的主要原因了。
反而这个阶段业务系统承受不住了，如果再不对系统做模块拆分，
业务系统也撑不下去了，所以按照模块和业务，
把一个系统拆分成若干子系统。若干子系统之间，
数据相对独立。比如淘宝不会跟支付支付宝分享全部数据，
共享同一套数据表，这也影响各自业务的发展。
所以就要弄垂直切分了，
把数据表归类，拆分成若干个数据库系统。
如果过早的对数据库做了垂直切分，
势必要重新构建若干独立的业务系统，
工作量太巨大。
水平切分并不需要业务系统做大幅度的修改，
因此说应该先从水平切分开始做。

# 分库分表---常见问题

1. 分库分表之后的数据会非常散乱，管理员对数据库的操作变得异常繁重，
   需要知道数据需要从哪个具体的数据库的分表中获取。

2. 能够正确的运行在单节点数据库中的SQL ，在分片之后的数据库中并不一定能够正确运行。
   例如，分表导致表名称的修改，或者分页、排序、聚合分组等操作的不正确处理。

3. 跨库事务也是分布式的数据库集群要面对的棘手事情。

4. 分布式全局唯一 ID 。
   在单库单表的情况下，直接使用数据库自增特性来生成主键ID，这样确实比较简单。
   在分库分表的环境中，数据分布在不同的分表上，不能再借助数据库自增长特性。
   需要使用全局唯一 ID，例如 UUID、GUID等 。

# 分库分表---id处理

**方式1——数据库自增id** 
   系统里每次得到一个 id，
   都是往一个库的一个表里
   插入一条没什么业务含义的数据，
   然后获取一个数据库自增的一个id。
   拿到这个 id 之后再往对应的分库分表里去写入。
`好处`
   就是方便简单，谁都会用；
`缺点`
   就是单库生成自增 id，要是高并发的话，就会有瓶颈的；
`改进`
   那么就专门开一个服务出来，
   这个服务每次就拿到当前 id 最大值，
   然后自己递增几个 id，
   一次性返回一批 id，
   然后再把当前最大 id 值
   修改成递增几个 id 之后的一个值；
   但是无论如何都是基于单个数据库。
`适合的场景`
   要不就是单库并发太高，要不就是单库数据量太大；
   除非是并发不高，
   但是数据量太大导致的分库分表扩容，
   可以用这个方案，
   因为可能每秒最高并发最多就几百，
   那么就走单独的一个库和表生成自增主键即可。
**方式2——设置数据库 sequence 或者表自增字段步长**
   可以通过设置数据库 sequence 或者表的自增字段步长来进行水平伸缩。  
   比如说，现在有 8 个服务节点，
   每个服务节点使用一个 sequence 功能来产生 ID，
   每个 sequence 的起始 ID 不同，并且依次递增，步长都是 8。
 `适合的场景`
   在用户防止产生的 ID 重复时，
   这种方案实现起来比较简单，也能达到性能目标。
   但是服务节点固定，步长也固定，
   将来如果还要增加服务节点，就不好搞了。
**方式3——UUID**
 `好处`
   就是本地生成，不要基于数据库来了；
 `缺点`
   就是，UUID 太长了、占用空间大，
   作为主键性能太差了；更重要的是，
   UUID 不具有有序性，
   会导致 B+ 树索引在写的时候
   有过多的随机写操作
   连续的 ID 可以产生部分顺序写，
   还有，由于在写的时候不能
   产生有顺序的append 操作，
   而需要进行 insert 操作，
   将会读取整个 B+ 树节点到内存，
   在插入这条记录后会将整个节点写回磁盘，
   这种操作在记录占用空间比较大的情况下，
   性能下降明显。
 `适合的场景`
   如果是要随机生成个什么文件名、编号之类的，
   可以用 UUID，但是作为主键是不能用 UUID 的。
**方式4——获取系统当前时间**
   这个就是获取当前时间即可，
   但是问题是，并发很高的时候，
   比如一秒并发几千，会有重复的情况，
   这个是肯定不合适的。基本就不太合适。
 `适合的场景`   
   一般如果用这个方案，
   是将当前时间跟很多其他的业务字段拼接起来，
   作为一个 id，
   将别的业务字段值跟当前时间拼接起来，
   组成一个全局唯一的编号。
**方式5——利用 redis 生成 id** 
   性能比较好，灵活方便，
   不依赖于数据库。但是，
   引入了新的组件造成系统更加复杂
   可用性降低，编码更加复杂，
   增加了系统成本。
**方式6——snowflake 算法** 
是把一个 64 位的 long 型的 id，1 个 bit 是不用的，
用其中的 41 bit 作为毫秒数，
用 10 bit 作为工作机器 id，12 bit 作为序列号。

# 分库分表---事务

通过在主库中创建一个流水表，
把操作数据库的逻辑映射为一条流水记录。
当整个大事务执行完毕后（流水被插入到流水表）,
然后通过其他方式来执行这段流水，保证最终一致性。


# 数据库扩容---原因

分库之后的数据库会遇到数据扩容或者数据迁移的情况。

## 18-4-2：主从数据库扩容

假设有两个数据库集群，每个集群分别有 M1 S1 和 M2 S2 互为主备。
由于 M1 和 S1 互为主备所以数据是一样的，
M2 和 S2 同样。把原有的 ID %2 模式切换成 ID %4 模式，
也就是把两个数据集群扩充到 4 个数据库集群。
负载均衡器直接把数据路由到原来两个 S1 和 S2 上面，
同时 S1 和 S2 会停止与 M1 和 M2 的数据同步，
单独作为主库（写操作）存在。
这些修改不需要重启数据库服务，
只需要修改代理配置就可以完成。
由于 M1 M2 S1 S2 中会存在一些冗余的数据，
可以后台起服务将这些冗余数据删除，不会影响数据使用。
此时，再考虑数据库可用性，将扩展后的 4 个主库进行主备操作，
针对每个主库都建立对应的从库，
前者负责写操作，后者负责读操作。
下次如果需要扩容也可以按照类似的操作进行。

## 18-4-3：双写数据库扩容

在没有数据库主从配置的情况下的扩容，假设有数据库M1 M2 
需要对目前的两个数据库做扩容，
扩容之后是4个库
新增的库是 M3，M4 路由的方式分别是 ID%2=0 和 ID%2=1。
这个时候新的数据会同时进入 M1 M2 M3 M4 四个库中，
而老数据的使用依旧从 M1 M2 中获取。
与此同时，后台服务对 M1 M3，M2 M4 做数据同步，
可以先做全量同步再做数据校验。
当完成数据同步之后，四个库的数据保持一致了，
修改负载均衡代理的配置为 ID%4 的模式。
此时扩容就完成了，从原来的 2 个数据库扩展成 4 个数据库。
当然会存在部分的数据冗余，
需要像上面一个方案一样通过后台服务删除这些冗余数据，
删除的过程不会影响业务。
