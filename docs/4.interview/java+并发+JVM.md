# 1.java基础-java特性

## 1-1：java特点

1. 简单易学；
2. <font color=red size='5'>⾯向对象（封装，继承，多态）；</font>
3. <font color=red size='5'>平台⽆关性（ Java 虚拟机实现平台⽆关性）；</font>
4. 可靠性；
5. 安全性；
6. <font color=red size='5'>⽀持多线程；</font>
7. <font color=red size='5'>⽀持⽹络编程并且很⽅便；</font>
8. 编译与解释并存；

## 1-2：JVM\JRE\JDK\JIT

java虚拟机(JVM)
    使用java编程语言的主要优势就是平台的独立性。java实现平台的独立性靠的就是虚拟机，
    它抽象化了硬件设备，开发者和他们的程序的得以操作系统。虚拟机的职责就是处理和操作系统的交流。
    java不同的接口规范对任何平台都有良好的支持，因为jvm很好的实现了每个平台的规范。
    jvm可以理解伪代码字节码，在用户和操作系统之间建立了一层枢纽。
 
java运行时环境(JRE)
    java运行时环境是JVM的一个超集。JVM对于一个平台或者操作系统是明确的，
    而JRE确实一个一般的概念，他代表了完整的运行时环境。
    我们在jre文件夹中看到的所有的jar文件和可执行文件都会变成运行时的一部分。
    事实上，运行时JRE变成了JVM。所以对于一般情况时候使用JRE，
    对于明确的操作系统来说使用JVM。当你下载了JRE的时候，也就自动下载了JVM。
 
java开发工具箱(JDK)
    java开发工具箱指的是编写一个java应用所需要的所有jar文件和可执行文件。
    事实上，JRE是JKD的一部分。如果你下载了JDK,你会看到一个名叫JRE的文件夹在里面。
    JDK中要被牢记的jar文件就是tools.jar,它包含了用于执行java文档的类还有用于类签名的jar包。
 
即时编译器(JIT)
    即时编译器是种特殊的编译器，它通过有效的把字节码变成机器码来提高JVM的效率。
    JIT这种功效很特殊，因为他把检测到的相似的字节码编译成单一运行的机器码，
    从而节省了CPU的使用。这和其他的字节码编译器不同，
    因为他是运行时(第一类执行的编译？)
    the firs of its kind to perform the compilation(从字节码到机器码）
    而不是在程序运行之前。
    正是因为这些，动态编译这个词汇才和JIT有那么紧密的关系。

## 变量的初始化顺序：

基类的静态变量或全局变量。
派生类的静态变量或全局变量。
基类的成员变量。
派生类的成员变量。

# 2.java基础-面对对象-综述

## 2-1：面对对象三大特征(特点)

1. 封装
2. 继承
3. 多态

## 2-2：面对对象的五大原则

1. 单一职责原则
   * 一个类，最好只做一件事，只有一个引起它的变化
2. 开放封闭原则
   * 对抽象编程，而不对具体编程
3. 里式替换原则
   * 子类必须能够替换其基类（这个是继承的关键）
4. 依赖倒置原则
   * 抽象不依赖于具体，具体依赖于抽象
5. 接口隔离原则
   * 使用多个小的专门的接口，而不要使用一个大的总接口

## 2-3：Java创建对象方式

1. 使用new关键字
2. 使用反射的机制创建对象
   * 使用Class类的newInstance方法
   * 使用Constructor类的newInstance方法
3. 使用clone方法
   * 需要已经有一个分配了内存的源对象，创建新对象时，首先应该分配一个和源对象一样大的内存空间。
4. 反序列化
   * 调用ObjectInputStream类的readObject（）方法
5. 通过Unsafe实例化一个类

注：使用构造器的三种(new和反射的两种newInstance)，没用构造器的两种(clone和反序列化)

## 2-4：new abc是在堆里面呢？

放在堆里，栈里面放着引用

## 2-4：⾯向过程性能⽐⾯向对象⾼

Java 性能差的主要原因并不是因为它是⾯向对象语⾔，⽽是 Java 是半编译语⾔，最终的执⾏代码并不是可
以直接被 CPU 执⾏的⼆进制机械码。

# 3.java基础-面对对象-封装

## 3-1：封装的应用场景？ 

如果一个属性不想被其他人直接的访问，那么这时候就可以使用封装。

现实开发中的实体类的成员属性(成员变量)一般我们都会封装起来。

# 3.java基础-面对对象-多态

## 3-1：多态的必要条件（实现方式、机制）

1. 有类继承或者接口实现
2. 子类要重写父类的方法
3. 父类的引用指向子类的对象


## 3-3：多态的好处

1. 应用程序不必为每一个派生类编写功能调用，只需要对抽象基类进行处理即可。大大提高程序的可复用
   性。 
2. 派生类的功能可以被基类的方法或引用变量所调用，可以提高可扩充性和可维护性。 

## 3-4：多态的例子



# 4.java基础-面对对象-重载与重写 

## 4-1：重载与重写

1. 重载——函数或者方法有同样的名称，但是参数列表不相同的情形
2. 重写——Java的子类与父类中有两个名称、参数列表都相同的方法的情况。由于他们具有相同的方法签名，所以
   子类中的新方法将覆盖父类中原有的方法

## 4-2：Java 中是否可以覆盖(override)一个 private 或者是 static 的方法？

1. Java中static方法不能被覆盖， 因为方法覆盖是基于运行时动态绑定的， 而static方法是编译时静态
   绑定的。 

2. Java中也不可以覆盖private的方法， 因为private修饰的变量和方法只能在当前类中使用，如果是其他
   的类继承当前类是不能访问到 private 变量或方法的， 当然也不能覆盖。


# 6.java基础-面对对象-继承和接口

1,java类可以一次继承多个接口，用implements 接口1，接口2
2，如果是接口继承接口的话也可以用extends，接口是多继承的，java类才是单继承
3，接口继承接口可以不实现父接口中的方法，可以声明自己的新方法，
4，类实现接口时，一定要实现接口中声明的方法，如果接口中没有定义抽象方法则不需要，但是要注意，类实现了一个接口A,如果B是A的父接口，且B中有抽象方法，则该类必须实现A和B中的所有抽象方法
5，抽象方法只能定义在抽象类中，抽象类实现接口，可以不实现接口中的抽象方法
继承接口是说的接口来继承接口，是接口与接口间的




# 5.java基础-面对对象-接口与抽象类

## 5-1：接⼝和抽象类的区别是什么？

1. 所有⽅法在接⼝中不能有实现，⽽抽象类可以有⾮抽象的⽅法。

2. 接⼝中除了final变量，不能有其他变量，⽽抽象类中则不⼀定。

3. ⼀个类可以实现多个接⼝，但只能实现⼀个抽象类。

4. 从设计层⾯来说，抽象类作为很多子类的父类，是一种模板式设计，接口是一种行为规范

## 5-2：接口和抽象类的应用场景

1. 抽象类的使用场景

   既想约束子类具有共同的行为（但不再乎其如何实现），又想拥有缺省的方法，又能拥有实例变量

   如：模板方法设计模式，模板方法使得子类可以在不改变算法结构的情况下，重新定义算法中某些步骤的具体实现。

2. 接口的应用场景

  1. 约束多个实现类具有统一的行为，但是不在乎每个实现类如何具体实现

  2. 作为能够实现特定功能的标识存在，也可以是什么接口方法都没有的纯粹标识。

  3. 实现类需要具备很多不同的功能，但各个功能之间可能没有任何联系。

  4. 使用接口的引用调用具体实现类中实现的方法（多态）


## 5-2：Java 抽象类可以有构造函数吗？作用是什么

可以有， 抽象类可以声明并定义构造函数。 

它可以用来初始化抽象类内部声明的通用变量，并被各种实现使用。

## 5-3: Java 抽象类可以实现接口吗？ 它们需要实现所有的方法吗？

可以， 抽象类可以通过使用关键字implements来实现接口。 

## 5-4：Java 抽象类可以是 final 的吗？

不可以， Java 抽象类不能是 final 的。 将它们声明为final的将会阻止它们被继承， 而这正是使用抽象类唯一的方法。 

## 5-5：Java 抽象类可以有 static 方法吗？

可以， 抽象类可以声明并定义 static 方法， 没什么阻止这样做。

## 5-6：可以创建抽象类的实例吗？

不可以， 

1. 对象实例化的时候，关键字new向JVM申请内存，这个类的成员会被保存到内存中。而抽象类，没有具体的成
   员，没办法准确分配内存。

2. 可能也是设计层面上的解释，不希望实例化
   
## 5-7：抽象类必须有抽象方法吗？

不需要， 抽象类有抽象方法不是强制性的。 但是一般在抽象类中设置抽象方法

## 5-8：何时选用抽象类而不是接口？

1. 当关心升级时， 因为不可能在一个发布的接口中添加一个新方法， 用抽象类会更好。
2. 如果你的接口中有很多方法， 你对它们的实现感到很头疼， 考虑提供一个抽象类作为默认实现。

## 5-9：Java中的抽象方法是什么？

1. 抽象方法是一个没有方法体的方法。 你仅需要声明一个方法， 
2. 不需要定义它并使用关键字abstract 声明。 

## 5-10：Java抽象类中可以包含main方法吗？

是的， 抽象类可以包含 main 方法， 它只是一个静态方法， 你可以使用 main 方法执行抽象类， 但不可以创建任何实例。

## 5-11：创建⼀个对象⽤什么运算符?对象实体与对象引⽤有何不同?

new 运算符，new创建对象实例，对象引⽤指向对象实例。⼀个对象引⽤可以指向0个或1个对象;⼀个对象可以有n个引⽤指向它。

## 5-12：interface实现方法



# 6.java基础-值传递与引用传递

1. 值传递是对基本型变量而言的,传递的是该变量的一个副本,改变副本的值不影响原变量的值

2. 引用传递一般是对于引用类型变量而言的,传递的是该对象地址的一个副本，是一个地址。
   * 如果说改变了原地址的值（注意是  值  ），那么会影响
   * 如果改变了副本地址，如new 一个原地址不会改变  

一般认为,java传递都是值传递.

## 6-2：值传递与引用传递的实例举证

1. 基本类型
那我先说一下基本类型作为参数传递的例子：
```java
public class Test1 {
       public static void main(String[] args) {
        int n = 3;
        System.out.println("Before change, n = " + n);
        changeData(n);
        System.out.println("After changeData(n), n = " + n);
    }
public static void changeData(int n) {
        n = 10;
    }}
```

基本类型作为参数传递时，是传递值的拷贝，无论你怎么改变这个拷贝，原值是不会改变的，输出的结果证明了这一点：

Before change, n = 3

After changeData(n), n = 3

2. 引用类型
```java
   public class TransferTest2 {
    public static void main(String[] args) {
        Person person = new Person();
        System.out.println(person);
        change(person);
        System.out.println(person);
    }

    public static void change(Person p) {
        p = new Person();
    }
}

/**
 * Person类
 */
class Person {

}
```
两次打印结果一致。

在调用change()方法后，person变量并没发生改变。

01.当程序执行到第3行 Person person = new Person()时，
   程序在堆内存（heap）中开辟了一块内存空间用来存储Person类实例对象，
   同时在栈内存（stack）中开辟了一个存储单元来存储该实例对象的引用，即上图中person指向的存储单元。

02.当程序执行到第5行 change(person)时，person作为参数（实参）传递给饿了change()方法。
   这里是person将自己的存储单元的内容传递给了change()方法的p变量。
   此后在change()方法中对p变量的一切操作都是针对于p变量所指向的存储单元，与perosn所指向的存储单元就没有关系了。

# 7.java基础-深拷贝与浅拷贝

## 7-1：深拷贝与浅拷贝

1. 浅拷⻉：对基本数据类型进⾏值传递，对引⽤数据类型进⾏引⽤传递的拷⻉。

2. 深拷⻉：对基本数据类型进⾏值传递，对引⽤数据类型，创建⼀个新的对象，并复制其成员变量。

## 7-2：浅拷贝方法

1. 通过拷贝<font color=red>构造方法</font>实现浅拷贝：

   * 拷贝构造方法指的是该类的构造方法参数为该类的对象。

2. 通过重写clone()方法进行浅拷贝
   
   * 使用clone方法的类必须实现Cloneable接口

## 7-3：深拷贝方法

[参考文献](https://www.cnblogs.com/coderzhw/archive/2019/06/26/11094284.html)

1. 序列化
   * 序列化为数据流，在反序列化回来，就可以得到这个对象
2. 利用Kryo框架，这是一个快速高效的Java序列化框架
3. 利用json转化方式
   * 对象转化为JSON，再序列化为对象
4. 人工构建对象

## 7-4：深拷贝与浅拷贝的区别

深拷贝和浅拷贝最根本的区别在于是否真正获取一个对象的复制实体，而不是引用。

比如说我有两个数值，A和B，B复制了A，修改A的时候，看B是否发生变化：

如果B跟着也变了，说明是浅拷贝，修改堆内存中的同一个值

如果B没有改变，说明是深拷贝，修改堆内存中的不同的值、

浅拷贝（shallowCopy）只是增加了一个指针指向已存在的内存地址，

深拷贝（deepCopy）是增加了一个指针并且申请了一个新的内存，使这个增加的指针指向这个新的内存，

使用深拷贝的情况下，释放内存的时候不会因为出现浅拷贝时释放同一个内存的错误。

## 7-5：赋值和浅拷贝的区别

当我们把一个对象赋值给一个新的变量时，赋的其实是该对象的在栈中的地址，而不是堆中的数据。

两个对象指向的是同一个存储空间，无论哪个对象发生改变，其实都是改变的存储空间的内容，因此，两个对象是联动的。

浅拷贝是按位拷贝对象，它会创建一个新对象，这个对象有着原始对象属性值的一份精确拷贝。

如果属性是基本类型，拷贝的就是基本类型的值；如果属性是内存地址（引用类型），拷贝的就是内存地址 ，

因此如果其中一个对象改变了这个地址，就会影响到另一个对象。

即默认拷贝构造函数只是对对象进行浅拷贝复制(逐个成员依次拷贝)，即只复制对象空间而不复制资源。


# 8.java基础-面对对象-构造器

## 8-1：⼀个类的构造⽅法的作⽤是什么? 若⼀个类没有声明构造⽅法，该程序能正确执⾏吗? 为什么?

主要作⽤是完成对类对象的初始化⼯作。可以执⾏。因为⼀个类即使没有声明构造⽅法也会有默认的不带参数的构造⽅法。

## 8-2：构造⽅法有哪些特性？

1. 名字与类名相同。
2. 没有返回值，但不能⽤ void 声明构造函数。
3. ⽣成类的对象时⾃动执⾏，⽆需调⽤。

## 8-3：构造方法可不可以被重写和重载？

构造方法可以被重载。

构造方法不可以被重写，因为重写发生在父类和子类之间，要求方法名称相同，

而构造方法的名称是和类名相同的，而子类类名不会和父类类名相同，所以不可以被重写。

# 9.java基础-面对对象-静态与非静态

## 9-1：静态⽅法和实例⽅法有何不同

1. 调⽤静态⽅法可以⽆需创建对象。而实例方法需要用类名.方法名访问

2. 静态⽅法在访问本类的成员时，只允许访问静态成员，⽽不允许访问实例成员变量和实例⽅法；实例⽅法则⽆此限制。

## 9-2：静态变量和实例变量的区别？

1. 语法区别： 静态变量前要加 static 关键字，而实例变量前则不加。

2. 程序运行的区别：实例变量必须创建对象后才可以通过这个对象来使用，静态变量则可以直接使用类名来引用。

# 10.java基础-equals与==

## 10-1： == 与 equals

1. == : 它的作⽤是判断两个对象的地址是不是相等。
   基本数据类型⽐较的是值，引⽤数据类型⽐较的是内存地址

2. equals() : 它的作⽤也是判断两个对象是否相等。但它⼀般有两种使⽤情况：

   * 情况 1：类没有覆盖equals()⽅法。则通过equals()⽐较该类的两个对象时，等价于通过“==”⽐ 较这两个对象。
   * 情况 2：类覆盖了equals()⽅法。⼀般，我们都覆盖 equals() ⽅法来⽐较两个对象的内容是否相等；若它们的内容相等，则返回true。

## 10-2：为什么要重写hashcode与equals

如果只重写了equals方法而没有重写hashCode方法的话，那么就会违背，相等的对象必须具有相等的散列码（hashCode）。
     
比如说，对于HashSet和HashMap这些基于散列值（hash）实现的类。

HashMap的底层处理机制是以数组的方法保存放入的数据的，关键就是数组下标的处理。

数组的下标是根据传入的元素hashCode方法的返回值再和特定的值异或决定的。

如果该数组位置上已经有放入的值了，且传入的键值相等则不处理，

若不相等则覆盖原来的值，如果数组位置没有条目，则插入，并加入到相应的链表中。

检查键是否存在也是根据hashCode值来确定的。所以如果不重写hashCode的话，

可能导致HashSet、HashMap不能正常的运作、

如果我们将某个自定义对象存到HashMap或者HashSet及其类似实现类中的时候，

如果该对象的属性参与了hashCode的计算，那么就不能修改该对象参数hashCode计算的属性了。有可能会移除不
了元素，导致内存泄漏。

## 10-3：重写equals不重写hashcode会出现什么问题

在集合中将会存储两个值相同的对象,从而导致混淆。

## 10-4：为什么两个对象有相同的hashcode值，它们也不一定是相等的？

hashCode方法实际上返回的就是对象存储的物理地址，也就是说 hashcode 只是用来缩小查找成本。

## 10-5：hashcode和equals源码写一下

equals()方法在object类中定义如下： 

```java
public boolean equals(Object obj) {  
    return (this == obj);  //用来比较其他对象是否等于此对象
} 
```


比如说在String类中重写

```java
public boolean equals(Object anObject) {
		//使用==操作符检查“参数是否为这个对象的引用”(比较对象地址)
        if (this == anObject) {
            return true;
        }
        //用instanceof检查“参数是否为正确的类型(是否为String的实例)”
        if (anObject instanceof String) {
            String anotherString = (String)anObject;
            int n = value.length;
           	//判断两个字符串的长度是否相同
            if (n == anotherString.value.length) {
                char v1[] = value;
                char v2[] = anotherString.value;
                int i = 0;
                //一个字符一个字符的进行比较
                while (n-- != 0) {
                    if (v1[i] != v2[i])
                        return false;
                    i++;
                }
                return true;
            }
        }
        return false;
    }
```

```java
public int hashCode() {
      int h = hash;
      if (h == 0 && value.length > 0) {
          char val[] = value;
  
          for (int i = 0; i < value.length; i++) {
              h = 31 * h + val[i];
          }
          hash = h;
     }
     return h;
 }
```


## 10-5：说说&和&&的区别。

1. &和&&都可以表示逻辑与，当运算符两边的表达式的结果都为 true 时，整个运算结果才为 true，否则，只要有一方为 false，则结果为 false。
2. &&还具有短路的功能，即如果第一个表达式为 false，则不再计算第二个表达式，所以不会出现 NullPointerException 
3. &还可以用作位运算符，当&操作符两边的表达式不是 boolean 类型时， &表示按位与操作

## 10-6：用最有效率的方法算出 2 乘以 8 等于几?

用移位运算符

2<<3

* 因为将一个数左移 n 位，就相当于乘以了2的 n 次方

# 11.java基础-i++与++i的问题

## 11-1：i++和++i的区别，及其线程安全问题

i++：先赋值再自加。

++i：先自加再赋值。

1. 如果i是局部变量（在方法里定义的），那么是线程安全的。因为局部变量是线程私有的，别的线程访问不
   到

2. 如果i是全局变量（类的成员变量），那么是线程不安全的。因为如果是全局变量的话，同一进程中的不同
   线程都有可能访问到。

如果有大量线程同时执行i++操作，i变量的副本拷贝到每个线程的线程栈，当同时有两个线程栈以上的线程读取
线程变量，假如此时是1的话，那么同时执行i++操作，再写入到全局变量，最后两个线程执行完，i会等于3而不
会是2，所以，出现不安全性。

## 11-2：i++和++i是否为原子操作

不是原子操作

比如说i++

分为三个阶段：

1. 内存到寄存器

2. 寄存器自增

3. 回内存

这三个阶段中间都可以被中断分离开.

++i首先要看编译器是怎么编译的，

如果编译成了“inc dword ptr[i]”，这是原子操作

## 11-3：如何实现i++和++i的原子性呢？

总线锁和缓存锁两个机制来保证原子性，可以通过处理器提供的很多LOCK前缀的指令来实现。

1. 总线锁：多个处理器可能会同时从各自的缓存中读取变量，并分别进行操作，
   在分别写入内存中，想要保证读改写共享变量的操作是原子的，就要使用总线锁来解决，
   即使用处理器提供的一个LOCK#信号，当有一个处理器在总线上输出此信号时，
   其他处理器的请求将被阻塞，此时该处理器可以独占共享内存。

2. 缓存锁：频繁使用的内存将会缓存在处理器的高速缓存里，
   内存区域如果被缓存到处理器的缓存行里，并且在Lock操作期间被锁定，
   那么当他执行锁操作回写到内存时，其他处理器会检查各自缓存行内的内存地址，
   如果发现自己的缓存行对应的地址被修改了，就会将缓存行置于无效状态，
   下次访问时，重新从内存中读取数据到缓存行，并允许它的缓存一致性机制
   （通常采用嗅探技术来实现，即缓存不仅仅是在内存传输的时候才和总线打交道，
   而是时刻不停的在窥探总线上发生的数据交换，并跟踪其他缓存在做什么，
   所以当一个缓存代表它所属的处理器去读写内存时，其他处理器都会得到通知，
   从而保证各个缓存保持同步）来保证操作的原子性。此时，处理器不会在总线上输出LOCK#信号。

总线锁会把CPU和内存之间的通信锁住，导致其他处理器不能操作其他内存地址的数据，

所以总线锁的开销比较大，在某些场合下，会使用缓存锁来代替总线锁进行优化。

但是，当操作的数据不能被缓存在处理器内部或要操作的数据会跨多个缓存行时，

处理器会调用总线锁。对于有些处理器不支持缓存锁，就算锁定的内存区域在处理器的缓存行，这时也会调用总线锁。

# 11.java基础-数据类型-8种常见类型
##  11-1：八种数据类型是什么？-中兴

1. 字符型   char
2. 布尔型  boolean
3. 数值型
   1. 整型：byte、short、int、long
   2. 浮点型：float、double

<font?color=red>特别注意</font>：String不是基本数据类型，是引用类型。

## 11-2：数据类型的范围

byte：-2^7 ~ 2^7-1，

short：-2^15 ~ 2^15-1

int：-2^31 ~ 2^31-1

long：-2^63 ~ 2^63-1，

浮点型：

float：4字节。

double：8字节。

字符型：

char：2字节。
                                                          
##  11-3：为什么byte类型是-128~+127

使用原码或反码表示的范围为[-127, +127], -0并没有反码补码表示，而使用补码表示的范围为[-128, 127]

##  11-4：java为什么除了基本数据类型还要有引用数据类型

引用类型在堆里，基本类型在栈里。
栈空间小且连续，往往会被放在缓存。引用类型cache miss（缓存未命中）率高且要多一次解引用。对象还要再多储存一个对象头，对基本数据类型来说空间浪费率太高

## 11-5：String为什么不是基本数据类型-字节

1. 基本类型仅表示简单的数据类型，引用类型可以表示复杂的数据类型，还可以操作这种数据类型的行为 

2. java虚拟机处理基础类型与引用类型的方式是不一样的，对于基本类型，java虚拟机会为其分配数据类型实际占用的内存空间，而对于引用类型变量，他仅仅是一个指向堆区中某个实例的指针。


# 12.java基础-数据类型-自动拆装箱
## 12-1：为什么要有自动拆装箱

比如说集合类中，要求元素必须是Object类，而int、double等基本数据类型无法使用，那么我们就把基本数据类型包装起来，使其具有对象的特征，并让他有了属性和方法

## 12-2：Integer缓存机制

Integer对小数据（-128~=127）具有缓存机制，当jvm在初始化的时候，如果数据是小数据，那么就会把数据存储在本地内存当中，当下次使用的时候该数据的时候，那么就可以直接从本地内存进行调用，就不需要再次创建对象来解决

1. 其中会有一个valueof函数，用来判断内存中是否有着这个数值，
   * 如果说有，那么直接从内存进行读取
   * 如果说没有，那么就需要创建一个对象
2. 在jvm初始化的时候，低值是不能改变的，但是高值是可以改变的，可以通过jvm进行参数设置，但是只有Integer源码可以对高值、低值进行改变。

## 12-3：自动拆装箱的原理

    * 自动装箱：调用valueOf（）方法将原始类型值转换成对象
    * 自动拆箱：调用intValue()方法，其他的（xxxValue())这类的方法将对象转换成原始类型值。

## 12-4：自动拆装箱使用场景

1. 场景一、将基本数据类型放入集合类
2. 场景二、包装类型和基本类型的大小比较
3. 场景三、包装类型的运算 
4. 场景四、三目运算符的使用如果i是包装类，j是null就会NPE报错
5. 场景五、函数参数与返回值

## 12-5：自动拆装箱带来的问题

1. 包装对象的数值比较，不能简单的使用==，~~虽然-128到127之间的数字可以，但是这个范围之外还是需要使用equals比较~~。（笔试选择较为频繁，跟谁学考过）

2. 如果包装类对象为null，那么自动拆箱时就有可能抛出NPE（NullPointException）。

3. 如果一个for循环中有大量拆装箱操作，会浪费很多资源。

## 12-6：String转出int型， 判断能不能转？ 如何转？

可以转， 得处理异常 Integer.parseInt(s) 主要为 NumberFormatException： 

## 12-7：short s1 = 1; s1 = s1 + 1;有什么错? short s1 = 1; s1+=1;有什么错?

对于 short s1 = 1; s1 = s1 + 1;由于 s1+1运算时会自动提升表达式的类型，所以结果是 int型，再赋值给 short 类型 s1时， 编译器将报告需要强制转换类型的错误。

对于 short s1 = 1; s1 += 1;由于 +=是 java 语言规定的运算符， java 编译器会对它进行特殊处理，因此可以正确编译

## 12-8：int与Integer区别

1. Integer是int的包装类 ，int则是java的一种基本数据类型
2. Integer变量必须实例化后才能使用，而int变量不需要
3. Integer的默认值是null, int的默认值是0

注：

1. 非new生成的Integer变量和new Integer生成的变量比较时， 结果为false。( 因为非new生成的Integer变量指向的是java常量池中的对象，而new Integer0生成的变量指向堆中新建的对象，两者在内存中的地址不同)
```java
Integer i = new Integer(100);
Integer j = 100;
Syatem.out.print(i == J); //false
```

2. Integer变量和int变量比较时，只要两个变量的值是相等的，则结果为true


# 13.java基础-关键字-访问权限关键字

## 13-1：访问控制关键字级别

![avatar](./../../1.basics/1.java-basic/assets/3-2.jpg)

## 13-2: 通过反射访问private成员和方法，既然能访问为什么要private？

1. private并不是解决安全问题的，如果想让解决代码的安全问题，请用别的办法。
2. private的意义是OOP（面向对象编程）的封装概念。

# 14.java基础-关键字-static

## 14-1：static使用场景

1. 修饰成员变量和成员方法 
     
2. 静态代码块: 
   
3. 静态内部类（static修饰类的话只能修饰内部类）： 
   
4. 静态导包: 
   
# 15.java基础-关键字-final关键字

## 15-1：final关键字使用特点

1. final修饰的类不能被继承

2. final修饰的方法不能被重写；

3. final修饰的变量是常量，如果是基本数据类型的变量，则其数值一旦在初始化之后便不能更改；如果是引用类型的变量，则在对其初始化之后便不能让其指向另一个对象。

4. 想通过使用final提升程序性能
   * 因为编译器能从final中获取额外的信息，因此可以对类或者方法调用进行额外的优化处理。但这中优化对程序性能的提升极其
     有限。

## 15-2：final, finally, finalize 的区别。

1. final 用于声明属性，方法和类，分别表示属性不可变，方法不可覆盖，类不可继承。

2. finally 是异常处理语句结构的一部分，表示总是执行。
   
3. finalize 是 Object 类的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法，可
以覆盖此方法提供垃圾收集时的其他资源回收，例如关闭文件等。


## 15-3：使用 final 关键字修饰一个变量时，是引用不能变，还是引用的对象不能变？

使用 final 关键字修饰一个变量时，是指引用变量不能变，引用变量所指向的对象中的内容还是可以改变的。


# 16.java基础-关键字-this关键字和super关键字

1. this程序
```java
class Manager {
    Employees[] employees;
     
    void manageEmployees() {
        int totalEmp = this.employees.length;
        System.out.println("Total employees: " + totalEmp);
        this.report();
    }
     
    void report() { }
}
```

主要是访问本类（自己）的成员变量和方法（可写可不写）
super主要是通过子类去访问父类的成员变量和方法，必须写
2. super程序

```java
public class Super {
    protected int number;
     
    protected showNumber() {
        System.out.println("number = " + number);
    }
}
 
public class Sub extends Super {
    void bar() {
        super.number = 10;
        super.showNumber();
    }
}
```

1. 在构造器中使用 super（） 调用父类中的其他构造方法时，该语句必须处于构造器的首行，否则编译器会报错。
2. this 调用本类中的其他构造方法时，也要放在首行。
3. this、super不能用在static方法中。

# 17.java基础-关键字-transient

阻⽌实例中那些⽤此关键字修饰的的变量序列化；当对象被反序列化时，被 transient 修饰的变量值不会被持久化和恢复。 transient 只能修饰变量，不能修饰类和⽅法。


# 18.java基础-集合map-hashmap的数据结构

## 18-1：hashmap的数据结构

1. JDK1.7用的是头插法，而JDK1.8及之后使用的都是尾插法，JDK1.7采用头插法虽然能够提高插入的效率，
   
   但是为了安全,防止环化，因为resize的赋值方式，也就是使用了单链表的头插入方式，同一位置上新元素总会被放在链表的头部位置，
   
   在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。所以使用头插会改变链表的上的顺序，
   
   但是如果使用尾插，在扩容时会保持链表元素原本的顺序，保持之前节点的引用关系，就不会出现逆序且链表死循环的问题

2. 扩容存储位置的计算方式也不一样：
   1. 在JDK1.7的时候是直接用hash值和需要扩容的二进制数进行&
   2. 在JDK1.8的时候是扩容前的原始位置+扩容的大小值=JDK1.8的计算方式，
   
      但是这种方式就相当于只需要判断Hash值的新增参与运算的位是0还是1就直接迅速计算出了扩容后的存储方式。

3. （插入元素）JDK1.7的时候使用的是数组+单链表的数据结构。HashMap通过key的hashCode经过扰动函数处理过后得到hash
   值，然后通过(n-1)&hash判断当前元素存放的位置，如果当前位置存在元素的话，就判断该元素与要存入的元素的hash值以及
   key是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。但是在JDK1.8及之后时，使用的是数组+链表+红黑树的
   数据结构,当链表的深度达到8的时候，也就是默认阈值，就会自动扩容把链表转成红黑树的数据结构，以减少搜索时间。

## 18-2：扩容死循环问题

比如说若当前线程在扩容并发的时候，此时获得ertry节点，但是被线程中断无法继续执行，此时线程二进入transfer 函数，并把函数顺利执行，

此时新表中的某个位置有了节点，之后线程一获得执行权继续执行，因为并发 transfer，所以两者都是扩容的同一个链表，

当线程一执行到new table[i]的时候，由于线程二之前数据迁移的原困导致此时new table[i]上就有ertry存在，

所以线程一执行的时候，会将next节点，设置为自己，导致自己互相使用next引用对方，因此产生链表，导致死循环。

但是在JDK 8用head 和 tail 来保证链表的顺序和之前一样。

## 18-2；为什么JDK8时候引入了红黑树？

因为当数组中每个元素，都是一个Entry，每一个Entry是一个单链表。

当链表长度过长的时候，查询链表中的一个元素就比较耗时，这时就引入了红黑树。

首先红黑树是一棵二叉树，红黑树有一条特性就是

从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。

这一特性，确保没有一条路径会比其他路径长出两倍，因而，红黑树是接近平衡的二叉树。这就使得红黑树的时间复杂度大大降低。

所以，用红黑树替代单链表会降低集合中元素的访问速度。

## 18-3：为什么不把链表全部换为红黑树

1. 链表的结构比红黑树简单，构造红黑树要比构造链表复杂，所以在链表的节点不多的情况下，从整体的性能看来，如果把链表全部换为红黑树，效率反而更低。
2. HashMap频繁的resize（扩容），扩容的时候需要重新计算节点的索引位置，也就是会将红黑树进行拆分和重组，其实这是很复杂的，这里涉及到红黑树的着色和旋转，所以为链表树化设置一个阀值是非常有必要的。

## 18-4：为什么是使用红黑树而不是AVL树？

在CurrentHashMap中是加锁了的，实际上是读写锁，如果写冲突就会等待，如果插入时间过长必然等待时间更长。同时因为AVL树需要更高的旋转次数才能在修改时正确地重新平衡数据结构，所以红黑树相对AVL树他的插入更快！

## 18-5：为什么在JDK1.7的时候是先进行扩容后进行插入，而在JDK1.8的时候则是先插入后进行扩容的呢？

在JDK1.7中的话，是先进行扩容后进行插入的，就是当你发现你插入的桶是不是为空，说明存在值就发生了hash冲突，那么就必须得扩容，但是如果不发生Hash冲突的话，说明当前桶是空的（后面并没有挂有链表），那就等到下一次发生Hash冲突的时候在进行扩容，但是当如果以后都没有发生hash冲突产生，那么就不会进行扩容了，减少了一次无用扩容，也减少了内存的使用

## 18-6：为什么在JDK1.8中进行对HashMap优化的时候，把链表转化为红黑树的阈值是8,而不是7或者不是20呢（面试蘑菇街问过）

1. 中间有个差值7可以有效防止链表和树频繁转换，降低效率

2. 由于treenodes的大小大约是常规节点的两倍，因此我们仅在容器包含足够的节点以保证使用时才使用它们，当它们变得太小（由于移除或调整大小）时，它们会被转换回普通的node节点，容器中节点分布在hash桶中的频率遵循泊松分布，桶的长度超过8的概率非常非常小。

## 18-7：扰动函数以及作用

HashMap的hash方法。

为了防止一些实现比较差的hashCode()方法，使用扰动函数之后可以减少碰撞。


## 18-8：哈希冲突的解决方法

1. 拉链法
   
创建一个链表数组，数组中每一格就是一个链表。若遇到哈希冲突，则将冲突的值加到链表中即可。

2. 开发地址法

所有输入的元素全部存放在哈希表里，先通过哈希函数进行判断，若是发生哈希冲突，就以当前地址为基准，根据再寻址的方法（探查序列），去寻找下一个地址，若发生冲突再去寻找，直至找到一个为空的地址为止。

## 18-9：HashMap的put操作

HashMap通过key的hashCode经过扰动函数处理过后得到hash值，然后通过计算判断当前元素存放的位置

1. 如果数组的这个位置是空的，把key放进去，put操作就完成了。

2. 如果数组位置不为空，就判断该元素与要存入的元素的hash值以及key是否相同，如果相同的话，直接覆盖

3. 若果不相等，这个元素必然是个链表。遍历链表逐一比对value，如果value在链表中不存在，就把新建节点，将value放进去，put操作完成。

4. 如果链表中value存在，则替换原节点的value，put操作完成。

5. 如果链表节点数已经达到8个，首先判断当前hashMap的长度，如果不足64，只进行resize，扩容table，如果达到64就将冲突的链表为红黑树。

## 18-11：手写put方法

```java
public V put(K key, V value) {
        if (key == null)
            return putForNullKey(value);
        int hash = hash(key.hashCode());
        int i = indexFor(hash, table.length);
        for (Entry<K,V> e = table[i]; e != null; e = e.next) {
            Object k;
            if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
                V oldValue = e.value;
                e.value = value;
                e.recordAccess(this);
                return oldValue;
            }
        }
  
        modCount++;
        addEntry(hash, key, value, i);
        return null;
    }
```

## 18-10：HashMap的get操作

1. 查找位置。

2. 如果访问的节点是bucket里的第一个节点，则直接命中；

3. 如果有冲突，则通过key.equals(k)去树或链表中查找对应的entry。


## 18-12：手写get方法

```java

 public V get(Object key) {
        //定义一个Node对象来接收
        Node<K,V> e;
        //调用getNode()方法，返回值赋值给e，如果取得的值为null，就返回null，否则就返回Node对象e的value值
        return (e = getNode(hash(key), key)) == null ? null : e.value;
    }

 //取hash值方法，HashMap的put方法的也是调用了这个方法，get方法也调用这个方法，保证存取时key值对应的hash值是一致的，这样才能正确对应 
 static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }
    
     
final Node<K,V> getNode(int hash, Object key) {
        //定义几个变量 
        Node<K,V>[] tab; Node<K,V> first, e; int n; K k;
        //首先是判断数组table不能为空且长度要大于0，同时把数组长度tab.length赋值给n
        if ((tab = table) != null && (n = tab.length) > 0 &&
             //其次是通过[(n - 1) & hash]获取key对应的索引，同时数组中的这个索引要有值，然后赋值给first变量
            (first = tab[(n - 1) & hash]) != null) {
            //这个first其实就是链表头的节点了，接下来判断first的hash值是否等于传进来key的hash值
            if (first.hash == hash && 
                //再判断first的key值赋值给k变量，然后判断其是否等于key值，或者判断key不为null时，key和k变量的equals比较结果是否相等
                ((k = first.key) == key || (key != null && key.equals(k))))
                //如果满足上述条件的话，说明要找的就是first节点，直接返回
                return first;
            //走到这步，就说明要找的节点不是首节点，那就用first.next找它的后继节点 ，并赋值给e变量，在这个变量不为空时   
            if ((e = first.next) != null) {
                //如果首节点是树类型的，那么直接调用getTreeNode()方法去树里找
                if (first instanceof TreeNode)
                     //这里就不跟进去了，获取树中对应key的节点后直接返回
                    return ((TreeNode<K,V>)first).getTreeNode(hash, key);
                //走到这步说明结构还是链表    
                do {
                    //这一步其实就是在链表中遍历节点，找到和传进来key相符合的节点，然后返回
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        return e;
                  //获取e节点的后继节点，然后赋值给e，不为空则进入循环体  
                } while ((e = e.next) != null);
            }
        }
        //以上条件都不满足，说明没有该key对应的数据节点，返回null
        return null;
    }
```

## 18-11：hashmap的get和put操作的时间复杂度

如果说一个entry数组下标最多只对应了一个entry，此时get方法的时间复杂度可以达到O(1)。

但是如果所有的hash都一样，那么退化为线性查找，变成了O（n）

## 18-12：hashmap的String类型如何计算hashcode的

就是以31为权，每一位为字符的ASCII值进行运算，用自然溢出来等效取模。

选择值31是因为它是素数。如果是偶数并且乘法运算溢出，则信息将丢失，因为乘以2等于移位。

31的一个不错的特性是乘法可以用移位和减法来代替，以获得更好的性能

哈希分布比较均匀。偶数的冲突率很高，只有少数例外。小乘数（1-20）的冲突率也很高

## 18-13：reHash过程

1. 首先创建一个比现有哈希表更大的新哈希表（expand）
2. 然后将旧哈希表的所有元素都迁移到新哈希表去（rehash）

## 18-14：hash函数以及常用方法

1. 直接定址法：直接以key或者key上加上某个常数作为哈希地址
2. 数字分析法：提取key中取值比较均匀的数字作为哈希地址
3. 除留余数法：用key除以某个不大于哈希表长度m的数，将所得余数作为哈希地址
4. 分段叠加法：按照哈希表地址位数将关键字分成了位数相等的几部分，其中最后一部分可以比较短，然后将这几部分相加，舍弃最
   高位仅为后的结果就是该关键字的哈希地址
5. 平方取中法：如果key的各部分分部都不均匀，可以先求出他的平方值，然后按照需求求取中间的几位作为哈希地址
6. 伪随机数法：采用一个伪随机数作为哈希函数


## 18-15：HashMap为什么要树化?

安全问题。因为在元素放置过程中，如果一个对象哈希冲突，都被放置到同一个桶中，则会形成一个链表。而链表查询时线性的，会
严重影响存取的性能。

## 18-16：hashmap树化门槛及作用

* 链表长度大于8
* 数组长度大于64

作用：
这个本质上，是一个安全问题。因为在元素放置过程中，如果一个对象哈希冲突，都被放置到同一个桶中，则会形成一个链表。而链
表查询是线性的，会严重影响存取的性能。

## 18-17：hashmap的特性

1. 允许空键和空值（但空键只有一个，且放在第一位）
2. 元素是无序的，而且顺序会不定时改变
3. key不允许重复。

## 18-18：HashMap为什么可以插入空值?

HashMap在put的时候会调用hash()方法来计算key的hashcode值，可以从hash算法中看出当key==null时返回的值为0。因此key为
null时，hash算法返回值为0，不会调用key的hashcode方法。

## 18-19：JDK的hashmap与Redis的hashmap的区别

1. HashMap由于对链表size超过8采用二叉树结构，使得get操作随着激烈冲突导致变成一个类二叉树，时间复杂度为O(log(n))较
   redis的字典表O(n)，性能提升明显。
2. Redis的rehash由于采用渐进式的方式，对于大数据量下的rehash操作性能提升明显。这也是由于HashMap大部分用于临时且数
   据量不是特别大的数据，redis的hash用于存储避免大数据情况导致异常，双方的侧重点不一样。
3. Redis的单链表在冲突的情况下是从表头插入，时间复杂度为O(1)，而HashMap则为O(n)。

## 18-20：为什么要两次hash

两个不同的键值，在对数组长度进行按位与操作后得到的结果相同，就会发生冲突


# 19.java基础-集合map-hashmap源码数值分析

## 19-1：HashMap中(tab.length - 1) & hash作用

1. 保证不会发生数组越界

2. 保证元素尽可能的均匀分布

## 19-2：请解释一下HashMap的参数loadFactor，它的作用是什么？

loadFactor表示HashMap的拥挤程度

作用：影响hash操作到同一个数组位置的概率。

## 19-3：HashMap的扩容因子为什么是0.75

1. 如果设置过大，如0.85，桶中键值对碰撞的几率就会越大，同一个桶位置可能会存放好几个value值，这样就会增加搜索的时间，
   性能下降。
   
2. 如果设置过小，如0.1，那么10个桶，threshold为1，你放两个键值对就要扩容，太浪费空间了。

## 19-4：为什么默认初始化桶数组大小为16

如果桶初始化桶数组设置太大，就会浪费内存空间，16是一个折中的大小，既不会像1，2，3那样放几个元素就扩容，也不会像几千几
万那样可以只会利用一点点空间从而造成大量的浪费。

## 19-5：hashmap为什么是2的次幂

取模运算可以变成位与运算，效率显著提高！但是要浪费一些空间。

## 19-6：红黑树

红黑树比较传统的定义是需要满足以下五个特征：
（1）每个节点或者是黑色，或者是红色。
（2）根节点是黑色。
（3）每个叶子节点（NIL）是黑色。 [注意：这里叶子节点，是指为空(NIL或NULL)的叶子节点！]
（4）如果一个节点是红色的，则它的子节点必须是黑色的。
（5）从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。
其特点在于给数的每一个节点加上了颜色属性，在插入的过程中通过颜色变换和节点旋转调平衡。

## 19-7：AVL树


avl树即平衡树，他对二叉树做了改进，在我们每插入一个节点的时候，

必须保证每个节点对应的左子树和右子树的树高度差不超过1。如果超过了就对其进行调平衡，

无非就是四个操作——左旋，左旋再右旋，右旋再左旋。

最终可以是二叉树左右两边的树高相近，这样我们在查找的时候就可以按照二分查找来检索，

也不会出现退化成链表的情况。

# 20.java基础-集合map-hashmap线程问题

## 20-1：hashMap是否线程安全

在JDK1.7的时候没有加入同步锁保护，同时由于JDK1.7在并发执行put造作导致扩容行为从而导致环形链表，在获取数据遍历链表形
成死循环，同时hashmap迭代器的fail-fast策略，一旦在使用地带器过程中出现并发操作，就会跑出异常。

那么JDK1.8虽然解决了死循环问题，但是还是没有同步锁保护机制，所以依然线程不安全

所以多线程情况下，首选线程安全的ConcurrentHashMap

## 20-2：为什么hashmap中String、integer包装类适合作为key

1. 包装类重写了equals\hashcode方法，不容易出现hash值计算错误
2. 由于String类型是final的，保证了key的不可更改性

## 20-3：线程安全的Map

* Hashtable
* ConcurrentHashMap
* SynchronizedMap

1. Hashtable、SynchronizedMap源码中是使用synchronized来保证线程安全的
   
2. ConcurrentHashMap沿用了与它同时期的HashMap版本的思想，底层依然由“数组”+链表+红黑树的方式思想，但是
   ConcurrentHashMap没有对整个hash表进行锁定，而是采用了分离锁（segment）的方式进行局部锁定。具体体现在，它在代码
   中维护着一个segment数组。
   
## 20-4：设计线程安全的map

1. 使用synchronized来进行约束：

2. 使用JDK1.5版本所提供的lock机制
   
3. 使用JDK提供的读写锁

4. 使用JDK1.5提供的ConcurrentHashMap,该类将Map的存储空间分为若干块,每块拥有自己的锁,减少了多个线程争夺同一个锁的情
   况


# 21.java基础-集合map-ConcurrentHashMap

## 21-1：ConcurrentHashMap的底层实现

ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术。
它使用了多个锁来控制对hash表的不同段进行的修改，每个段其实就是一个小的hashtable，它们有自己的锁。只要多个并发发生在不同的段上，它们就可以并发进行。
ConcurrentHashMap在底层将key-value当成一个整体进行处理，这个整体就是一个Entry对象。Hashtable底层采用一个Entry[]数组来保存所有的key-value对，当需要存储一个Entry对象时，会根据key的hash算法来决定其在数组中的存储位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry时，也会根据key的hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Entry。
与HashMap不同的是，ConcurrentHashMap使用多个子Hash表，也就是段(Segment)
ConcurrentHashMap完全允许多个读操作并发进行，读操作并不需要加锁。如果使用传统的技术，如HashMap中的实现，如果允许可以在hash链的中间添加或删除元素，读操作不加锁将得到不一致的数据。ConcurrentHashMap实现技术是保证HashEntry几乎是不可变的。

## 21-2：为何会出现ConcurrenHashMap?

1. 线程安全，读写还快，以空间换时间

2. 改善了hashmap迭代器出现的ConcurrentModificationException

* 由于ConcurrentHashMap对于会产生并发操作的node都会有加锁同步处理,且迭代器获取tab[index]开头node时都会从主存来获
  
  得,保证获取的数据是最新的，从而保证了迭代器在迭代过程中即使有put , remove 等操作同时发生也可以保证迭代的安全性,不会
  
  出现ConcurrentModificationException

## 21-3：为什么ConcurrentHashMap（hashtable）为何不支持null键和null值

ConcurrentHashmap和Hashtable都是支持并发的，这样会有一个问题，当你通过get(k)获取对应的value时，如果获取到的是null
时，你无法判断，它是put（k,v）的时候value为null，还是这个key从来没有做过映射。HashMap是非并发的，可以通过contains
(key)来做这个判断。而支持并发的Map在调用m.contains（key）和m.get(key),m可能已经不同了。

## 21-4：ConcurrentHashMap的put操作

1. 首先判断是否初始化，如果没有初始化则进入initTable()方法进行初始化工作
2. 如果已经初始化了，进入无限循环，判断key对应的数组下标是否有值了
3. 如果key对应的下标没有值，通过CAS原理插入，插入成功则退出循环，插入失败则继续循环
4. 如果key对应的下标已经存在值,判断此时hash==MOVED(-1),则进入帮助扩容。
5. 如果key对应的下标已经存在值，但是hash!=MOVED,则需要对数组的这个下标进行加锁了，以保证线程的安全。
6. 如果数组的这个下标是一个链表，则对操作链表（判断链表用hash>=0）
7. 如果数组的这个下标是一个红黑树，则操作红黑树。
8. 插入成功后，如果链表的长度已经达到了红黑树的阀门8，则首先判断此时数组的长度是否大于64，如果小于64则进行扩容，如果
   大于等于64则链表变成红黑树
9. 判断容器是否扩容

## 21-5：分段锁原理

它内部细分了若干个小的 HashMap，称之为段(Segment)。默认情况下一个 ConcurrentHashMap 被进一步细分为 16 个段，既就是锁的并发度。如果需要在
ConcurrentHashMap 添加一项key-value，并不是将整个 HashMap 加锁，而是首先根据 hashcode 得到该key-value应该存放在哪个段中，然后对该段加锁，
并完成 put 操作。在多线程环境中，如果多个线程同时进行put操作，只要被加入的key-value不存放在同一个段中，则线程间可以做到真正的并行。

ConcurrentHashMap 是一个 Segment 数组， Segment 通过继承ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保
证每个 Segment 是线程安全的，也就实现了全局的线程安全

## 21-6：hashmap与ConcurrentHashMap中put的区别

## 21-7：扩容机制

1. 通过计算 CPU 核心数和 Map 数组的长度得到每个线程要帮助处理多少个桶，并且这里每个线程处理都是平均的。默认每
   个线程处理 16 个桶。因此，如果长度是 16 的时候，扩容的时候只会有一个线程扩容。

2. 初始化临时变量,将其在原有基础上扩容两倍。

3.死循环开始转移。多线程并发转移就是在这个死循环中，根据一个 finishing 变量来判断，该变量为 true 表示扩容结束，否则
继续扩容。
3.1 进入一个 while 循环，分配数组中一个桶的区间给线程，默认是 16. 从大到小进行分配。当拿到分配值后，进行 i-- 递减。
这个 i 就是数组下标。（其中有一个 bound 参数，这个参数指的是该线程此次可以处理的区间的最小下标，超过这个下标，就需要
重新领取区间或者结束扩容，还有一个 advance 参数，该参数指的是是否继续递减转移下一个桶，如果为 true，表示可以继续向后
推进，反之，说明还没有处理好当前桶，不能推进)
3.2 出 while 循环，进 if 判断，判断扩容是否结束，如果扩容结束，清空临死变量，更新 table 变量，更新库容阈值。如果没
完成，但已经无法领取区间（没了），该线程退出该方法，并将 sizeCtl 减一，表示扩容的线程少一个了。如果减完这个数以后，
sizeCtl 回归了初始状态，表示没有线程再扩容了，该方法所有的线程扩容结束了。（这里主要是判断扩容任务是否结束，如果结束
了就让线程退出该方法，并更新相关变量）。然后检查所有的桶，防止遗漏。
3.3 如果没有完成任务，且 i 对应的槽位是空，尝试 CAS 插入占位符，让 putVal 方法的线程感知。
3.4 如果 i 对应的槽位不是空，且有了占位符，那么该线程跳过这个槽位，处理下一个槽位。
3.5 如果以上都是不是，说明这个槽位有一个实际的值。开始同步处理这个桶。
3.6 到这里，都还没有对桶内数据进行转移，只是计算了下标和处理区间，然后一些完成状态判断。同时，如果对应下标内没有数据
或已经被占位了，就跳过了。

处理每个桶的行为都是同步的。防止 putVal 的时候向链表插入数据。
4.1 如果这个桶是链表，那么就将这个链表根据 length 取于拆成两份，取于结果是 0 的放在新表的低位，取于结果是 1 放在新
表的高位。
4.2 如果这个桶是红黑数，那么也拆成 2 份，方式和链表的方式一样，然后，判断拆分过的树的节点数量，如果数量小于等于 6，
改造成链表。反之，继续使用红黑树结构。
4.3 到这里，就完成了一个桶从旧表转移到新表的过程。

## 21-8：什么时候会发生扩容机制

1. put操作（插入键值对）

2. putAll操作（批量插入键值对）

3. remove操作（移除元素，底层实现是用null空值代替原位元素）

4. replace操作（对已存在的键值对替换值）

5. computeIfAbsent操作（若key对应的value为空，会将第二个参数的返回值存入并返回）

# 22.java基础-集合map-TreeMap

## 22-1：TreeMap底层原理：

TreeMap是桶+红黑树的实现方式.TreeMap的底层结构就是一个数组,数组中每一个元素又是一个红黑树.当添加一个元素
(key-value)的时候,根据key的hash值来确定插入到哪一个桶中(确定插入数组中的位置),当桶中有多个元素时,使用红黑树进行保
存;当一个桶中存放的数据过多,那么根据key查找的效率就会降低

## 22-2：使用场景

1. 需要基于排序的统计功能：

2. 需要快速增删改查的存储功能：

3. 需要快速增删改查而且需要保证遍历和插入顺序一致的存储功能：

# 23.java基础-集合map-LinkedHashmap

## 23-1：linkedhashmap的底层原理

LinkedHashMap继承于HashMap，底层使用哈希表和双向链表来保存所有元素，并且它是非同步，允许使用null值和null键。
基本操作与父类HashMap相似，通过重写HashMap相关方法，重新定义了数组中保存的元素Entry，来实现自己的链接列表特性。该Entry除了保存当前对象的引用外，还保存了其上一个元素before和下一个元素after的引用，从而构成了双向链接列表。

# 24.java基础-集合map-HashTable

## 24-1：HashTable的底层原理

Hashtable是基于哈希表的Map接口的同步实现，不允许使用null值和null键
底层使用数组实现，数组中每一项是个单链表，即数组和链表的结合体
Hashtable在底层将key-value当成一个整体进行处理，这个整体就是一个Entry对象。Hashtable底层采用一个Entry[]数组来保存所有的key-value对，当需要存储一个Entry对象时，会根据key的hash算法来决定其在数组中的存储位置，在根据equals方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry时，也会根据key的hash算法找到其在数组中的存储位置，再根据equals方法从该位置上的链表中取出该Entry。
synchronized是针对整张Hash表的，即每次锁住整张表让线程独占

# 25.java基础-集合list-ArrayList

## 25-1：数组(Array)和列表(ArrayList)有什么区别？ 什么时候应该使用 Array 而不是ArrayList？
1. 定义上： Array 可以包含基本类型和对象类型， ArrayList 只能包含对象类型。 
2. 容量上： Array 大小固定， ArrayList 的大小是动态变化的。 
3. 操作上： ArrayList 提供更多的方法和特性， 
   
使用基本数据类型或者知道数据元素数量的时候可以考虑 Array;ArrayList 处理固定数量的基本类型数据类型时会自动装箱来减少
编码工作量，但是相对较慢。

## 25-2：arraylist底层

ArrayList 底层是通过维护了一个Object数组实现的，特点是查询速度快，增加删除慢
ArrayList 使用无参构造函数创建对象时，Object数组默认的容量是10，当长度不够时，自动增长0.5倍，也就是原来数组长度的1.5倍
当数据需要频繁的查询，而增加删除较少的时候，建议使用ArrayList数组存储数据。

## 25-2：扩容机制

1. 当前数组是由默认构造方法生成的空数组并且第一次添加数据。此时minCapacity等于默认的容量（10）那么根据下面逻辑可以看
   到最后数组的容量会从0扩容成10。而后的数组扩容才是按照当前容量的1.5倍进行扩容；
2. 当前数组是由自定义初始容量构造方法创建并且指定初始容量为0。此时minCapacity等于1那么根据下面逻辑可以看到最后数组的
   容量会从0变成1。这边可以看到一个严重的问题，一旦我们执行了初始容量为0，那么根据下面的算法前四次扩容每次都 +1，在
   第5次添加数据进行扩容的时候才是按照当前容量的1.5倍进行扩容。
3. 当扩容量（newCapacity）大于ArrayList数组定义的最大值后会调用hugeCapacity来进行判断。如果minCapacity已经大于
   Integer的最大值（溢出为负数）那么抛出OutOfMemoryError（内存溢出）否则的话根据与MAX_ARRAY_SIZE的比较情况确定是
   返回Integer最大值还是MAX_ARRAY_SIZE。这边也可以看到ArrayList允许的最大容量就是Integer的最大值（-2的31次方~2的
   31次方减1）。

## 25-3：ArrayList的add操作

不是原子操作，原因主要是elementData[size++] = e可以继续进行拆分

## 25-4：Arraylist初始大小以及扩容大小

ArrayList添加第一个元素时，数组的容量设置为10

4.当ArrayList数组超过当前容量时，扩容至1.5倍（遇到计算结果为小数的，向下取整），第一次扩容后，容量为15，第二次扩容至22

## 25-5：那如何解决ArrayList线程不安全问题呢？

1. 用Vector代替ArrayList
2. 用Collections.synchronized(new ArrayList<>())
   *  因为Collections.synchronizedList封装后的list，list的所有操作方法都是带synchronized关键字的，相当于所有操作
      都会进行加锁，所以使用它是线程安全的但是除迭代数组之外
3. CopyOnWriteArrayList
   * 写操作：添加元素时，不直接往当前容器添加，而是先拷贝一份数组，在新的数组中添加元素后，在将原容器的引用指向新的容
     器。因为数组时用volatile关键字修饰的，所以当array重新赋值后，其他线程可以立即知道（volatile的可见性）
   * 读操作：读取数组时，读老的数组，不需要加锁。
   * 读写分离：写操作是copy了一份新的数组进行写，读操作是读老的数组，所以是读写分离。

## 25-6：ArrayList底层原理

ArrayList是List接口的可变数组非同步实现，并允许包括null在内的所有元素。
底层使用数组实现
该集合是可变长度数组，数组扩容时，会将老数组中的元素重新拷贝一份到新的数组中，每次数组容量增长大约是其容量的1.5倍，这种操作的代价很高。
采用了Fail-Fast机制，面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险
remove方法会让下标到数组末尾的元素向前移动一个单位，并把最后一位的值置空，方便GC

# 26.java基础-集合list-vector

由于vector中Add方法加了synchronized，来保证add操作是线程安全的

## 26-1：Vector是保证线程安全的

Vector 的所有方法加上了 synchronized 关键字，

# 27.java基础-集合list-linkedlist

## 27-1：LinkedList底层原理

LinkedList是List接口的双向链表非同步实现，并允许包括null在内的所有元素。
底层的数据结构是基于双向链表的，该数据结构我们称为节点
双向链表节点对应的类Node的实例，Node中包含成员变量：prev，next，item。其中，prev是该节点的上一个节点，next是该节点的下一个节点，item是该节点所包含的值。
它的查找是分两半查找，先判断index是在链表的哪一半，然后再去对应区域查找，这样最多只要遍历链表的一半节点即可找到

# 28.java基础-集合set-set

## 28-1：set底层原理

1.在调用add方法添加元素时,先判断该元素的hash值和集合中原有元素的hash值,不一样则添加进来.
2.如果hash值相同,则内部调用equals方法比较值,不同则放入,相同则不加入.

# 28.java基础-集合set-HashSet

## 28-1：hashset原理

HashSet由哈希表(实际上是一个HashMap实例)支持，不保证set的迭代顺序，并允许使用null元素。
基于HashMap实现，API也是对HashMap的行为进行了封装，可参考HashMap

## 28-2：hashSet的内存泄漏

当一个对象被存储进HashSet集合中以后，就不能修改该对象的参与计算哈希值的属性值了，否则对象修改后的哈希值与最初存储进

HashSet集合中时的哈希值就不同了，在这种情况下，即使在contains方法使用该对象的当前引用作为参数去HashSet集合中检索对
象，也将返回找不到对象的结果，这也会导致无法从HashSet集合中删除当前对象，造成内存泄露。

## 28-3：为什么HashSet不安全

底层add操作���保证可见性、原子性。所以不是线程安全的

## 28-4：如何保证线程安全

1. 使用Collections.synchronizedSet

2. 使用CopyOnWriteArraySet

# 29.java基础-集合set-TreeSet

## 29-1：TreeSet原理

# 30.java基础-集合set-LinkedHashSet

## 30-1：LinkedHashSet

对于LinkedHashSet而言，它继承与HashSet、又基于LinkedHashMap来实现的。

LinkedHashSet底层使用LinkedHashMap来保存所有元素，它继承与HashSet，其所有的方法操作上又与HashSet相同。

# 31.java基础-集合-集合大比较（区别和使用场景）

## 31-1：线程安全/非线程安全的集合

1. 线程安全
   
* Vector
* HashTable
* StringBuffer

2. 非线程安全

* ArrayList
* LinkedList
* HashMap
* HashSet
* TreeMap
* TreeSet
* StringBulider


## 31-2：set和list、map的区别

1. List(对付顺序的好帮手)：List接口存储一组不唯一（可以有多个元素引用相同的对象），有序的对象

2. Set(注重独一无二的性质):不允许重复的集合。不会有多个元素引用相同的对象。

3. Map(用Key来搜索的专家):使用键值对存储。Map会维护与Key有关联的值。两个Key可以引用相同的对象，但Key不能重复，典型的Key是String类型，但也可以是任何对象。

## 31-3：arraylist、linkedlist区别和适用场景

1. 是否保证线程安全： ArrayList在单线程下是线程安全的，多线程下由于多个线程不断抢夺资源，所以会出现不安全
                     -------和 LinkedList 都是不同步的，也就是不保证线程安全；
2. 底层数据结构： Arraylist 底层使用的是 Object 数组；LinkedList 底层使用的是 双向链表 数据结构
3. 插入和删除是否受元素位置的影响： 
   ① ArrayList 采用数组存储，所以插入和删除元素的时间复杂度受元素位置的影响。 
   ② LinkedList 采用链表存储，插入，删除元素时间复杂度不受元素位置的影响，如果是要在指定位置i插入和删除元素的话需要先移动到指定位置再插入。
4. 是否支持快速随机访问： LinkedList 不支持高效的随机元素访问，而 ArrayList 支持。快速随机访问就是通过元素的序号快速获取元素对象(对应于get(int index) 方法)。<br>
5. 内存空间占用： ArrayList的空间浪费主要体现在在list列表的结尾会预留一定的容量空间，而LinkedList的空间花费则体现在它的每一个元素都需要消耗比ArrayList更多的空间（因为要存放直接后继和直接前驱以及数据）

<font color="#986078">使用场景：</font>

当需要对数据进行对此访问的情况下选用ArrayList，当需要对数据进行多次增加删除修改时采用LinkedList。

## 31-4：vector、Arraylist区别和适用场景

1. 线程：Vector是多线程安全的，
2. 底层：两个都是数组实现，
3. 时间复杂度：Vector类中的方法很多有synchronized进行修饰，这样就导致了Vector在效率上无法与ArrayList相比
4. 内存：但是当空间不足的时候，两个类的增加方式是不同。vector增长率为目前数组长度的100%,而arraylist增长率为目前数组长度的41%
5. 其他：Vector可以设置增长因子，而ArrayList不可以
   
<font color="#986078">使用场景：</font>

1. 安全因素
2. 在集合中使用数据量比较大的数据

## 31-5：HashMap、Treemap、linkedHashMap区别和适用场景

1. 线程安全：都不是线程安全的
2. 底层：TreeMap的底层是红黑树，能够按照键值进行升序排列，而HashMap与linkedHashMap是基于哈希表实现，
3. 时间复杂度：Treemap由于是红黑树，hashmap要更快一些，
4. 内存，由于Treemap使用的是红黑树，内存要大于另外两个， 又因为linkedhashmap多维护了一个双向链表，也要大约hashmap
5. 其他：hashmap排序是无序的。另外两种排序有序
   
<font color="#986078">使用场景：</font>

## 31-6：HashTable、Hashmap区别和适用场景

1. 线程安全，hashtable更加安全
2. 底层，hashtable底层加入了锁保护
3. 时间复杂度，由于加入了锁保护，hashtable时间复杂度要低于hashmap
4. 内存，
5. 其他

<font color="#986078">使用场景：</font>

1. 若在单线程中，我们往往会选择HashMap；
2. 而在多线程中，则会选择Hashtable。(02)，
3. 若不能插入null元素，则选择Hashtable；否则，可以选择HashMap。

## 31-7： ConcurrentHashMap、Hashmap区别和适用场景

1. ConcurrentHashMap对桶数组进行了分段，而HashMap并没有。
2. ConcurrentHashMap在每一个分段上都用锁进行了保护。HashMap没有锁机制。所以，前者线程安全的，后者不是线程安全的。
   
<font color="#986078">使用场景：</font>

1.安全因素

## 31-8： Hashset、Hashmap区别和适用场景

待定
1. 接口：实现了Map接⼝ 实现Set接⼝
2. 存储：存储键值对 仅存储对象
3. 添加元素：调⽤ put（）向map中添加元素       调⽤ add（） ⽅法向Set中添加元素
4. 计算：HashMap使⽤键（Key）计算Hashcode     HashSet使⽤成员对象来计算hashcode值，对于两个对象来说hashcode可能相同，所以equals()⽅法⽤来判断对象的相等性，
   
<font color="#986078">使用场景：</font>

## 31-9：treeset、hashset区别和适用场景

1. TreeSet 是二差树实现的,Treeset中的数据是自动排好序的，不允许放入null值
   HashSet 是哈希表实现的,HashSet中的数据是无序的，可以放入null，但只能放入一个null，两者中的值都不能重复，就如数据库中唯一约束

2. HashSet要求放入的对象必须实现HashCode()方法，放入的对象，是以hashcode码作为标识的，而具有相同内容的String对象，hashcode是一样，所以放入的内容不能重复。但是同一个类的对象可以放入不同的实例	

<font color="#986078">使用场景：</font>

在我们需要排序的功能时，我们才使用TreeSet。

## 31-10：JAVA集合类

集合框架有Map和Collection两大类

1. Collection
   1. List
        * Arraylist： Object数组
        * Vector： Object数组
        * LinkedList： 双向链表(JDK1.6之前为循环链表， JDK1.7取消了循环)
    2. Set
        * HashSet（⽆序，唯⼀） : 基于 HashMap 实现的，底层采⽤ HashMap 来保存元素
        * LinkedHashSet： LinkedHashSet 继承于 HashSet，并且其内部是通过 LinkedHashMap 来实现的。有点类似于我们之前说的LinkedHashMap 其内部是基于 HashMap 实现⼀样，不过还是有⼀点点区别的
        * TreeSet（有序，唯⼀）： 红⿊树(⾃平衡的排序⼆叉树)
    3. Queue


2. Map
    1. HashMap： JDK1.8之前HashMap由数组+链表组成的，数组是HashMap的主体，链表则是主要为了解决哈希冲突⽽存在的（“拉链法”解决冲突）。 JDK1.8以后在解决哈希冲突时有了较⼤的变化，当链表⻓度⼤于阈值（默认为8）时，将链表转化为红⿊树，以减少搜索时间
    2. LinkedHashMap： LinkedHashMap 继承⾃ HashMap，所以它的底层仍然是基于拉链式散列结构即由数组和链表或红⿊树组成。另外， LinkedHashMap 在上⾯结构的基础上，增加了⼀条双向链表，使得上⾯的结构可以保持键值对的插⼊顺序。同时通过对链表进⾏相应的操作，实现了访问顺序相关逻辑。详细可以查看： 
    3. Hashtable： 数组+链表组成的，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突⽽存在的
    4. TreeMap： 红⿊树（⾃平衡的排序⼆叉树）

## 31-11：并发集合

1. Queue
  * ConcurrentLinkedQueue
  * BlockingQueue
    * ArrayBlockingQueue：基于数组、先进先出、线程安全，可实现指定时间的阻塞读写，并且容量可以限制
    * LinkedBlockingQueue：基于链表实现，读写各用一把锁，在高并发读写操作都多的情况下，性能优于ArrayBlockingQueue
  * Deque
2. CopyOnWriteArrayList：线程安全且在读操作时无锁的ArrayList
3. CopyOnWriteArraySet：基于CopyOnWriteArrayList，不添加重复元素
4. ConcurrentMap：线程安全的HashMap的实现
   * ConcurrentHashMap
   * ConcurrentNavigableMap

主要是跟下方的并发容器[一起看](#14并发容器)

## 31-12：并发集合出现的原因

比如说若当前线程在扩容并发的时候，此时获得ertry节点，但是被线程中断无法继续执行，此时线程二进入transfer 函数，并把函数顺利执行，

此时新表中的某个位置有了节点，之后线程一获得执行权继续执行，因为并发 transfer，所以两者都是扩容的同一个链表，

当线程一执行到new table[i]的时候，由于线程二之前数据迁移的原困导致此时new table[i]上就有ertry存在，

所以线程一执行的时候，会将next节点，设置为自己，导致自己互相使用next引用对方，因此产生链表，导致死循环。

但是在JDK 8用head 和 tail 来保证链表的顺序和之前一样。

## 31-13：collection与collections的区别

java.util.Collection 是一个集合接口
Collections则是集合类的一个工具类/帮助类，其中提供了一系列静态方法

## 31-14：Collections有哪些静态方法

1. 排序(Sort)

2. 混排（Shuffling）

3. 反转(Reverse)

4. 替换所有的元素(Fill)

5. 拷贝(Copy)

6. 返回Collections中最小元素(min)

7. 返回Collections中最小元素(max)

## 31-15：Comparable和Comparator区别

1. 实现Comparable的类，该类就具有自身比较的功能；Comparator的实现，是一个外部比较工具器 

# 32.java基础-设计类问题

## 32-1：如果想要一个key对应多个Value的话，怎么设计Map

https://blog.csdn.net/yanzhenjie1003/article/details/42541264?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase


## 32-2：插入一万个元素之后会不会扩容，扩容扩多少

HashMap 是否扩容，由 threshold 决定，而 threshold 又由初始容量和 loadFactor 决定。

1. HashMap 构造方法传递的 initialCapacity，它实际表示 table 的容量。
   
   * 只是代表了 table 数组容量为 1000

2. 构造方法传递的initialCapacity，最终会被tableSizeFor()方法动态调整为2的N次幂，以方便在扩容的时候，计算数据在
   newTable中的位置。

  * 虽然你传入了10000，但是实际传入的是10000/loadFactor，但是呢会调整为最接近的2 的 N 次幂
  
    * 如：实际传入了10000/0.75=13333，最接近的是2^13=16384，那么就采用16384
  
3. 如果设置了table的初始容量，会在初始化 table 时，将扩容阈值 threshold 重新调整为 table.size * loadFactor。

  * 那么可以储存的最大容量就是：16384*0.75=12288

## 32-3：创建一个对象HashMap<Integer,Integer> map=new HashMap<>先put(10),然后get(new Long(10))结果是多少？

为空，原因是

1. hashmap在存入的时候，先对key做一遍hash，以hash值作为数组下标，如果发现下标已有值，判断存的key跟传入的key是不是
   相同，如果相同覆盖，显然Integer 和 Long 肯定不是一个类型，所以 Long 123 和 Integer 123 hashmap会认为是 hash冲
   突

2. hashmap 在 get的时候，也是先做hash处理，根据hash值查找对应的数组下标查找,虽然存入Integer 123  根据 Long 123 
   来获取返回的 是 NULL

## 32-4：使用final static修饰集合hashmap会产生什么影响

当final修饰变量时，对于基本类型和string，这个变量的值是不能改变的；

当修饰其他类型的对象时，final使其引用恒定不变，但是对象自身却可以自由修改变换。


# 33.java基础-IO-各种流

## 33-1：为何还要有字符流

因为我们不知道编码类型很容易出现乱码，所以IO就提供了一个直接操作字符的接口

## 33-2：字节流和字符流区别

1. 字节流不会用到缓冲区(内存)的，而字符流在操作的时候是使用到缓冲区的
2. 字节流在操作文件时，即使不关闭资源，文件也能输出，
   但是如果字符流不使用close方法的话，则不会输出任何内容，
   只有在使用flush方法强制进行刷新缓冲区，这时才能在不close的情况下输出内容
3. 字节流:处理字节和字节数组或二进制对象;字符流:处理字符、字符数组或字符串。

## 34-2：IO读取方法

1、FileInputStrem和FileOnputStream字节流逐字节读写（速度最慢）
 
2、FileInputStrem和FileOnputStream构造一个缓冲数组进行读写（速度提升）

3、利用字节缓冲区流BufferedInputStream和BufferedOutputStream来直接逐字节读写（速度较快）

4、利用字节缓冲区流BufferedInputStream和BufferedOutputStream通过构造一个缓冲数组进行读写（速度最快）

5、利用字符流InputStreamWriter和 OutputStreamWriter直接按字节读取

6、字符流InputStreamWriter和 OutputStreamWriter直接用缓冲区数组读写

7、字符缓冲流BufferedWriter和BufferedReader直接逐字节读写

8、字符缓冲流BufferedWriter和BufferedReader按照数组大小逐块读写

9、字符缓冲流BufferedWriter和BufferedReader按逐行读写（应用于文本读写）

# 34.IO读取程序

## 34-1：将c盘的文件复制到d盘
```java
public class CopyTextFileTest {

public static void main(String[] args) {

               FileReader fr = null;

               FileWriter fw = null;

                  try {
                  //1,创建一个字符读取流读取与源数据相关联。
                  fr = new FileReader("demo.txt");
                  //2,创建一个存储数据的目的地。
                  fw = new FileWriter("copyDemo.txt");
                  //3,创建一个字符数组将读取流对象和写入流对象相连接。
                  char[] buf = new char[1024];
                  //4,每次读取的长度不一样，所以定义一个变量.
                  int len = 0;
                  //5,用循环读取文件中的数据
                  while((len= fr.read(buf)) != -1)//判断是否读取完没
                  fw.write(buf,0,len);//为了只读取有效的数据
                  } catch (Exception e) {
                  }finally{
                  try {fr.close();} catch (IOException e) {e.printStackTrace();}
                  try {fw.close();} catch (IOException e) {e.printStackTrace();}}}}
```

# 35.同异步、阻塞非阻塞

## 33-3：同步、异步与阻塞、非阻塞

同步：执行一个操作之后， 等待结果，然后执行其他后续的操作

异步：执行一个操作后，可以去执行其他的操作，然后等待通知再回来执行刚才没有执行完的操作

阻塞：进程给CPU传达一个任务后，一直等待CPU处理完成，然后执行后面的操作

非阻塞：进程给CPU传达一个任务后，继续处理其他的操作，隔段时间来询问之前的操作是否完成

# 36.BIO\NIO\AIO
## 33-4：BIO\NIO\AIO区别

BIO (Blocking I/O): 同步阻塞 I/O 模式，数据的读取写入必须阻塞在一个线程内等待其完成。

（NIO与IO区别）NIO (Non-blocking/New I/O): NIO 是一种同步非阻塞的I/O模型，

1. IO流是阻塞的，NIO流是不阻塞的。比如说，单线程中从通道读取数据到buffer，同时可以继续做别的事情，当数据读取到
   buffer中后，线程再继续处理数据。Java IO的各种流是阻塞的。这意味着，当一个线程调用 read() 或 write() 时，该线程
   被阻塞，直到一些数据被读取，或数据完全写入。该线程在此期间不能干其他任何事情了

2. IO面向流(Stream oriented)，而NIO面向缓冲区(Buffer oriented)。在面向流的I/O中,可以将数据直接写入或者将数据直接
   读到Stream对象中。在从流读到缓冲区，因为Buffer是一个对象，它包含一些要写入或者要读出的数据。NIO是直接读到Buffer
   中进行操作。

3. NIO通过Channel（通道）进行读写。通道是双向的，可读也可写，而流的读写是单向的。无论读写，通道只能和Buffer交互。因
   为 Buffer，通道可以异步地读写。

4. NIO有选择器，而IO没有。线程之间的切换对于操作系统来说是昂贵的，因此选择器用于使用单个线程处理多个通道提高系统效率
   选择器是有用的。

AIO: AIO 也就是NIO2。在引入了NIO的改进版,它是异步非阻塞的IO模型。异步IO是基于事件和回调机制实现的，也就是应用操作之
后会直接返回，不会阻塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。

## 33-5：linux的5种IO模型

1. 阻塞式IO模型

2. 非阻塞IO模型

3. IO复用模型

4. 信号驱动IO模型

5. 异步IO模型

## 33-6：IO多路复用

如果有一百万个I/O流进来，那我们就需要开启一百万个进程一一对应处理这些I/O流，这样会造成CPU占有率会多高，这个实现方式
及其的不合理。

所以人们提出了I/O多路复用这个模型，一个线程，通过记录I/O流的状态来同时管理多个I/O，可以提高服务器的吞吐能力

## 33-7：三种常用的实现方式-select

a. 从用户空间将fd_set拷贝到内核空间
　　b. 注册回调函数
　　c. 调用其对应的poll方法
　　d. poll方法会返回一个描述读写是否就绪的mask掩码，根据这个mask掩码给fd_set赋值。
　　e. 如果遍历完所有的fd都没有返回一个可读写的mask掩码，就会让select的进程进入休眠模式，直到发现可读写的资源后，重
新唤醒等待队列上休眠的进程。如果在规定时间内都没有唤醒休眠进程，那么进程会被唤醒重新获得CPU，再去遍历一次fd。
　　f. 将fd_set从内核空间拷贝到用户空间

select函数优缺点
　　缺点：两次拷贝耗时、轮询所有fd耗时，支持的文件描述符太小
　　优点：跨平台支持

## 33-8：三种常用的实现方式-poll

poll函数的调用过程（与select完全一致）

　　优点：连接数没有限制（链表存储）
　　缺点：大量拷贝，水平触发（当报告了fd没有被处理，会重复报告，很耗性能）

## 33-9：三种常用的实现方式-epoll

epoll的优点

没有最大并发连接的限制
只有活跃可用的fd才会调用callback函数
内存拷贝是利用mmap()文件映射内存的方式加速与内核空间的消息传递，减少复制开销。（内核与用户空间共享一块内存）
只有存在大量的空闲连接和不活跃的连接的时候，使用epoll的效率才会比select/poll高

## 33-10：三种常用的实现方式区别

(1)select==>时间复杂度O(n)

只是知道有I/O事件发生了，却并不知道是哪那几个流，我们只能无差别轮询所有流，找出能读出数据，同时处理的流越多，无差别轮
询时间就越长。

(2)poll==>时间复杂度O(n)

poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， 但是它没有最大连接数的
限制，原因是它是基于链表来存储的.

(3)epoll==>时间复杂度O(1)

epoll可以理解为event poll，不同于忙轮询和无差别轮询，epoll会把哪个流发生了怎样的I/O事件通知我们。所以我们说epoll实
际上是事件驱动（每个事件关联上fd）的，此时我们对这些流的操作都是有意义的。

例子：

1. select大妈 每一个女生下楼, select大妈都不知道这个是不是你的女神, 她需要一个一个询问, 并且select大妈能力还有限, 
   最多一次帮你监视1024个妹子
2. poll大妈不限制盯着女生的数量, 只要是经过宿舍楼门口的女生, 都会帮你去问是不是你女神
3. epoll大妈不限制盯着女生的数量, 并且也不需要一个一个去问. 那么如何做呢? epoll大妈会为每个进宿舍楼的女生脸上贴上一
   个大字条,上面写上女生自己的名字, 只要女生下楼了, epoll大妈就知道这个是不是你女神了, 然后大妈再通知你.

# 34.java基础-IO流读取




# 34.java基础-反射

## 34-1：什么是反射

JAVA 反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一
个方法和属性

## 34-2：反射会导致性能问题呢？

由于反射的时候调用了native方法，可能暂时无法准确判断

可能造成的原因也是可能是

在程序运行时操作class有关，比如需要判断是否安全？是否允许这样操作？入参是否正确？

是否能够在虚拟机中找到需要反射的类？主要是这一系列判断条件导致了反射耗时；

也有可能是因为调用natvie方法，需要使用JNI接口，导致了性能问题

在四种访问方式当中，直接访问实例的方式效率最高；

其次是直接调用方法的方式；

接着是通过反射访问实例的方式；

最慢的是通过反射访问方法的方式


## 34-3：如果避免反射导致的性能问题？

不要过于频繁地使用反射，大量地使用反射会带来性能问题；

通过反射直接访问实例会比访问方法快很多，所以应该优先采用访问实例的方式。

## -1：Class类的作用



## 34-2：获取class对象方法

1. Object类的getClass();
2. 任何数据类型（包括基本数据类型）都有一个“静态”的class属性
3. 通过Class类的静态方法：forName(常用)

## 34-3：Class.forName和classloader.loadClass的区别

1. 初始化不同:
   * Class.forName()会对类初始化，而loadClass()只会装载或链接。
   * foranme在类加载的时候会执行静态代码块，loadclass只有在调用newInstance方法的时候才会执行静态代码块
2. 类加载器不同:
   * Class.forName(String)方法(只有一个参数)，哪个调用了forname就用那个类加载器
   * ClassLoader.loadClass()方法是一个实例方法，调用时需要自己指定类加载器

## 34-4：哪些类不能反射

枚举，因为枚举类类的修饰abstract，所以没法实例化，反射也无能为力

## 34-5：反射优缺点

优点： 动态编译可以最大程度地支持多态，而多态最大的意义在于降低类的耦合性，因此反射的优点就很明显了:解耦以及提高代码
的
       灵活性。

缺点： 1、性能瓶颈：反射相当于一系列解释操作，通知 JVM 要做的事情，性能比直接的 java 代码要慢很多。
        
      2、安全问题，让我们可以动态操作改变类的属性同时也增加了类的安全隐患。

## 34-6：反射的应用场景

1. 使用 JDBC 连接数据库时使用 Class.forName()通过反射加载数据库的驱动程序；
2. Spring 框架的 IOC（动态加载管理 Bean）创建对象以及 AOP（动态代理）功能都和反射有联系；
3. 动态配置实例的属性；

## -7：反射实例

```java
首先创建一个类
public class Car {
    private String brand;
    private String color;
    private int maxSpeed;


通过反射思路创建

public class ReflectTest {

    public static Car initByDefaultConst() throws Throwable {

        //①通过类装载器获取Car类对象
        ClassLoader loader = Thread.currentThread().getContextClassLoader();
        Class clazz = loader.loadClass("com.smart.reflect.Car");

        //②获取类的默认构造器对象并通过它实例化Car
        Constructor cons = clazz.getDeclaredConstructor((Class[]) null);
        Car car = (Car) cons.newInstance();

        //③通过反射方法设置属性
        Method setBrand = clazz.getMethod("setBrand", String.class);
        setBrand.invoke(car, "红旗CA72");
        Method setColor = clazz.getMethod("setColor", String.class);
        setColor.invoke(car, "黑色");
        Method setMaxSpeed = clazz.getMethod("setMaxSpeed", int.class);
        setMaxSpeed.invoke(car, 200);
        return car;
    }

    public static void main(String[] args) throws Throwable {
        Car car = initByDefaultConst();
        car.introduce();
    }
}
```




# 35.java基础-注解

## 35-1：元注解以及分类

定义其他注解的注解 ，共四个

1. @Target（表示该注解可以用于什么地方）

2. @Retention（表示再什么级别保存该注解信息）

3. @Documented（将此注解包含再javadoc中）

4. @Inherited（允许子类继承父类中的注解）
 
## 35-2：Java常用注解

1. @Override 表示当前方法覆盖了父类的方法

2. @Deprecation 表示方法已经过时,方法上有横线，使用时会有警告。

3. @SuppressWarnings 表示关闭一些警告信息(通知java编译器忽略特定的编译警告)

4. SafeVarargs (jdk1.7更新) 表示：专门为抑制“堆污染”警告提供的。

5. @FunctionalInterface (jdk1.8更新) 表示：用来指定某个接口必须是函数式接口，否则就会编译出错。

扩展[Spring常用注解]()

# 36.java基础-泛型

## 36-1：什么是泛型

1. 允许在定义类和接口的时候使⽤类型

2. 泛型可以提⾼代码的复⽤性

## 36-2：编译器如何处理泛型

1. Code specialization：在实例化一个泛型类或泛型方法时都产生一份新的字节码or二进制代码。

2. Code sharing：对每个泛型类只生成唯一的一份目标代码；该泛型类的所有实例都映射到这份目标代码上，在需要的时候执行类
   型检查和类型转换。

## 36-3：为什么Java要用这种编译器

1. C++和C#是使用Code specialization的处理机制，他有几个缺点:
   * 导致代码膨胀。
   * 在引用类型系统中，浪费空间

2. Java编译器通过Code sharing方式为每个泛型类型创建唯一的字节码表示，并且将该泛型类型的实例都映射到这个唯一的字节码
   表示上。将多种泛型类形实例映射到唯一的字节码表示是通过类型擦除（type erasue）实现的。

## 36-4: 什么是类型擦除

Java的泛型基本上都是在编译器这个层次上实现的，在生成的字节码中是不包含泛型中的类型信息的，使用泛型的时候加上类型参
数，在编译器编译的时候会去掉，这个过程成为类型擦除。

## 36-5：类型擦除过程

1. 将所有的泛型参数用最顶级的父类型进行替换。 

2. 移除所有的类型参数

## 36-6：泛型带来的问题

1. 虚拟机中没有泛型，只有普通类和普通方法,所有泛型类的类型参数在编译时都会被擦除,泛型类并没有自己独有的Class类对象。
   比如并不存在List<String>.class或是List<Integer>.class，而只有List.class。 

2. 创建泛型对象时需要指明类型，让编译器尽早的做参数检查

3. 不要忽略编译器的警告信息，那意味着潜在的ClassCastException等着你。 

4. 静态变量是被泛型类的所有实例所共享的。
    
5. 泛型的类型参数不能用在Java异常处理的catch语句中。

## 36-7：List泛型和原始类型List之间的区别?

 List<Object>和原始类型List之间的区别?
1. 在编译时编译器不会对原始类型进行类型安全检查，会对带参数的类进行检查
2. 你可以把任何带参数的类型传递给原始类型List，但是list会产生编译错误

## 36-8：List泛型和原始类型List泛型之间的区别?

List<?>和原始类型List<Object>之间的区别?

List<?>是一个未知类型的List，而List<Object> 其实是任意类型的List。你可以把List<String>, List<Integer>赋值给
List<?>，却不能把List<String>赋值给 List<Object>。

## 36-9:子类继承父类的public可以写成private吗

可以写，但是变为private之后，需要对方法重写写get/set方法

## 36-10：多态时是否会出现类型擦除

会出现类型擦除

编译器在编译一个继承自泛型类的子类时，为了方法覆盖的签名匹配，保留泛型类型的多态性，会生成一个桥接方法

# 37-java基础-异常

## 37-1：异常的分类

1. Error表⽰系统级的错误，是java运⾏环境内部错误或者硬件问题，不能指望程序来处理这样的问题

2. Exception 表⽰程序需要捕捉、 需要处理的常， 是由与程序设计的不完善⽽出现的问题， 程序必须处理的问题。

## 37-2：Error和Exception的区别

1. Exception是java程序运行中可预料的异常情况，咱们可以获取到这种异常，并且对这种异常进行业务外的处理。

2. Error是java程序运行中不可预料的异常情况，这种异常发生以后，会直接导致JVM不可处理或者不可恢复的情况。所以这种异常不可能抓取到，比如OutOfMemoryError、NoClassDefFoundError等。

## 37-2：Java 中的两种异常类型是什么？ 他们有什么区别？

Java 中有两种异常： 受检查的(checked)异常和不受检查的(unchecked)异常。

1. 不受检查的异常不需要在方法或者是构造函数上声明 
2. 受检查的异常必须要用 throws 语句在方法或者是构造函数上声明。

## 37-3：异常类型

0. Java中的异常， 主要可以分为两⼤类——受检异常（ checked exception） 和 ⾮受检异常（ unchecked exception）

1. 受检异常

这种异常在IO操作中⽐较多。 ⽬的就是告诉这个⽅法的调⽤者，我这个⽅法不保证⼀定可以成功， 是有可能找不到对应的⽂件 
的， 你要明确的对这种情况做特殊处理哦。

2. 非受检异常

这种异常⼀般可以理解为是代码原因导致的。⽐如发⽣空指针、数组越界等。




## 37-4：什么是OOM？常见有哪些OOM？

1. Java堆溢出——OutOfMemoryError

原因：由于不断创建对象实例，当对象数量达到了最大堆的容量限制后产生内存溢出异常。

解决方法：

1)首先确认是内存泄露（Memory Leak）还是内存溢出（Memory Overflow）；

2)如果是内存泄漏引起的，查看GC Roots引用链，找出为什么无法被垃圾回收的原因；

3)如果是内存溢出，检查虚拟机的堆参数（-Xmx最大值和-Xms最小值），对比物理内存看是否可以调大；

2. 虚拟机栈和本地方法栈溢出——StackOverflowError

原因：在单线程下，虚拟机栈容量太小或者定义了大量的本地变量

解决方法：增大虚拟机栈容量

原因：在多线程下，大量创建新线程，会抛出OOM，每个线程的栈分配的内存越大，越容易产生；

解决方法：减少线程产生、降低最大堆、减少栈容量；

3. 运行时常量池溢出

原因：代码在运行时创建了大量的常量，超出了常量池上限；

解决方法：通过修改-XX:PermSize和-XX:MaxPermSize参数来修改方法区大小，从而修改常量池大小；

4.方法区溢出

原因：在运行时，ClassLoader动态加载了大量的Class信息，超出方法区上限；

解决方法：通过修改参数来修改方法区大小；


## 37-3：异常链

是指在进⾏⼀个异常处理时抛出了另外⼀个异常， 由此产⽣了⼀个异常链条。

该技术⼤多⽤于将“ 受检查异常” （ checked exception） 封装成为“⾮受检查异常”（ unchecked exception)或者
RuntimeException。


# 38.java基础-常用类-String底层

## 38-1：String为什么是final的？

1. 它创建的时候HashCode就被缓存了，不需要重新计算，这样在键值对就运行很快
2. 为了线程安全，可以被多个线程调用
3. 只有字符串不变，才能实现字符串池，提高效率


## 38-6：String str = new String("abc");创建了几个对象

分情况讨论：
1. 如果常量池中没有abc，会创建两个
   * 一个是new  String 创建的一个新的对象
   * 一个是常量“abc”对象的内容创建出的一个新的String对象

2. 如果常量池有，会创建一个

## 38-7：String str="abc",堆和常量池中的情况

因为String是不可变的，由final关键字修饰过了，
“abc”字符串，就是作为字面量（常量)写在class的常量池里。

"abc"的一个引用会被存到同样在Non Heap区的字符串常量池(String Pool)里。

而“abc”本体还是和所有对象一样，创建在Heap堆区。

因为一直有一个引用驻留在字符串常量池，所以不会被GC清理掉。

也就是这个abc对象会生存到整个线程结束。

字符串常量池的具体位置是在过去说的永生代里，方法区的外面。

等主线程开始创建str变量的时候，虚拟机就会到字符串常量池里找，

看有没有能equals("abc")的String。如果找到了，

就在栈区当前栈帧的局部变量表里创建str变量，然后把字符串常量池里对

abc对象的引用复制给str变量。

找不到的话，才会在heap堆重新创建一个对象，

然后把引用驻留到字符串常量区。然后再把引用复制栈帧的局部变量表。


## 38-7：String str = new String("abc");堆和常量池中的情况

因为new关键字会在Heap堆申请一块全新的内存，来创建新对象。

虽然字面还是"Hello"，但是完全不同的对象，有不同的内存地址。

运行程序用到运行了new String的类的时候，这个类文件的信息就会被解析到内存的方法区里。

class文件里常量池里大部分数据会被加载到“运行时常量池”。

String s1 = new String(“123”);，

这里要编译时首先涉及到 “123” 这个字面量，因此会先在常量池中创建 “123” 这个对象，

然后通过 new 关键字在堆中再创建一个 “123” 的对象


# 39.java基础-常用类-String拼接方式

## 38-2：拼接方式

1. 使用+
2. 使用concat
3. 使用StringBuilder
4. 使用StringBuffer
5. 使用StringUtils.join

# 40.java基础-常用类-三大String

## 38-3: String、StringBuffer和StringBuilder区别

1. 运行速度上：StringBuilder>StringBuffer>String(因为String每次都要生成新对象)

2. 线程安全：StringBuffer，String 

3. 是否可变：只有String不可变

4. 底层实现：StringBuffer用了同步块synchronized


## 38-4：StringBuffer如何实现线程安全

直接通过synchronized 关键字来实现同步操作





## 38-7：处理数据量较大的字符串用string还是stringbuilder，为什么

Stringbuilder，操作字符串效率更高

注：StringBuffer虽然也可以处理字符而且线程安全，但是处理字符相对Stringbuilder慢

## 38-8：为什么StringBuffer和StringBuilder比String更快（不变性）

1. string类设计成final类型，每次有修改操作时，都会赋值给新的对象。

2. 因为赋值给新的对象，原来的对象就不再引用，就会进行回收。

3. 因为string拼接的扩容机制，当在某个点上，会发生oom(内存用完了)


# 41.java基础-常用类-String成员

## 41-1：String的内部属性

1. 创建一个能够容纳两个数组长度的数组

2. 使用getChars方法，将对象数组中赋值到新的数组中，偏移量为0；
	 
3. 使用getChars()方法将，参数数组赋值到新的数组中，偏移量对象数组的长度。
	 
4. 通过String构造器将数组转换成为新的字符串。

## 41-2：String的常用方法

1. 求字符串长度----length方法

2. 求字符串某一位置字符----charAt方法

3. 提取子串-----substring方法

4. 字符串比较-----compareTo方法

5. 字符串连接-----concat方法

6. 用于查找当前字符串中字符或子串----indexOf方法

7. 字符串中字符的大小写转换-----toLowerCase方法/toUpperCase方法

8. 字符串中字符的替换-----replace方法

## 41-3：subString原理

这个方法是通过new String（偏移量，数量，原字符串值）的构造方法，

进行创建对象，这个方法的好处是为了提高效率实现快速的共享，

但是由于要赋值原有的数据进行截取，

在新的截取的字符串中包含了原来的所有的内容，

占据了相应的内存，但是实际数值只是其中一部分，浪费了大量的内存空间


# 42.java基础-常用类-String应用

## 38-9：如何把一段逗号分割的字符串转换成一个数组?

1 用正则表达式，代码大概为： String [] result = orgStr.split(“,”);
2 用 StingTokenizer 


## 38-5：String 和 char[] 数组谁更适合存密码

相对来说是String更合适，原因是底层有final关键字进行了修饰





# 39.java基础-常用类-枚举

## 39-1：enum线程安全

## 39-2: switch 是否可用于String类型的判断，Java哪个版本之后有此功能的

JDK1.7开始支持

# 40.Java基础-常用类-时间类

## 40-1：SimpDateFormat是线程不安全的类，不要定义为static变量，如果定义，必须加锁或工具类

1. SimpleDateFormat中的format方法在执行过程中，会使用一个成员变量calendar来保存时间。

2. 由于我们在声明SimpleDateFormat的时候，使用的是static定义的。那么这个SimpleDateFormat就是一个共享变量，随之，
   SimpleDateFormat中的calendar也就可以被多个线程访问到。

解决方案：
1. SimpleDateFormat变成了局部变量，就不会被多个线程同时访问到了，就避免了线程安全问题。
2. 通过加锁，使多个线程排队顺序执行。避免了并发导致的线程安全问题。
3. ThreadLocal 可以确保每个线程都可以得到单独的一个 SimpleDateFormat 的对象


# 41.java基础-常用类-Object类

## 41-1：Object类有哪些方法

1．clone方法
保护方法，实现对象的浅复制，只有实现了Cloneable接口才可以调用该方法，否则抛出CloneNotSupportedException异常。

2．getClass方法
final方法，获得运行时类型。

3．toString方法
该方法用得比较多，一般子类都有覆盖。

4．finalize方法
Java允许在类中定义一个名为finalize()的方法。

它的工作原理是：一旦垃圾回收器准备好释放对象占用的存储空间，

将首先调用其finalize()方法。并且在下一次垃圾回收动作发生时，才会真正回收对象占用的内存。

finalize()的用途：
　　无论对象是如何创建的，垃圾回收器都会负责释放对象占据的所有内存。

   这就将对finalize()的需求限制到一种特殊情况，

    即通过某种创建对象方式以外的方式为对象分配了存储空间。
    
    不过这种情况一般发生在使用“本地方法”的情况下，
    
    本地方法是一种在Java中调用非Java代码的方式。

5．equals方法
该方法是非常重要的一个方法。一般equals和==是不一样的，但是在Object中两者是一样的。子类一般都要重写这个方法。

6．hashCode方法
该方法用于哈希查找，重写了equals方法一般都要重写hashCode方法。这个方法在一些具有哈希功能的Collection中用到。

一般必须满足obj1.equals(obj2)==true。可以推出obj1.hash- Code()==obj2.hashCode()，但是hashCode相等不一定就满足equals。不过为了提高效率，应该尽量使上面两个条件接近等价。

7．wait方法
wait方法就是使当前线程等待该对象的锁，当前线程必须是该对象的拥有者，也就是具有该对象的锁。wait()方法一直等待，直到获得锁或者被中断。wait(long timeout)设定一个超时间隔，如果在规定时间内没有获得锁就返回。

调用该方法后当前线程进入睡眠状态，直到以下事件发生。

（1）其他线程调用了该对象的notify方法。

（2）其他线程调用了该对象的notifyAll方法。

（3）其他线程调用了interrupt中断该线程。

（4）时间间隔到了。

此时该线程就可以被调度了，如果是被中断的话就抛出一个InterruptedException异常。

8．notify方法
该方法唤醒在该对象上等待的某个线程。

9．notifyAll方法
该方法唤醒在该对象上等待的所有线程。

## 41-2：为什么操作线程方法会在Object对象中

1. 这些方法存在于同步中；
2. 使用这些方法必须标识同步所属的锁；
3. 锁可以是任意对象，所以任意对象调用方法一定定义在Object类中。

# 42.java基础-序列化

## 42-1：序列化的作用

1)序列化就是一种用来处理对象流的机制,所谓对象流也就是将对象的内容进行流化,可以对流化后的对象进行读写操作,也可以将流化后的对象传输与网络之间;

2)为了解决对象流读写操作时可能引发的问题(如果不进行序列化,可能会存在数据乱序的问题)

3）序列化除了能够实现对象的持久化之外，还能够用于对象的深度克隆

## 42-2：java对象如何实现序列化

1. 通过实现Serializable接口
   

```java
    public class UserInfo implements Serializable{
    private String userName;
    private String usePass;
    ....}

public class UserInfoTest {
    
    /**
     * 序列化对象到文件
     * @param fileName
     */
    public static void serialize(String fileName){
        try {
            ObjectOutputStream out=new ObjectOutputStream(new FileOutputStream(fileName));
            
            out.writeObject("序列化的日期是：");//序列化一个字符串到文件
            out.writeObject(new Date());//序列化一个当前日期对象到文件
            UserInfo userInfo=new UserInfo("郭大侠","961012",21);
            out.writeObject(userInfo);//序列化一个会员对象
            
            out.close();
            
        } catch (FileNotFoundException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
    
    /**
     * 从文件中反序列化对象
     * @param fileName
     */
    public static void deserialize(String fileName){
        try {
            ObjectInputStream in=new ObjectInputStream(new FileInputStream(fileName));
            
            String str=(String) in.readObject();//刚才的字符串对象
            Date date=(Date) in.readObject();//日期对象
            UserInfo userInfo=(UserInfo) in.readObject();//会员对象
            
            System.out.println(str);
            System.out.println(date);
            System.out.println(userInfo);
            
        } catch (FileNotFoundException e) {
            e.printStackTrace();
        } catch (IOException e) {
            e.printStackTrace();
        } catch (ClassNotFoundException e) {
            e.printStackTrace();
        }
    }
```

2. 通过实现ExternalSeri alizable方法

因为一个类中我们只希望序列化一部分数据，其他数据都使用transient修饰的话显得有点麻烦，这时候我们使用externalizable接口，指定序列化的属性。

```java
//实现Externalizable接口序列化
public class UserInfo implements Externalizable{
 private String userName;
 private String usePass;
 private int userAge;

 测试函数同上
```

## 42-3：externalizable和Serializable的区别：

1. 实现serializable接口是默认序列化所有属性，如果有不需要序列化的属性使用transient修饰。

2. 实现serializable接口的对象序列化文件进行反序列化不走构造方法，载入的是该类对象的一个持久化状态，再将
   这个状态赋值给该类的另一个变量

## 42-4：哪些不会被序列化

1. 被static修饰的属性不会被序列化
2. 对象的类名、属性都会被序列化,方法不会被序列化

## 42-5: 什么是serialVersionUID

1. 这样做是为了serialVersionUID是用来验证版本一致性的，保证安全的，因为⽂件存储中的内容可能被篡改。
2. 在进⾏反序列化时， JVM会把传来的字节流中的serialVersionUID与本地相应实体类的serialVersionUID进⾏⽐
   较， 如果相同就认为是⼀致的， 可以进⾏反序列化， 否则就会出现序列化版本不⼀致的异常

# 43.java基础-反序列化

## 43-1：java对象如何实现反序列化

  * 实现Serializable接口的对象在反序列化时不需要调用对象所在类的构造方法。
  * 实现externalSerializable接口的方法在反序列化时会调用构造方法。

# 44.java基础-序列化与反序列化

## 44-1：JAVA中的序列化和反序列化主要用于

（1）将对象或者异常等写入文件，通过文件交互传输信息；
（2）将对象或者异常等通过网络进行传输。

## 42-6：序列化协议有哪些

1. COM,COM的序列化的原理利用了编译器中虚表,使得其学习成本巨大.
2. CORBA，COBRA的主要问题是版本之间兼容性较差,以及使用复杂晦涩.
3. XML&5OAP，无论是性能还是间接性比较差
4. Thrift在时空开销上不太理想
5. JSON，序列化后数据更加简洁，而且解析速度较快
6. protobuf、avro不仅兼容json格式，解析速度更快

## 42-7：该接口并没有方法和字段，为什么只有实现了该接口的类的对象才能被序列化呢？

这是因为，在序列化操作过程中会对类型进行检查，要求被序列化的类必须属于Enum、Array和Serializable类型其中的任何一种。



# 50.JDK8新特性

1. 接口可以添加默认方法，default;
2. lambda表达式，对于接口可以直接用()->{}方式来表达，小括号表示方法入参，花括号内表示方法返回值，如Collections的sort()方法：
3. 函数式接口
4. 新的日期和时间API
5. 并发增强
6. 支持多重注解
7. 特性四、反射的加强 。JDK8加强了反射，它允许你直接通过反射获取参数的名字
8. Stream API
9. JavaScript引擎Nashorn
10. Java虚拟机（JVM）的新特性,PermGen空间被移除了，取而代之的是Metaspace（JEP 122）

# 51.Java实现同步

Java提供了很多同步操作，比如synchronized关键字、wait/notifyAll、ReentrantLock、Condition、一些并发包下的工具类、Semaphore，ThreadLocal、AbstractQueuedSynchronizer等

# 52.持久化对象三种状态

1.瞬时态：也叫做临时态或自由态，它一般指我们new出来的对象，它不存在OID,与hibernate       session   无关联，在数据库中也无记录。它使用完成后，会被jvm直接回收掉，它只是用于信息携带。简单说：无OID与数据库中的信息无关联，不在session管理范围内。

2.持久态：在hibernate session管理范围内，它具有持久化标识OID它的特点，在事务未提交前一直是持久态，当它发生改变时，hibernate是可以检测到的。简单说：有OID由session管理，在数据库中有可能有，也有可有没有。

3.托管态：也叫做游离态或离线态，它是指持久态对象失去了与session的关联，托管态对象它存在OID,在数据库中有可能存在，也有可能不存在。对于托管态对象，它发生改变时hibernet不能检测到。


# ---------并发------------------------------------------------------------------------------------------------------

# 1.线程与进程

## 1-1：什么是进程

系统运行一个程序，从创建，运行到消亡的过程这个是一个进程

## 1-2：何为线程?

线程是进程内的一个执行单元

## 1-3：线程与进程的区别

1. 拥有资源
   进程是资源分配的基本单位，虽然线程不拥有资源，线程可以访问隶属进程的资源

2. 调度
   线程是独立调度的基本单位

3. 系统开销
   创建或者撤销进程的开销大于线程的开销

4. 通信方面
   线程间可以通过读写进行通信，进程通信需要PIC

## 1-4：进程的通信方式

1. 管道

管道分为有名管道和无名管道,无名管道数据只能单向流动,而且只能在具有亲缘关系的进程间使用;有名管道也是一种半双工的通信方式,但是它允许无亲缘关系进程间的通信。

2. 信号量

信号量是一个计数器,可以用来控制多个线程对共享资源的访问.它常作为一种锁机制,防止某进程在访问资源时其它进程也访问该资源.因此,主要作为进程间以及同一个进程内不同线程之间的同步手段.

3. 信号

信号是一种比较复杂的通信方式,用于通知接收进程某个事件已经发生.

4. 消息队列

消息队列是消息的链表,存放在内核中并由消息队列标识符标识.消息队列克服了信号传递信息少,管道只能承载无格式字节流以及缓冲区大小受限等特点.

5. 共享内存

共享内存就是映射一段能被其他进程所访问的内存,这段共享内存由一个进程创建,但多个进程都可以访问.

6. 套接字：可用于不同及其间的进程通信

# 2.进程调度

## 2-1：什么时候会发生CPU调度

1. 当进程从运行状态转到等待状态；

2. 当进程从运行状态转到就绪状态；

3. 当进程从等待状态转到就绪状态；

4. 当进程从运行状态转到终止状态；

## 2-2：抢占式与非抢占式

非抢占式的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。

抢占式调度，进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。

抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。

## 2-3：进程调度任务过程

1. 首先保存当前进程的处理机的现场信息

2. 按照算法选取进程

3. 把处理器分配给进程


## 2-4：进程的调度算法

1. 先来先服务调度算法

2. 最短作业优先调度算法

3. 高响应比优先调度算法

4. 时间片轮转调度算法

5. 最高优先级调度算法

6. 多级反馈队列调度算法


1. 非抢占式的先来先服务（First Come First Severd, FCFS）算法

先来后到，每次从就绪队列选择最先进入队列的进程，

然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。

这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。

FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。

2. 最短作业优先（Shortest Job First, SJF）调度算法 
   
     它会优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。

      这显然对长作业不利，很容易造成一种极端现象。

     比如，一个长作业在就绪队列等待运行，
     
     而这个就绪队列有非常多的短作业，
     
     那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。

3. 高响应比优先 （Highest Response Ratio Next, HRRN）调度算法
   
   主要是权衡了短作业和长作业。

   每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，
   
   「响应比优先级」的计算公式：
    
    优先权=（等待时间+要求服务时间）/要求服务时间

    - 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；
    - 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，
      这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，
      当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；

4. 时间片轮转（Round Robin, RR）调度算法。

每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。

如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程；

如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；

另外，时间片的长度就是一个很关键的点：

- 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；
- 如果设得太长又可能引起对短作业进程的响应时间变长；

注：通常时间片设为 20ms~50ms 通常是一个比较合理的折中值。

5. 最高优先级调度算法

希望调度程序能从就绪队列中选择最高优先级的进程进行运行，

进程的优先级可以分为，静态优先级或动态优先级：

- 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
- 动态优先级：根据进程的动态变化调整优先级，
  
  比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，
  
  则升高其优先级，也就是随着时间的推移增加等待进程的优先级。该算法也有两种处理优先级高的方法，非抢占式和抢占式：

非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。

抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。
        但是依然有缺点，可能会导致低优先级的进程永远不会运行。

6. 多级反馈队列（Multilevel Feedback Queue）调度算法

「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。

「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短；

新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，

如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；

当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。

如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，

接着让较高优先级的进程运行；可以发现，对于短作业可能可以在第一级队列很快被处理完。

对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，

虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。

# 3.并发级别

1. 阻塞

一个线程是阻塞的，那么在其他线程释放资源之前，

当前线程无法继续执行。比如：使用synchronize关键字或者其他重入锁，

我们得到的就是阻塞的线程。无论是synchronized或者重入锁，

都会在试图执行后续代码前，得到临界区的锁，如果得不到，线程就会被挂起等待，直到占有了所需资源为止。

2. 无饥饿（Starvation-Free）

如果线程之间是有优先级的，那么线程调度的时候总是会倾向于满足高优先级的线程。

也就是说，对于同一个资源的分配，是不公平的。

锁也分公平锁和非公平锁，对于非公平锁来说，系统允许高优先级的线程插队。

这样就有可能导致低优先级的线程产生饥饿。

但是如果是公平锁，满足先来后到，那么饥饿就不会产生，

不管新来的线程优先级多高，要想获得资源，就必须乖乖排队。

这样所有的线程都有机会执行。

3. 无障碍（Obstruction-Free）

无障碍是一种最弱的非阻塞调度。

两个线程如果是无障碍的执行，那么他们不会因为临界区的问题导致一方被挂起。

换言之，大家都可以大摇大摆的进入临界区了。

那么如果大家一起修改共享区数据，把数据修改坏了怎么办呢？对于无障碍的线程来说，

一旦检测到这种情况，它就会立即对自己所做的修改进行回滚，确保数据安全。

但是如果没有数据竞争发生，那么线程就可以顺利完成自己的工作，走出临界区。

从这个策略可以看出，无障碍的多线程程序不一定能顺畅的运行。

因为当临界区中存在严重的冲突时，所有的线程可能都会不断的回滚自己的操作，

导致没有一个线程能顺利走出临界区。这种情况会影响系统的正常执行。

一种可行的无障碍实现可以依赖一个“一致性标记”来实现：

线程在操作之前，先读取并保存这个标记，在操作完成之后，再次读取，

检查这个标记是否更改过，如果两者是一致的，则说明资源访问没有冲突。

如果不一致，则说明资源可能在操作过程中与其他线程存在冲突，

需要重新操作。而任何对资源有修改操作的线程，在修改数据前，

都需要更新这个一致性的标记，表示数据不再安全。

4. 无锁（Lock-Free）

无锁的并行都是无障碍的。

在无锁的情况下，所有的线程都能尝试对临界区进行访问，

但不同的是，无锁的并发保证必然有一个线程能够在有限步内完成操作走出临界区。

在无锁的调用中，一个典型的特点是可能会包含一个无线循环。

在这个循环中，线程会不断尝试修改共享变量，如果没有冲突，修改成功，那么程序退出。

否则继续尝试修改，但无论如何，无锁的并行总能保证一个线程胜出，不会全军覆没。

至于临界区中竞争失败的线程，它们则必须不断重试，直到自己获胜，

如果运气不好，总是不成功，则会出现饥饿的现象，线程会停止不前。

5. 无等待（Wait-Free）

无锁只要求一个线程可以在有限步数内完成操作，

而无等待则是在无锁的基础上更进一步进行扩展，

它要求所有的线程都必须在有限步数内完成，这样就不会引起线程饥饿问题。

一种典型的无等待结构是RCU（Read-Copy-Update）。

它的基本思想是，对数据的读可以不加控制。

因此，所有的读操作是无等待的，他们既不会被锁定等待也不会引起任何冲突。

但是在写数据的时候，先取得原始数据的副本，

接着只修改副本数据（这就是为什么读可不加控制），修改完成后，在合适的时机回写数据。

# 4.并行与并发

## 4-1：并行与并发概念

1. 并发： 同⼀时间段，多个任务都在执⾏；
2. 并⾏： 单位时间内，多个任务同时执⾏。

## 4-2：并发特性

1. 原子性 : 要么所有的操作都执行，要么都不执行。
2. 可见性 ：当一个变量对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。
3. 有序性 ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，
            代码的执行顺序未必就是编写代码时候的顺序。
            volatile 关键字可以禁止指令进行重排序优化。

# 5.多线程

## 5-1：为什么要使⽤多线程呢?

1. 线程间的切换和调度的成本远远⼩于进程。减少了线程上下⽂切换的开销。

2. 现在的系统动不动就要求百万级甚⾄千万级的并发量，
   ⽽多线程并发编程正是开发⾼并发系统的基础，利⽤好多线程机制可以⼤⼤提⾼系统整体的并发能 ⼒以及性能。

3. 发挥多核 CPU 的优势

4. 防止阻塞

## 5-2：使⽤多线程可能带来什么问题?

并发编程的⽬的就是为了能提⾼程序的执⾏效率提⾼程序运⾏速度，

但是并发编程并不总是能提⾼程序运⾏速度的，⽽且并发编程可能会遇到很多题，

⽐如：内存泄漏、上下⽂切换、死锁还有受限于硬件和软件的资源闲置问题。

## 5-3：多线程公共用一个数据注意什么

1. 当我们在线程对象( Runnable )中定义了全局变量, run方法会修改该变量时,
   如果有多个线程同时使用刻线程对象, 那么就会造成全局变量的值被同时修改,造成错误

2. ThreadLocal是JDK引入的一种机制,它用于解决线程间共享变量,使用ThreadLocal声明的变量，
   即使在线程中属于全局变量,针对每个线程来讲,这个变量也是独立的。

3. volatile变量每次被线程访问时,都强迫线程从主内存中重读该变量的最新值,
   而当该变量发生修改变化时,也会强迫线程将最新的值刷新回主内存中。这样一来 ,不同的线程都能及时的看到该变量的最新值。

## 5-4：如何确保 N 个线程可以访问 N 个资源同时又不导致死锁？

1. 加锁顺序（线程按照一定的顺序加锁）
2. 加锁时限（线程尝试获取锁的时候加上一定的时限， 超过时限则放弃对该锁的请求，并释放自己占有的锁）
3. 死锁检测


## 5-5：单cpu上多线程效率和单线程比如何

单CPU来说（没有开启超线程），在同一时间只能执行一个线程，所以如果想实现多任务，
那么就只能每个进程或线程获得一个时间片，在某个时间片内，只能一个线程执行，
然后按照某种策略换其他线程执行。由于时间片很短，这样给用户的感觉是同时有好多线程在执行。
但是线程切换是有代价的，因此如果采用多进程，
那么就需要将线程所隶属的该进程所需要的内存进行切换，
这时间代价是很多的。而线程切换代价就很少，线程是可以共享内存的。
所以采用多线程在切换上花费的比多进程少得多。

# 6.线程的基本操作

## 6-1：线程的生命周期和状态

运行状态（Runing）：该时刻进程占用 CPU；

就绪状态（Ready）：可运行，但因为其他进程正在运行而暂停停止；

阻塞状态（Blocked）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）
                    而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；

创建状态（new）：进程正在被创建时的状态；

结束状态（Exit）：进程正在从系统中消失时的状态；

----------------------------------------------------------------------------------------------------------------------------------

NULL -> 创建状态：一个新进程被创建时的第一个状态；

创建状态 -> 就绪状态：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的；

就绪态 -> 运行状态：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程；

运行状态 -> 结束状态：当进程已经运行完成或出错时，会被操作系统作结束状态处理；

运行状态 -> 就绪状态：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，
            操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行；

运行状态 -> 阻塞状态：当进程请求某个事件且必须等待时，例如请求 I/O 事件；

阻塞状态 -> 就绪状态：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；


## 6-2：说说 sleep() ⽅法和 wait() ⽅法区别和共同点?

1. sleep ⽅法没有释放锁，⽽ wait ⽅法释放了锁 。
2. 两者都可以暂停线程的执⾏。
3. Wait 通常被⽤于线程间交互/通信， sleep 通常被⽤于暂停执⾏。
4. wait() ⽅法被调⽤后，线程不会⾃动苏醒，
   需要别的线程调⽤同⼀个对象上的 notify() 或notifyAll() ⽅法。 
   sleep() ⽅法执⾏完成后，线程会⾃动苏醒。或者可以使⽤ wait(longtimeout)超时后线程会⾃动苏醒。

## 6-3：yield join notify notifyAll

1. yield()方法是停止当前线程， 让同等优先权的线程或更高优先级的线程有执行的机会。
   如果没有的话， 那么 yield()方法将不会起作用， 并且由可执行状态后马上又被执行。

2. join 方法是用于在某一个线程的执行过程中调用另一个线程执行， 
   等到被调用的线程执行结束后， 再继续执行当前线程。 
   如： t.join();//主要用于等待 t 线程运行结束， 若无此句，main 则会执行完毕， 导致结果不可预测。

3. notify 方法只唤醒一个等待（对象的） 
   线程并使该线程开始执行。 所以如果有多个线程等待一个对象， 
   这个方法只会唤醒其中一个线程， 选择哪个线程取决于操作系统对多线程管理的实现。

4. notifyAll 会唤醒所有等待(对象的)线程， 尽管哪一个线程将会第一个处理取决于操作系统的实现


## 6-4：为什么我们调⽤ start() ⽅法时会执⾏ run() ⽅法，为什么我们不能直接调⽤run() ⽅法？

new ⼀个 Thread，线程进⼊了新建状态;调⽤ start() ⽅法，
会启动⼀个线程并使线程进⼊了就绪状态，当分���到时间⽚后就可以开始运⾏了。 
start() 会执⾏线程的相应准备⼯作，然后⾃动执⾏run() ⽅法的内容，
这是真正的多线程⼯作。 ⽽直接执⾏ run() ⽅法，
会把 run ⽅法当成⼀个 main线程下的普通⽅法去执⾏，
并不会在某个线程中执⾏它，所以这并不是多线程⼯作。

## 6-5：中断线程方法 

1. 使用退出标志， 使线程正常退出， 也就是当 run 方法完成后线程终止。 

2. 通过 return 退出 run 方法

3. 通过对有些状态中断抛异常退出thread.interrupt() 中断。 

4. 使用 stop 方法强行终止线程（过期）

## 6-6：一般线程和守护线程以及两者区别

所谓守护线程是指在程序运行的时候在后台提供一种通用服务的线程， 
比如垃圾回收线程就是一个很称职的守护者， 并且这种线程并不属于程序中不可或缺的部分。 
因 此，当所有的非守护线程结束时， 程序也就终止了， 
同时会杀死进程中的所有守护线程。 
反过来说， 只要任何非守护线程还在运行， 程序就不会终止。

区别：
为守护线程是 JVM 自动创建的线程， 用户线程是程序创建的线程； 
比如 JVM的垃圾回收线程是一个守护线程， 
当所有线程已经撤离， 不再产生垃圾， 守护线程自然就没事可干了， 
当垃圾回收线程是 Java 虚拟机上仅剩的线程时， Java 虚拟机会自动离开。

# 7.创建线程

## 7-1：创建线程的方式

1. 继承 Thread类创建线程
  
  1）定义Thread类的子类，并重写该类的run方法，代表了线程要完成的任务
  
  2）创建了线程对象。
  
  3）调用线程对象的start()方法来启动该线程

2. 实现Runnable接口创建线程

1）定义runnable接口的实现类，并重写该接口的run()方法，该run()方法的方法体同样是该线程的线程执行体。

2）创建 Runnable实现类的实例，并以此实例作为Thread的 target来创建Thread对象，该Thread对象才是真正的线程对象。

3）调用线程对象的start()方法来启动该线程。

3. 使用Callable和Future创建线程，

1）创建Callable接口的实现类，并实现call方法，call方法作为线程执行体

2）创建Callable实现类的实例，使用FutureTask类来包装Callable对象，
   
   该FutureTask对象封装了该Callable对象的call（）方法的返回值
   FutureTask是一个包装器，它通过接受Callable来创建，它同时实现了Future和Runnable接口

3）使用FutureTask对象                                                                                                                

   作为Thread对象的target创建并启动新线程。

4）调用FutureTask对象的get方法获得子线程执行结束后的返回值

4. 使用线程池

比如说用Executor框架


## 7-2：创建线程的对比

创建线程的方式的对比

1)采用实现Runnable、Callable接口的方式创建多线程时，线程类只是实现了Runnable接口或Callable接口，还可以继承其他类。
  
  在这种方式下，多个线程可以共享同一个 target对象，
  所以非常适合多个相同线程来处理同一份资源的情况，从而可以将CPU、代码和数据分开。
  但是，缺点是编程稍微复杂，如果要访问当前线程，则必须使用 Thread.currentThread)方法。

2）使用继承Thread类的方式创建多线程时，

   如果需要访问当前线程，则无需使用Thread.currentThread()方法，直接使用this即可获得当前线程。
   缺点是线程类已经继承了Thread类，所以不能再继承其他父类。

3）Runnable和Callable的区别
  
  1) Callable规定（重写）的方法是call()，Runnable规定（重写）的方法是run()。
  
  2) Callable的任务执行后可返回值，而Runnable的任务是不能返回值的。
  
  3)call方法可以抛出异常，run方法不可以。
  
  4)运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的方法，并检索计算的结果。
  
    通过Future对象可以了解任务执行情况，可取准任务的执行，还可获取执行结果。


## 7-3：实现Runnable接⼝和Callable接⼝的区别

Runnable ⾃Java 1.0以来⼀直存在，但 Callable 仅在Java 1.5中引⼊,⽬的就是为了来处理 Runnable
不⽀持的⽤例。 Runnable 接⼝不会返回结果或抛出检查异常，但是 Callable 接⼝可以。所以，如果
任务不需要返回结果或抛出异常推荐使⽤ Runnable 接⼝，这样代码看起来会更加简洁。

## 7-4：实现 Runnable 接口比继承 Thread 类所具有的优势
1. 适合多个相同的程序代码的线程去处理同一个资源 

2. 可以避免 java 中的单继承的限制 

3. 增加程序的健壮性， 代码可以被多个线程共享， 代码和数据独立

4. 线程池只能放入实现 Runable 或 callable 类线程， 不能直接放入继承 Thread 的类 

5. runnable 实现线程可以对线程进行复用， 因为 runnable 是轻量级的对象， 
   重复 new 不会耗费太大资源， 而 Thread 则不然， 它是重量级对象， 而且线程执行完就完了， 无法再次利用

## 7-5：run()方法和start()方法的区别

线程的run()方法是由java虚拟机直接调用的，

如果我们没有启动线程（没有调用线程的start()方法）而是在应用代码中直接调用run()方法，

那么这个线程的run()方法其实运行在当前线程（即run()方法的调用方所在的线程）之中，

而不是运行在其自身的线程中，从而违背了创建线程的初衷；


# 8.线程安全

1. synchronized关键字
2. volatile实现同步

 　　1）使用volatile关键字会强制将修改的缓存值立即写入主存。

　　 2）使用volatile关键字，当线程2进行修改时，会导致线程1的工作内存中变量缓存无效，
        然后线程1读取时发现自己的缓存无效他会等待缓存行对应的主存地址被更新之后，
        然后去主存读取最新信息。

　　 3）禁止指令重排序

　　　　　　（1）当程序执行到volatile变量的读操作或者写操作时，
                其前面的操作的更改肯定全部已经进行，
                且结果已经对后面的操作可见，在其后面的操作还没有进行。

　　　　　　（2）在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，
                也不能把volatile变量后面的语句放在其前面执行。

3. ThreadLocal管理变量
   
   ThreadLocal的作用是提供线程内的局部变量，
   这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。

4. 原子类

  原子类是基本类的原子化版本，通过线程安全的方式操作，等同于自动加synchronized

5. 使用Lock，读写锁

   lock更灵活，可以自由定义多把锁的枷锁解锁顺序（synchronized要按照先加的后解顺序）
   提供多种加锁方案，lock 阻塞式, trylock 无阻塞式, lockInterruptily 可打断式， 还有trylock的带超时时间版本。
   本质上和监视器锁（即synchronized）是一样的

6. 容器类（BlockingQueue、ConcurrentHashMap）
   

# 9.线程同步

1. 互斥量(Mutex)：采用互斥对象机制，
   
   只有拥有互斥对象的线程才有访问公共资源的权限。
   因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。
   比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。

2. 信号量(Semphares) ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量

3. 事件(Event) :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操

# 10.synchronized关键字

## 10-1：synchronized关键字理解

1. 解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的⽅法或者代码块在任意时刻只能有⼀个线程执⾏。

2. 在Java早期版本中， synchronized属于重量级锁，效率低下，
   
   因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的， 
   Java 的线程是映射到操作系统的原⽣线程之上的。
   如果要挂起或者唤醒⼀个线程，都需要操作系统帮忙完成，
   ⽽操作系统实现线程之间的切换时需要从⽤户态转换到内核态，
   这个状态之间的转换需要相对⽐较⻓的时间，时间成本相对较⾼，
   但是在JDK1.6对锁的实现引⼊了⼤量的优化，
   如⾃旋锁、适应性⾃旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。

## 10-2：JDK1.6优化有哪些？

JDK1.6 对锁的实现引⼊了⼤量的优化，如偏向锁、轻量级锁、⾃旋锁、适应性⾃旋锁、锁消除、锁粗化等技术来减少锁操作的开销。

1. 偏向锁

引入偏向锁的目是为了没有多线程竞争的前提下，
减少传统的重量级锁使用操作系统互斥量产生的性能消耗。
但是不同是：轻量级锁在无竞争的情况下使用 CAS 操作去代替
使用互斥量。而偏向锁在无竞争的情况下会把整个同步都消除掉。

2. 轻量级锁

轻量级锁不是为了代替重量级锁，它的本意是在没有多线程竞争的前提下，
减少传统的重量级锁使用操作系统互斥量产生的性能消耗，因为使用轻量级锁时，不需要申请互斥量。

如果没有竞争，轻量级锁使用CAS操作避免了使用互斥操作的开销。但如果存在锁竞争，
除了互斥量开销外，还会额外发生CAS操作，因此在有锁竞争的情况下，轻量级锁比传统的重量级锁更慢！
如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁！

3. 自旋锁和自适应自旋

一般线程持有锁的时间都不是太长，所以仅仅为了这一点时间去挂起线程/恢复线程是得不偿失的。
为了让一个线程等待，我们只需要让线程执行一个忙循环（自旋）也就是自旋。

另外,在 JDK1.6 中引入了自适应的自旋锁。自适应的自旋锁带来的改进就是：
自旋的时间不在固定了，而是和前一次同一个锁上的自旋时间以及锁的拥有者的状态来决定。

4. 锁消除

就是把锁干掉。当Java虚拟机运行时发现有些共享数据不会被线程竞争时就可以进行锁消除。

5. 锁粗化

如果一系列的连续操作都对同一个对象反复加锁和解锁，
甚至加锁操作都是出现在循环体体之中，就算真的没有线程竞争，
频繁地进行互斥同步操作将会导致不必要的性能
损耗，所以就采取了一种方案：把加锁的范围扩展（粗化）到整个操作序列的外部，
这样加锁解锁的频率就会大大降低，从而减少了性能损耗。
   
## 10-3：底层原理

每个对象都有个 monitor 对象， 加锁就是在竞争 monitor 对象，
代码块加锁是在代码块前后分别加上 monitorenter 和 monitorexit 指令来实现的，
方法加锁是通过一个标记位来判断的。

## 10-4：synchronized的优势

1. 只需要基础的同步功能时，用synchronized。

2. Lock应该确保在finally块中释放锁。如果使用synchronized，JVM确保即使出现异常，锁也能被自动释放。

3. 使用Lock时，Java虚拟机很难得知哪些锁对象是由特定线程锁持有的。

## 10-5：synchronized锁的膨胀过程（升级过程）

1. 整个膨胀过程在自旋下完成；

2. mark->has_monitor()方法判断当前是否为重量级锁，
   即Mark Word的锁标识位为 10，如果当前状态为重量级锁，执行步骤（3），否则执行步骤（4）；

3. mark->monitor()方法获取指向ObjectMonitor的指针，并返回，说明膨胀过程已经完成；

4. 如果当前锁处于膨胀中，说明该锁正在被其它线程执行膨胀操作，
   则当前线程就进行自旋等待锁膨胀完成，这里需要注意一点，
   虽然是自旋操作，但不会一直占用cpu资源，
   每隔一段时间会通过os::NakedYield方法放弃cpu资源，
   或通过park方法挂起；如果其他线程完成锁的膨胀操作，则退出自旋并返回；

5. 如果当前是轻量级锁状态，即锁标识位为 00，膨胀过程如下：

    通过omAlloc方法，获取一个可用的ObjectMonitor monitor，并重置monitor数据；
    通过CAS尝试将Mark Word设置为markOopDesc:INFLATING，标识当前锁正在膨胀中，
    如果CAS失败，说明同一时刻其它线程已经将Mark Word设置为
    markOopDesc:INFLATING，当前线程进行自旋等待膨胀完成；
    如果CAS成功，设置monitor的各个字段：_header、_owner和_object等，并返回；

6. 如果是无锁，重置监视器值；


## 10-6：那如何判断共享数据不会被线程竞争？

利用逃逸分析技术：分析对象的作用域，如果对象在A方法中定义后，被作为参数传递到B方法中，

则称为方法逃逸；如果被其他线程访问，则称为线程逃逸。

在堆上的某个数据不会逃逸出去被其他线程访问到，

就可以把它当作栈上数据对待，认为它是线程私有的，同步加锁就不需要了。


# 11.synchronized与其他的区别

## 11-1：谈谈 synchronized和ReentrantLock 的区别

1. 两者都是可重入锁

自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，
此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的。

2. synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API

3. ReentrantLock提供了一种能够中断等待锁的线程的机制，
   通过lock.lockInterruptibly()来实现这个机制。
   也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。

4. ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。
   ReentrantLock默认情况是非公平的，
   可以通过 ReentrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。

5. synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类借助于
   Condition接口与newCondition() 方法。 在使用notify()/notifyAll()方法进行通知时，
   被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” ，

## 11-2：Lock和synchronized的区别

1. Lock需要手动获取锁和释放锁。

2. Lock 是一个接口，而 synchronized 是 Java 中的关键字， synchronized 是内置的语言实现。

3. synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；
   而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁，则很可能造成死锁现象，
   因此使用 Lock 时需要在 finally 块中释放锁。

4. Lock 可以让等待锁的线程响应中断，而 synchronized 却不行，使用 synchronized 时，
   等待的线程会一直等待下去，不能够响应中断。

5. 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。

6. Lock 可以通过实现读写锁提高多个线程进行读操作的效率。

# 12.volatile关键字

## 12-1：为什么要是用volatile关键字

目前的 Java 内存模型下，线程可以把变量保存本地内存（比如机器的寄存器）中，

而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，

而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。

要解决这个问题，就需要把变量声明为volatile，这就指示JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。

volatile 关键字的主要作用就是保证变量的可见性然后还有一个作用是防止指令重排序。

## 12-2：为什么其他线程能感知到变量更新

当多个CPU持有的缓存都来自同一个主内存的拷贝，当有其他CPU偷偷改了这个主内存数据后，

其他CPU并不知道，那拷贝的内存将会和主内存不一致，

那我们为了保证缓存一致，这里就需要操作系统来共同制定一个同步规则来保证，

而这个规则就有MESI协议。

当CPU写数据时，如果发现操作的变量是共享变量，即在其它CPU中也存在该变量的副本，

系统会发出信号通知其它CPU将该内存变量的缓存行设置为无效。

当其它CPU读取这个变量的时，发现自己缓存该变量的缓存行是无效的，那么它就会从内存中重新读取。

为了让其他CPU是怎么知道要将缓存更新为失效的，这里是用到了总线嗅探技术。

每个CPU不断嗅探总线上传播的数据来检查自己缓存值是否过期了，

如果处理器发现自己的缓存行对应的内存地址被修改，

就会将当前处理器的缓存行设置为无效状态，

当处理器对这个数据进行修改操作的时候，

会重新从内存中把数据读取到处理器缓存中。

## 12-3：volatile为什么不保证原子性吗？

比如说，当20个线程同时给number自增1，执行1000次以后，单线程情况下，肯定是20000，但是在多线程情况下，执行了某个指令number的值取到操作栈顶时，volatile关
键字保证了number的值在此时是正确的，但是在执行压栈等指令的时候，其他线程可能已经把number的值改变了，而操作栈顶的值就变成了过期的数据，就可能把较小的
number值同步回主内存之中。

## 12-4：怎么保证输出结果是20000呢？

1. synchronized同步代码块

我们可以通过使用synchronized同步代码块来保证原子性。

但是使用synchronized太重了，会造成阻塞，只有一个线程能进入到这个方法。

我们可以使用Java并发包（JUC）中的AtomicInterger工具包。

2. AtomicInterger原子性操作

两个线程，线程1和线程2都有主内存中变量的拷贝，值都等于10

线程1想要将值更新为20，先要将工作内存中的变量值与主内存中的变量进行比较，值都等于10，所以可以将主内存中的值替换成20

线程1将主内存中的值替换成20，并将线程1中的工作内存中的副本更新为20

线程2想要将变量更新为30，先要将线程2的工作内存中的值与主内存进行比较10不等于20，所以不能更新

线程2将工作内存的副本更新为与主内存一致：20

## 12-5：为什么要重排

计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。

## 12-6： 有哪几种重排

1. 编译器优化重排：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。

2. 指令级的并行重排：现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，
                     处理器可以改变语句对应机器指令的执行顺序。

3. 内存系统的重排：由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

## 12-7：举例说一下指令重排

定义了变量num=0和变量flag=false，线程1调用初始化函数init()执行后，线程调用add()方法，
当另外线程判断flag=true后，执行num+100操作，那么我们预期的结果是num会等于101，
但因为有指令重排的可能，num=1和flag=true执行顺序可能会颠倒，以至于num可能等于100

## 12-8： volatile怎么实现禁止指令重排？

在volatile生成的指令序列前后插入内存屏障来禁止处理器重排序。

volatile写的场景

在每个volatile写操作的前面插入一个StoreStore屏障（写-写 屏障）。

在每个volatile写操作的后面插入一个StoreLoad屏障（写-读 屏障）。

volatile读场景

在每个volatile读操作的后面插入一个LoadLoad屏障（读-读 屏障）。

在每个volatile读操作的后面插入一个LoadStore屏障（读-写 屏障）。

## 12-9：happen-before原则是什么

定义了哪些指令不能重排。
八大原则:
1. 单线程happen-before原则:在同一个线程中，书写在前面的操作happen-before后面的操作。
2. 锁的happen-before原则:同一个锁的unlock操作happen-before此锁的lock操作。
3. volatile的happen-before原则:对一个volatile变量的写操作happen-before对此变量的任意操作(当然也包
   括写操作了)。
4. happen-before的传递性原则:如果A操作happen-before B 操作，B操作 happen-before C操作，那么A操作
   happen-beforeC操作。
5. 线程启动的happen-before原则:同一个线程的start方法 happen-before此线程的其它方法。
6. 线程中断的happen-before原则:对线程interrupt方法的调用happen-before被中断线程的检测到中断发送的
   代码。
7. 线程终结的happen-before原则:线程中的所有操作都 happen-before线程的终止检测。
8. 对象创建的happen-before原则:一个对象的初始化完成先于他的finalize方法调用。


## 12-10：volatile都不保证原子性，为啥我们还要用它？

1. volatile是轻量级的同步机制，对性能的影响比synchronized小。

  * 比如线程试图通过类似于数绵羊的传统方法进入休眠状态，为了使这个示例能正确执行，
    sleep必须为volatile变量。否则，当asleep被另一个线程修改时，执行判断的线程却发现不了。

2. 因为synchorized和lock是排他锁（悲观锁），如果有多个线程需要访问这个变量，
   将会发生竞争，只有一个线程可以访问这个变量，其他线程被阻塞了，会影响程序的性能。


## 12-11：synchronized 关键字和 volatile 关键字的区别

1. volatile关键字是线程同步的轻量级实现，但是volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块。
   synchronized关键字在1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的
   偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，实际开发中使用 synchronized 关键字的场景还是更多一些。

2. 多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞

3. volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。

4. volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。

# 13.线程池

## 13-1：使⽤线程池的好处

1. 降低资源消耗。通过重复利⽤已创建的线程降低线程创建和销毁造成的消耗。
2. 提⾼响应速度。当任务到达时，任务可以不需要的等到线程创建就能⽴即执⾏。
3. 提⾼线程的可管理性。线程是稀缺资源，如果⽆限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使⽤线
   程池可以进⾏统⼀的分配，调优和监控。

## 13-2：常规实现线程池方法

（1） newFixedThreadPool定长线程池

它是一种固定大小的线程池;corePoolSize和maximunPoolSize都为用户设定的线程数量nThreads:
keepAliveTime为0，意味着一旦有多余的空闲线程，就会被立即停止掉;但这里keepAliveTime无效;
阻塞队列采用了LinkedBlockingQueue，它是一个无界队列;由于阻塞队列是一个无界队列，

因此永远不可能拒绝任务;由于采用了无界队列，实际线程数量将永远维持在 nThreads，

因此 maximumPoolSize和keepAliveTime将无效。

(2） newCachedThreadPool可缓存

它是一个可以无限扩大的线程池;它比较适合处理执行时间比较小的任务;corePoolSize为O，

maximumPoolSize为无限大，意味着线程数量可以无限大;

keepAliveTime为 60S，意味着线程空闲时间超过 60S就会被杀死;采用SynchronousOueue装等待的任务，

这个阻塞队列没有存储空间，这意味着只要有请求到来，就必须要找到一条工作线程处理他，

如果当前没有空闲的线程，那么就会再创建一条新的线程。

(3） newSingleThreadExecutor单一线程池它只会创建一条工作线程处理任务;采用的阻塞队列为LinkedBlockingQueue

(4）ScheduledThreadPool可调度的线程池实现周期性线程调度，比较常用。

# 14.线程池几种策略

## 14-1：线程池增长策略

当一个任务通过execute(Runnable)方法欲添加到线程池时:
1、如果此时线程池中的数量小于corePoolSize，即使线程池中的线程都处于空闲状态，也要创建新的线程来处 
   理被添加的任务。
2、如果此时线程池中的数量等于corePoolSize，但是缓冲队列workQueue未满，那么任务被放入缓冲队列。
3、如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量小于
    maximumPoolSize，建新的线程来处理被添加的任务。
4、如果此时线程池中的数量大于corePoolSize，缓冲队列workQueue满，并且线程池中的数量等于     
   maximumPoolSize，那么通过handler所指定的策略来处理此任务。也就是:处理任务的优先级为:核心线程
   corePooSize、最大线程maximumPoolSize、任务队列workQueue
   如果三者都满了，使用handler处理被拒绝的任务。当线程池中的线程数大于corePooSize，如果某线程空闲
   时间超过keepAliveTime，线程将被终止。这样，线程池可以动态的调整池中的线程数。且体增长策略要看你
   使用什么workQueue。

## 14-2：线程池的核心线程数和最大线程数

核心线程数就像是本身所具有的，最大线程数，就是工厂临时工作量加大，

临时进行了申请，临时加正式的和就是最大线程数，

等这批任务结束后，临时的要辞退的，而正式的留下。

## 14-3：线程池拒绝策略

1、AbortPolicy:这种策略直接抛出异常，丢弃任务（当都满了）
2、CallerRunsPolicy:策略显然个想放弁执行任务。但是由于池中已经没有任何资源了，那么就直接使用调用该
                    execute 的线程本身来执行。很有可能造成当前线程也被阻塞。
3、DiscardPolicy:不能执行的任务将被删除，这种策略和AbortPolicy几乎一样，也是丢弃任务，只不过他不
                  抛出异常。
4、DiscardOldestPolicy:如果执行程序尚未关闭，则位于工作队列头部的任务将被删除，然后重试执行程序
                      （如果再次失败，则重复此过程）


# 15.线程池流程

## 15-1：新的任务提交到线程池，线程池是怎样处理

第一步 ：线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的工作线程来执行任务。

        如果核心线程池里的线程都在执行任务，则执行第二步。

第二步 ：线程池判断工作队列是否已经满。如果工作队列没有满，则将新提交的任务存储在这个工作队列里进行等待。
         
         如果工作队列满了，则执行第三步。

第三步 ：线程池判断线程池的线程是否都处于工作状态。如果没有，则创建一个新的工作线程来执行任务。
        
        如果已经满了，则交给饱和策略来处理这个任务。

即任务处理优先级：核心线程池的线程 > 工作队列 > 线程池的线程 > 饱和策略

# 16.线程池参数

## 16-1：线程池参数

一、corePoolSize 核心线程大小

线程池中最小的线程数量，即使处理空闲状态，也不会被销毁，除非设置了allowCoreThreadTimeOut。

CPU密集型：核心线程数 = CPU核数 + 1
IO密集型：核心线程数 = CPU核数 * 2+1
注：IO密集型（某大厂实践经验）
核心线程数 = CPU核数 / （1-阻塞系数）
例如阻塞系数 0.8，CPU核数为4，则核心线程数为20

二、maximumPoolSize 线程池最大线程数量
一个任务被提交后，首先会被缓存到工作队列中，等工作队列满了，则会创建一个新线程，处理从工作队列中的取出一个任务。

三、keepAliveTime 空闲线程存活时间
当线程数量大于corePoolSize时，一个处于空闲状态的线程，在指定的时间后会被销毁。

四、unit 空间线程存活时间单位
keepAliveTime的计量单位

五、workQueue 工作队列，jdk中提供了四种工作队列
新任务被提交后，会先进入到此工作队列中，任务调度时再从队列中取出任务。
①ArrayBlockingQueue
基于数组的有界阻塞队列，按FIFO排序。
②LinkedBlockingQuene
基于链表的无界阻塞队列（其实最大容量为Interger.MAX），按照FIFO排序。
④PriorityBlockingQueue
具有优先级的无界阻塞队列，优先级通过参数Comparator实现。

六、threadFactory 线程工厂
创建一个新线程时使用的工厂，可以用来设定线程名、是否为daemon线程等等
七、handler 拒绝策略
当工作队列中的任务已满并且线程池中的线程数量也达到最大，这时如果有新任务提交进来，拒绝策略就是解决这个问题的，

jdk中提供了4中拒绝策略：

①CallerRunsPolicy
该策略下，在调用者线程中直接执行被拒绝任务的run方法，除非线程池已经shutdown，则直接抛弃任务。
②AbortPolicy
该策略下，直接丢弃任务，并抛出RejectedExecutionException异常。
③DiscardPolicy
该策略下，直接丢弃任务，什么都不做。
④DiscardOldestPolicy
该策略下，抛弃最早进入队列的那个任务，然后尝试把这次拒绝的任务放入队列。

## 16-2：如何设置线程池参数。线程池调优怎么调优。


# 17.设计线程池

## 17-1：单一线程池中线程死亡该怎么办

每个线程都有个计时器，发现线程卡死直接杀死掉，

最好是及时移除超时任务，重启线程池

## 17-2：如何防止线程池线程死掉

比较简单的就是利用线程池，线程死掉后，会自动再创建线程。
如果是主线程的话，就用一个监视线程来管理，如果主线程死掉，通知监视线程，监视线程再创建一个线程。如果监视线程死掉，那就彻底挂了。
心跳机制，线程每隔一段时间往另一服务器进程发送数据包，如果服务器进程长时间没有收到心跳包，则说明当前线程已经死机！

## 17-3：如何设计一个线程池

1.创建线程

```java
 1     //先检查参数正确性
 2     if(ThreadNUM_MIN < 0 || ThreadNUM_MAX < ThreadNUM_MIN)
 3         return false;
 4     //创建信号量(在创建线程前创建信号量，防止线程空转)
 5     m_hSemphore = CreateSemaphore(NULL,0,ThreadNUM_MAX,0);
 6     //创建指定个数线程
 7     for(int i = 0;i < ThreadNUM_MIN;i++)
 8     {
 9         HANDLE handle = (HANDLE)_beginthreadex(NULL,0,&ThreadFunction,this,0,0);
10         if(handle)
11         {
12             m_lHandle.push_back(handle);
13         }
14     }
15     return true;
```

首先是，在这里创建线程我使用的是_beginthreadex（安全属性，线程栈大小，线程函数地址，线程函数参数，线程初始态，线程标识符）,而不是用CreateThread()，这是因为如果在代码中有使用标准C运行库中的函数时，尽量使用_beginthreadex()来代替CreateThread()（这个函数解决的应该是一个历史遗留问题，标准C运行库在1970年被实现了，由于当时没任何一个操作系统提供对多线程的支持。因此编写标准C运行库的程序员根本没考虑多线程程序使用标准C运行库的情况）比如标准C运行库的全局变量errno。很多运行库中的函数在出错时会将错误代号赋值给这个全局变量，这样可以方便调试。但如果有这样的一个代码片段：

1 if (system("notepad.exe readme.txt") == -1)
2 {
3     switch(errno)
4     {
5         ...//错误处理代码
6     }
假设某个线程A在执行上面的代码，该线程在调用system()之后且尚未调用switch()语句时另外一个线程B启动了，这个线程B也调用了标准C运行库的函数，不幸的是这个函数执行出错了并将错误代号写入全局变量errno中。这样线程A一旦开始执行switch()语句时，它将访问一个被B线程改动了的errno。这种情况必须要加以避免！因为不单单是这一个变量会出问题，其它像strerror()、strtok()、tmpnam()、gmtime()、asctime()等函数也会遇到这种由多个线程访问修改导致的数据覆盖问题，通过查看源码可知，_beginthreadex()是先创建了一个内存块，再调用CreateThread()，这个内存块中用来存放一些需要线程独享的数据。事实上新线程运行时会首先将内存块与自己进一步关联起来。然后新线程调用标准C运行库函数如strtok()时就会先取得内存块的地址再将需要保护的数据存入内存块中。这样每个线程就只会访问和修改自己的数据而不会去篡改其它线程的数据了。

　　 第二点，在设计线程睡眠状态时，有很多种方法 挂起（恢复指定线程）,阻塞中有关键段/临界区（无安全属性，不适用），事件（无法唤醒指定线程，不适用），互斥量(同事件)，所以我选择的是信号量用来阻塞线程和恢复线程，因为就如同停车场一样，我只是开放了车位，至于哪辆车（线程）停进来由系统随机分配。

 
2.销毁线程


 1     m_bFlagExit = false;
 2     list<HANDLE>::iterator ite = m_lHandle.begin();
 4     while(ite != m_lHandle.end())
 5     {
 6         if(WaitForSingleObject(*ite,100) == WAIT_TIMEOUT)
 7             TerminateThread(*ite,-1);
 8         CloseHandle(*ite);
 9         *ite = 0;
10         ite++;
11     }
12     m_lHandle.clear();14     CloseHandle(m_hSemphore);
15     m_hSemphore = 0;

能自然退出就自然退出，若遇到线程无法关闭的情况，即（等待线程中内核对象的信号量100ms内为无信号时），强制退出

3.线程函数


    CMyThreadPool *pThis = (CMyThreadPool *)lpvoid;
    CItask *pItask = NULL;
    while(pThis->m_bFlagExit)
    {       
        if(!pThis->m_qItask.empty())                                       
        {
            pItask = pThis->m_qItask.front();
            pThis->m_qItask.pop();

            pItask->RunTask();
            delete pItask;
            pItask = NULL;
        }

    }

    return 0;

目的很简单，在无退出标记的情况下，从队列中取出一个任务，来一个线程去执行

4.投递任务

    if(itask == NULL)
        return false;
    m_qItask.push(itask);
    //释放一个信号量
    ReleaseSemaphore(m_hSemphore,1,0);
将一个任务投入队列中，并且释放一个信号量

5.代码优化

1》在重写任务类后，尝试创建了两个线程去执行 从1加到10000000000的任务，不出意外的崩了，原因是 队列迭代器失效，在经过一顿查阅后发现，是因为在C++中STL不支持线程安全，队列的push和pop同时进行会崩掉，一般说来，STL对于多线程的支持仅限于下列两点：(Effective STL中有描述)

1.多个读取者是安全的。即多个线程可以同时读取一个容器中的内容。 即此时多个线程调用 容器的不涉及到写的接口都可以 eg find, begin, end 等.

2.对不同容器的多个写入者是安全的。即多个线程对不同容器的同时写入合法。 但是对于同一容器当有线程写,有线程读时,如何保证正确? 需要程序员自己来控制，比如：线程A读容器某一项时，线程B正在移除该项。这会导致一下无法预知的错误。 通常的解决方式是用开销较小的临界区（CRITICAL_SECTION）来做同步。以下列方式同步基本上可以做到线程安全的容器(就是在有写操作的情况下仍能保证安全)。

但是在查阅后，我打算利用一个bool变量去标记队列中任务是否已经pop，来决定是否去push，还是崩了，原来多根线程也不允许同时push也不符合线程安全，那么将push加入互斥量解决了这个问题。

2》但是作为CPU来说，线程池是由任务的个数来创建线程数，这样才能最大利用的使用资源，这就像在餐馆里吃饭一样，CPU是老板，饭店里最多有5个服务员（实现创建的线程最大数），在店的有2个（创建的线程数），此时来了一个客人（任务），此时放走一个服务员去执行即可（释放信号量），此时来了4个客人，我把不在店的2个服务员给叫回来，此时来了10个客人，饭店里5个服务员都已经用完了，那么剩下5个就只能排队等待了，人数（任务）少时，服务员（线程）少，老板（CPU）就可以减少开支（资源分配）。那么这种方法作为代码就可以这样实现。

复制代码
 1 //1.是否有空闲线程
 2     if(m_lRunThreadNum < m_lCreateThreadNum) 
 3     {
 4         //释放一个信号量
 5         ReleaseSemaphore(m_hSemphore,1,0);
 6     }
 7     //2.是否达到上限
 8     else if(m_lCreateThreadNum < m_lMaxThreadNum) 
 9     {
10         //创建线程 并且释放一个信号量
11         HANDLE handle = (HANDLE)_beginthreadex(NULL,0,&ThreadFunction,this,0,0);
12         if(handle)
13         {
14             m_lHandle.push_back(handle);
15         }
16         m_lCreateThreadNum++;
17         ReleaseSemaphore(m_hSemphore,1,0);
18     }
19     //3.已达到上限 任务等待
复制代码
3》在线程函数里，多个线程去执行任务时，难免会出现线程并发的情况，解决线程并发最常见的莫过于线程同步，也就是上锁，我列举一下常见的几种方式（如果有列举不当的，欢迎指出）：



 

 原子访问：同一时刻只允许一个线程访问资源，具体运用就是Interlocked...一系列函数，但是锁定范围小，一般就是一个变量，我认为它运用的主要核心就是Volatile关键字，因为CPU运算速度过快，需要一个Cache缓存来进行数据交换，而对于多线程来说，数据更改必须从内存中取用，而不是Cache，防止读内存不同步，比如变量a已经减1了，但此时两个线程中有一个线程读取的还是a，而不是内存中的a-1，这个关键字的作用就是防止编译优化，并且对于特殊地址的稳定访问。
关键段：同一个时刻只允许一个线程访问资源，举一个不雅观的例子，一群人上厕所，一个人进去后，将外面的牌子置为使用中，外面就有一群人在等待，当厕所里的人出来后，再将牌子置为未使用，在有一个人进入，这样就控制每一只有一个人（线程）,上厕所（访问资源）了，而根据外面人等待时间的长短分为等不到就直接坐下来（其余线程直接阻塞）,站着等一段时间，里面人出来了就直接进去，时间到了，里面人还没出来就直接阻塞（其余线程使用旋转锁），还有一种就是冲进来直接推门，能推开就进去，推不开就找另一个厕所（进程）(其余线程异步处理)
互斥量,事件和信号量：这三种都是内核对象，使用时很安全，并且作用范围广，可以跨进程进行通信，并且通过waitforsingleobject（）等待信号的时间长短，都能实现关键段中三个方法，唯一的缺点就是相对于关键段来说执行效率慢，关键段是用户态下的方法，不需要状态转换
根据这几种方法，针对线程函数又加了一些锁

复制代码
 1 CMyThreadPool *pThis = (CMyThreadPool *)lpvoid;
 2     CItask *pItask = NULL;
 3     while(pThis->m_bFlagExit)
 4     {
 5         //等待信号量
 6         if(WaitForSingleObject(pThis->m_hSemphore,100) == WAIT_TIMEOUT)        //为了能让卡死进程能够退出
 7             continue;
 8 
 9         InterlockedIncrement(&pThis->m_lRunThreadNum);       
10         while(!pThis->m_qItask.empty())                                        //由if->while 代码优化
11         {
12             if(WaitForSingleObject(pThis->m_lMutex,100) == WAIT_TIMEOUT)    //上锁
13                 continue;
14             if(pThis->m_qItask.empty())
15             {
16                 ReleaseMutex(pThis->m_lMutex);                                    //解锁
17                 break;
18             }
19             pItask = pThis->m_qItask.front();
20             pThis->m_qItask.pop();
21             //pThis->m_bIsPop = true;
22             ReleaseMutex(pThis->m_lMutex);                                    //解锁
23 
24             pItask->RunTask();
25             delete pItask;
26             pItask = NULL;
27         }
28         InterlockedDecrement(&pThis->m_lRunThreadNum);
29 
30     }
31 
32     return 0;
复制代码
4》在销毁时，能清空的都要清空，防止内存泄漏

复制代码
 1     m_bFlagExit = false;
 2     list<HANDLE>::iterator ite = m_lHandle.begin();
 3     //auto ite = m_lHandle.begin();
 4     while(ite != m_lHandle.end())
 5     {
 6         if(WaitForSingleObject(*ite,100) == WAIT_TIMEOUT)
 7             TerminateThread(*ite,-1);
 8         CloseHandle(*ite);
 9         *ite = 0;
10         ite++;
11     }
12     m_lHandle.clear();
13     m_lCreateThreadNum = 0;
14     CloseHandle(m_hSemphore);
15     m_hSemphore = 0;
16 
17     while(!m_qItask.empty())        //防止内存泄漏,将任务清空
18     {
19         CItask *pItask = NULL;
20         pItask = m_qItask.front();
21         m_qItask.pop();
22         delete pItask;
23         pItask = NULL;
24     }
25 
26     if(m_lMutex)                    //关闭互斥量
27     {
28         CloseHandle(m_lMutex);
29         m_lMutex = 0;
30     }
复制代码

# 18.锁

## 18-1：锁

| 序号 | 锁名称  | 应用                                                              |
|----|------|-----------------------------------------------------------------|
| 1  | 乐观锁  | CAS                                                             |
| 2  | 悲观锁  | synchronized、vector、hashtable                                   |
| 3  | 自旋锁  | CAS                                                             |
| 4  | 可重入锁 | synchronized、Reentrantlock、Lock                                 |
| 5  | 读写锁  | ReentrantReadWriteLock，CopyOnWriteArrayList、CopyOnWriteArraySet |
| 6  | 公平锁  | Reentrantlock(true)                                           |
| 7  | 非公平锁 | synchronized、reentrantlock(false)                             |
| 8  | 共享锁  | ReentrantReadWriteLock中读锁                                       |
| 9  | 独占锁  | synchronized、vector、hashtable、ReentrantReadWriteLock中写锁         |
| 10 | 重量级锁 | synchronized                                                    |
| 11 | 轻量级锁 | 锁优化技术                                                           |
| 12 | 偏向锁  | 锁优化技术                                                           |
| 13 | 分段锁  | concurrentHashMap                                               |
| 14 | 互斥锁  | synchronized                                                    |
| 15 | 同步锁  | synchronized                                                    |
| 16 | 死锁   | 相互请求对方的资源                                                       |
| 17 | 锁粗化  | 锁优化技术                                                           |
| 18 | 锁消除  | 锁优化技术                                                           |

并发下，同时访问数据会出现错误，那么，如果我不同时访问，

当并发来的时候，同一时间只允许同一时间访问，这样就可以了

锁是一种数据保护机制，可允许某一个线程（进程）进行操作锁，

当文件锁上时，其他线程（进程）根据锁的性质（读写锁，阻塞非阻塞）

## 18-2：乐观锁与悲观锁

1. 乐观锁

假定当前环境是读多写少，遇到并发写的概率比较低，读数据时认为别的线程不会正在进行修改也因此没有上锁。

写数据时，判断当前与期望值是否相同，如果相同则进行更新，

更新期间加锁，保证是原子性的。

可以同时进行读操作，读的时候其他线程不能进行写操作。

2. 悲观锁

认为写多读少，遇到并发写的可能性高，每次去拿数据的时候都认为其他线程会修改，

所以每次读写数据都会认为其他线程会修改，所以每次读写数据时都会上锁。

其他线程想要读写这个数据时，会被这个线程block，直到这个线程释放锁然后其他线程获取到锁。

只能有一个线程进行读操作或者写操作，其他线程的读写操作均不能进行。

## 18-3：两种锁的使用场景

1. Java中的乐观锁：

    CAS---比较并替换，比较当前值（主内存中的值），与预期值（当前线程中的值，主内存中值的一份拷贝）是否一样，

一样则更新，否则继续进行CAS操作。

2. Java中的悲观锁： 

      synchronized修饰的方法和方法块、ReentrantLock。

## 18-4：乐观锁常见的两种实现方式

乐观锁一般会使用版本号机制或CAS算法实现。

1. 版本号机制
一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，

当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取

version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，

否则重试更新操作，直到更新成功。

2. CAS算法

## 12-5：乐观锁的缺点

1. ABA 问题

JDK 1.5 以后的 AtomicStampedReference 类就提供了此种能力，

其中的 compareAndSet 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标

志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

2. 循环时间长开销大

自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 

如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，

pause指令有两个作用，第一它可以延迟流水线执行指令,使CPU不会消耗过多的执行资源，

延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避

免在退出循环的时候因内存顺序冲突而引起CPU流水线被清空，从而提高CPU的执行效率。

3. 只能保证一个共享变量的原子操作

CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，

提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量

放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。

## 18-6：自旋锁

## 18-7：自旋锁的优缺点

1. 自旋锁的优点： 避免了线程切换的开销。挂起线程和恢复线程的操作都需要转入内核态中完成，
                  这些操作给Java虚拟机的并发性能带来了很大的压力。

2. 自旋锁的缺点： 占用处理器的时间，如果占用的时间很长，会白白消耗处理器资源，
                 而不会做任何有价值的工作，带来性能的浪费。因此自旋等待的时间必须有一定的
                 限度，如果自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程。

## 18-8：自旋锁的升级——自适应自旋

自适应意味着自旋的时间不再是固定的，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定的。

有了自适应自旋，随着程序运行时间的增长及性能监控信息

的不断完善，虚拟机对程序锁的状态预测就会越来越精准。

## 18-9：自旋锁使用场景

Java中的自旋锁： CAS操作中的比较操作失败后的自旋等待。

## 18-10：可重入锁（递归锁）

任意线程在获取到锁之后能够再次获取该锁而不会被锁所阻塞。可重入锁的作用是避免死锁。

通过组合自定义同步器来实现锁的获取与释放。

- 再次获取锁：识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取。获取锁后，进行计数自增，
- 释放锁：释放锁时，进行计数自减。

## 18-11：可重入锁使用场景

ReentrantLock、synchronized修饰的方法或代码段。

## 18-12：可重入锁如果加了两把，但是只释放了一把会出现什么问题？

程序卡死，线程不能出来，也就是说我们申请了几把锁，就需要释放几把锁。

## 18-13：如果只加了一把锁，释放两次会出现什么问题？

会报错，java.lang.IllegalMonitorStateException。


## 18-14：读写锁

通过ReentrantReadWriteLock类来实现。为了提高性能， Java 提供了读写锁，在读的地方使用读锁，
在写的地方使用写锁，灵活控制，如果没有写锁的情况下，读是无阻塞的，在一定程度上提高了程序的执行效率。
读写锁分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由 jvm 自己控制的。

读锁： 允许多个线程获取读锁，同时访问同一个资源。

写锁： 只允许一个线程获取写锁，不允许同时访问同一个资源。

## 18-15：公平锁

多个线程按照申请锁的顺序来获取锁。在并发环境中，每个线程会先查看此锁维护的等待队列，

如果当前等待队列为空，则占有锁，如果等待队列不为空，

则加入到等待队列的末尾，按照FIFO的原则从队列中拿到线程，然后占有锁。

也就是如果一个线程组里，能保证每个线程都能拿到锁


## 18-16：非公平锁

线程尝试获取锁，如果获取不到，则再采用公平锁的方式。多个线程获取锁的顺序，

不是按照先到先得的顺序，有可能后申请锁的线程比先申请的线程优先获取锁。

## 18-17：公平锁与非公平锁优缺点

优点： 非公平锁的性能高于公平锁。

缺点： 有可能造成线程饥饿（某个线程很长一段时间获取不到锁）

## 18-18：公平锁与非公平锁使用场景

synchronized是非公平锁，ReentrantLock通过构造函数指定该锁是公平的还是非公平的，默认是非公平的。

## 18-19：共享锁

a.当试图读取数据时，事务默认会为所依赖的数据资源请求共享锁。
b.持有共享锁时间：从事务得到共享锁到读操作完成。
c.多个事务可以在同一阶段用共享锁作用于同一数据资源。
d.在读取数据时，可以对如何处理锁定进行控制。后面隔离级别会讲到如何对锁定进行控制。

## 18-20：共享锁使用场景

ReentrantReadWriteLock

## 18-21：独占锁

只能有一个线程获取锁，以独占的方式持有锁。和悲观锁、互斥锁同义。

## 18-22：独占锁使用场景

synchronized，ReentrantLock

## 18-23：重量级锁

同上

## 18-24：重量级锁使用场景

synchronized

## 18-25：轻量级锁

轻量级锁不是为了代替重量级锁，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗，
因为使用轻量级锁时，不需要申请互斥量。

如果没有竞争，轻量级锁使用CAS操作避免了使用互斥操作的开销。但如果存在锁竞争，除了互斥量开销外，
还会额外发生CAS操作，因此在有锁竞争的情况下，轻量级锁比传统的重量级锁更慢！
如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁！


## 18-26：轻量级锁优缺点

优点： 如果没有竞争，通过CAS操作成功避免了使用互斥量的开销。

缺点： 如果存在竞争，除了互斥量本身的开销外，还额外产生了CAS操作的开销，因此在有竞争的情况下，轻量级锁比传统的重量级锁更慢。

## 18-27：偏向锁

## 18-28：偏向锁优缺点

优点： 把整个同步都消除掉，连CAS操作都不去做了，优于轻量级锁。

缺点： 如果程序中大多数的锁都总是被多个不同的线程访问，那偏向锁就是多余的。

## 18-29：分段锁

它内部细分了若干个小的 HashMap，称之为段(Segment)。默认情况下一个 ConcurrentHashMap 被进一步细分为 16 个段，
既就是锁的并发度。如果需要在ConcurrentHashMap 添加一项key-value，并不是将整个 HashMap 加锁，
而是首先根据 hashcode 得到该key-value应该存放在哪个段中，然后对该段加锁，
并完成 put 操作。在多线程环境中，如果多个线程同时进行put操作，只要被加入的key-value不存放在同一个段中，
则线程间可以做到真正的并行。

ConcurrentHashMap 是一个 Segment 数组， Segment 通过继承ReentrantLock 来进行加锁，
所以每次需要加锁的操作锁住的是一个 segment，
这样只要保证每个 Segment 是线程安全的，也就实现了全局的线程安全

## 18-30：互斥锁

也是x锁，该锁每一次只能被一个线程锁持有，加锁后任何线程试图再次加锁的线程会被阻塞，直到当前线程解锁，例子：如果 线程A 对deta1加上排它锁后，则其他线程不能再对data1 加任何类型的锁，获得互斥锁的线既能读取数据又能修改数据

## 18-31：同步锁

表示并发执行的多个线程，在同一时间内只允许一个线程访问共享数据。

## 18-32：死锁

如线程A持有资源x，线程B持有资源y，线程A等待线程B释放资源y，线程B等待线程A释放资源x，两个线程都不释放自己持有的资源，则两个线程都获取不到对方的资源，就
会造成死锁。

Java中的死锁不能自行打破，所以线程死锁后，线程不能进行响应。所以一定要注意程序的并发场景，避免造成死锁。

## 18-33：锁粗化

如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作都是出现在循环体体之中，就算真的没有线程竞争，频繁地进行互斥同步操作将会导致不必要的性能
损耗，所以就采取了一种方案：把加锁的范围扩展（粗化）到整个操作序列的外部，这样加锁解锁的频率就会大大降低，从而减少了性能损耗。

## 18-34：锁消除

## 18-35：提高锁性能的方法
1. 减少锁持有时间
2. 减少锁粒度
3. 读写分离锁来替换独占锁
4. 锁分离
5. 锁粗话

# 19.ThreadLocal

## 19-1：什么是ThreadLocal，优势在哪里

因为我们常用的局部变量和静态变量，在某种情况下无法满足要求，

比如，我要求缓存一个变量，这个时候使用一个静态map存一下就可以了了，但是有几个问题：

第一：其他线程擅自修改我的这个静态map怎么办？

第二：静态map之间并发访问怎么办？

它的本质就是一个内部的静态map，key是当前线程的一个句柄，

value是需要保存的值，value可以是任何类型的，至少是一个map或者容器，

基于这种设计，每个线程其实根本无法获取到其他线程的key，

由于是内部静态map，不提供遍历和查询的接口，也确保了其他线程只能根据key获取，

所以，每个线程只能取到自己线程的value。

这样，即做到了线程安全，又在线程范围内提供了数据共享的能力。

# 20.ThreadLocal原理

## 20-1：ThreadLocal的实现原理

每个Thread 维护一个 ThreadLocalMap 映射表，

这个映射表的 key 是 ThreadLocal实例本身，value 是真正需要存储的 Object。

ThreadLocal 本身并不存储值，它只是作为一个 key 来让线程从 ThreadLocalMap 获取 value。

值得注意的是图中的虚线，表示 ThreadLocalMap 是使用 ThreadLocal 的弱引用作为 Key 的，

弱引用的对象在 GC 时会被回收。

# 21.Threadlocal内存泄露

## 21-1：ThreadLocal内存泄露问题

ThreadLocalMap 中使⽤的 key 为 ThreadLocal 的弱引⽤,⽽ value 是强引⽤。

所以，如ThreadLocal 没有被外部强引⽤的情况下，在垃圾回收的时候，key会被清理掉，⽽ value 不会被清理掉。

这样⼀来， ThreadLocalMap 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远⽆法被GC 回收，

这个时候就可能会产⽣内存泄露。 ThreadLocalMap实现中已经考虑了这种情况，

在调⽤ set() 、 get() 、 remove() ⽅法的时候，会清理掉 key 为 null 的记录。

使⽤完ThreadLocal ⽅法后 最好⼿动调⽤ remove() ⽅法

## 21-2：ThreadLocal如何防止内存泄漏？

每次使用完ThreadLocal，都调用它的remove()方法，清除数据。

在使用线程池的情况下，没有及时清理ThreadLocal，

不仅是内存泄漏的问题，更严重的是可能导致业务逻辑出现问题。

所以，使用ThreadLocal就跟加锁完要解锁一样，用完就需要清理。

# 23.线程变量绑定

## 23-1：如何线程绑定的

当使用 ThreadLocal 维护变量的时候 

为每一个使用该变量的线程提供一个独立的变量副本，

也就是每个线程内部都会有一个该变量，

这样同时多个线程访问该变量并不会彼此相互影响，

因此他们使用的都是自己从内存中拷贝过来的变量的副本， 

这样就不存在线程安全问题，也不会影响程序的执行性能。

但是由于在每个线程中都创建了副本，

所以要考虑它对资源的消耗，比如内存的占用会比不使用 ThreadLocal 要大。






# 24.无锁-CAS、Atomic

## 24-1：CAS

CAS是比较并交换。比较变量的现在值与之前的值是否一致，若一致则替换，否则不替换。

CAS的作用：原子性更新变量值，保证线程安全。

需要有三个操作数，变量的当前值（V），旧的预期值（A），准备设置的新值（B）。

CAS指令执行条件：当且仅当V=A时，处理器才会设置V=B，否则不执行更新。

CAS的返回值：V的之前值。

CAS处理过程：原子操作，执行期间不会被其他线程中断，线程安全。

## 24-2：CAS的ABA问题

如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说它值没有被其
他线程改变过吗?如果在这段期间它的值曾经改成了B，后来又改成了A，那么CAS操作就会误认为它没有改变过，
这个漏洞称为“ABA”问题。解决的核心思想是加上时间戳来标识不同阶段的数值。比如:J.U.C包为了解决这个问
题，提供了一个带有标记的原子引用类“AtomicStampedReference”，它可以通过控制变量值的版本来保证
CAS的正确性，如果需要解决ABA问题，改用传统的互斥同步（典型的就是synchronized和Lock）可能会比原子
类更高效。

# 25.Atomic原子类

## 25-1：原子类原理

原子量底层的实现均是采用CAS非阻塞算法实现的，

是无锁（lock-free）算法中最有名的一种

（无锁算法：不使用锁机制来实现线程安全的算法，

采用锁机制都会存在线程为请求锁而产生阻塞的情况）,CAS不会阻塞线程从而不会带来CPU上下文切换的性能开销。

## 25-1：为什么要使用原子类

为了让Java程序员能够受益于CAS等CPU指令，JDK并发包有一个atomic包，里面实现了一些直接使用CAS操作的线程安全的类型

## 25-2：什么是原子类

原子操作是指不会被线程调度机制打断的操作，这种操作一旦开始，就一直运行到结束，中间不会有任何线程上下文切换。

原子操作可以是一个步骤，也可以是多个操作步骤，但是其顺序不可以被打乱，也不可以被切割而只执行其中的一部分，
将整个操作视作一个整体是原子性的核心特征。

## 25-3：原子类的作用？

提供一种简单、性能高效、线程安全地更新一个变量的方式。

## 25-4：i++自增操作不是原子性的，如何决绝原子性问题

Atomic原子类就是来解决这个问题的，

## 25-5：基本数据类型原子类的优势

多线程环境使用原子类保证线程安全（基本数据类型）

# 26.unsafe

## 26-1：为什么是unsafe

java不能直接访问操作系统底层，而是通过本地方法来访问。

Unsafe类提供了硬件级别的原子操作，主要作用：

1、通过Unsafe类可以分配内存，可以释放内存；

类中提供的3个本地方法allocateMemory、reallocateMemory、freeMemory分别用于分配内存，扩充内存和释放内存，

2、可以定位对象某字段的内存位置，也可以修改对象的字段值，即使它是私有的；

3、挂起与恢复

将一个线程进行挂起是通过park方法实现的，调用 park后，线程将一直阻塞直到超时或者中断等条件出现。
unpark可以终止一个挂起的线程，使其恢复正常。整个并发框架中对线程的挂起操作被封装在 LockSupport类中，
LockSupport类中有各种版本pack方法，但最终都调用了Unsafe.park()方法。

4、CAS操作

是通过compareAndSwapXXX方法实现的

## 26-2：Unsafe为什么是不安全的？

比如使用unsafe创建一个超级大的数组,但是这个数组jvm是不管理的,只能你自己操作,容易oom,也不利于资源的回收.

## 26-3：Unsafe的实例怎么获取？
a. 在jdk8和之前如果获得其单例对象是会抛出异常的，只能通过反射获取，在jdk9及以后，可以通过getUnsafe静态方法获取
b. 我们知道 unsafe是提供给java核心内库使用的，那么我们如何获取Unsafe的实例呢？当然是反射！
c. 代码：
		Field f = Unsafe.class.getDeclaredField("theUnsafe");
		f.setAccessible(true);
		Unsafe unsafe = (Unsafe) f.get(null);

## 26-4：讲一讲Unsafe中的CAS操作？
a. JUC中用到了大量的CAS，他们的底层其实都是采用Unsafe的CAS操作，
b. CAS（比较与交换，Compare and swap）是一种有名的无锁算法,因为不需要加锁，性能比加锁搞。CAS是一个CPU指令。CAS还是一个乐观锁技术
c. CAS存在的问题：
		i. 经典的ABA问题，危害有（以栈举例），解决方案：版本号控制，有的数据结构在高位用邮戳标记；不重复使用节点引用，而是构建新的节点，
		ii. CAS常常搭配自旋一起使用，如果自选长时间不成功，循环时间长 开销大
		iii. 只能保持一个共享变量的安全操作

## 26-5：nsafe的阻塞/唤醒操作？
a. LockSupport类中的park与unpark方法对unsafe中的park与unpark方法做了封装，LockSupport类中有各种版本pack方法，
但最终都调用了Unsafe.park()方法。



# 27. 死锁

## 27-1：什么是线程死锁

多个线程同时被阻塞，它们中的⼀个或者全部都在等待某个资源被释放。由于线程被⽆限期地阻塞，因此程序不可能正常终⽌。

## 27-2：产生死锁的条件

1. 该资源任意⼀个时刻只由⼀个线程占⽤。
2. ⼀个进程因请求资源⽽阻塞时，对已获得的资源保持不放。
3. 线程已获得的资源在末使⽤完之前不能被其他线程强⾏剥夺，只有⾃⼰使⽤完毕后才释放资源。
4. 若⼲进程之间形成⼀种头尾相接的循环等待资源关系。

## 27-3：如何解决线程死锁问题

1. ⼀次性申请所有的资源。
2. 占⽤部分资源的线程进⼀步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
3. 靠按序申请资源来预防。按某⼀顺序申请资源，释放资源则反序释放。破坏循环等待条件。

# 28.AQS（队列同步器）

## 28-1：对AQS原理分析

如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的⼯作线程，并且将共享资源设置为锁定状态。
如果被请求的共享资源被占⽤，那么就需要⼀套线程阻塞等待以及被唤醒时锁分配的机制，
这个机制AQS是⽤CLH队列锁实现的，即将暂时获取不到锁的线程加⼊到队列中。

## 28-2：AQS 对资源的共享⽅式

1. Exclusive（独占）：只有⼀个线程能执⾏，如ReentrantLock。⼜可分为公平锁和⾮公平锁：
   * 公平锁：按照线程在队列中的排队顺序，��到者先拿到锁
   * ⾮公平锁：当线程要获取锁时，⽆视队列顺序直接去抢锁，谁抢到就是谁的
2. Share（共享）：多个线程可同时执⾏，如Semaphore/CountDownLatch。 Semaphore、
CountDownLatch、 CyclicBarrier、 ReadWriteLock 我们都会在后⾯讲到。

## 28-3：AQS 组件

1. Semaphore(信号量)-允许多个线程同时访问：
   synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。

2. CountDownLatch （倒计时器）： 
                               CountDownLatch是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，
                               它可以让某一个线程等待直到倒计时结束，再开始执行。

3. CyclicBarrier(循环栅栏)： 
                           CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，
                           但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。
                           CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。
                           它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，
                           直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。
                           CyclicBarrier默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，
                           每个线程调用await()方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。

## 28-4：AQS应用场景





# 29.并发容器

## 39-1：JDK 提供的并发容器总结

ConcurrentHashMap: 线程安全的 HashMap
CopyOnWriteArrayList: 线程安全的 List，在读多写少的场合性能非常好，远远好于 Vector.
ConcurrentLinkedQueue: 高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列。
BlockingQueue: 这是一个接口，JDK 内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。
ConcurrentSkipListMap: 跳表的实现。这是一个 Map，使用跳表的数据结构进行快速查找。

## 29-2：CopyOnWriteArrayList 是如何做到的？

CopyOnWriteArrayList 类的所有可变操作（add，set 等等）都是通过创建底层数组的新副本来实现的。

当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，

将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。

从 CopyOnWriteArrayList 的名字就能看出CopyOnWriteArrayList 是满足CopyOnWrite 的 ArrayList，

在计算机，如果你想要对一块内存进行修改时，我们不在原有内存块中进行写操作，

而是将内存拷贝一份，在新的内存中进行写操作，写完之后呢，就将指向原来内存指针指向新的内存，原来的内存就可以被回收掉了。

## 29-3：BlockingQueue

使用的就是是lock锁的多条件（condition）阻塞控制

直接提交队列、有界队列、无界队列、优先级任行队
(1）直接提交队列:设置为SynchronousOueue队列，SynchronousQueue是一个特殊的
BlockingQueue，它没有容量，没执行一个插入操作就会阻塞，需要再执行一个删除操作才会
被唤醒，反之每一个删除操作也都要等待对应的插入操作。

(2）有界的任务队列:有界的任务队列可以使用ArrayBlockingQucue实现。若有新的任务
需要执行时，线程池会创建新的线程，直到创建的线程数量达到corePoolSize时，则会将新
的任务加入到等待队列中。若等待队列已满，即超过ArrayBlockingQueue初始化的容量，则
继续创建线程，直到线程数量达到 maximumPoolSize设置的最大线程数量，若大于ximumPoolSize，则执行拒绝策略。


(3）无界的任务队列:有界任务队列可以使用LinkedBlockingQueue实现。使用无界任务队
列，线程池的任务队列可以无限制的添加新的任务，而线程池创建的最大线程数量就是你
corePoolSize设置的数量，在这种情况下maximumPoolSize这个参数是无效的，即使任务队列中缓存了很多未执行的任务，
当线程池的线程数达到corePoolSize后，就不会再增加了;若后续有新的任务加入，
则直接进入队列等待，当使用这种任务队列模式时，
一定要注意你任务提交与处理之间的协调与控制，不然会出现队列中的任务由于无法及时处
理导致一直增长，直到最后资源耗尽的问题。

（4）优先任务队列:优先任务队列通过 PriorityBlockingQueue实现。
PriorityBlockingQueue它其实是一个特殊的无界队列，它其中无论添加了多少个任
务，线程池创建的线程数也不会超过corePoolSize的数量，只不过其他队列一般是按照先进
先出的规则处理任务，而PriorityBlockingQueue队列可以自定义规则根据任务的优先级顺序
先后执行。

# 30.快速失败与安全失败

一:快速失败（fail-fast）

在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加.删除、修改），则会抛出 Concurrent Modification Exception。

场景:java.util包下的集合类都是快速失败的，不能在多线程下发生并发修改（迭代过程中被修改)。

二:安全失败（failsafe）

采用安全失败机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。

原理:由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发Concurrent Modification Exception。

缺点:基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即:迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。

场景:java.util.concurrent包下的容器都是安全失败，可以在多线程下并发使用，并发修改。

# 31.什么是上下⽂切换?

当前任务在执⾏完 CPU时间⽚ 切换到另⼀个任务 之前 会先保存⾃⼰的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。 任务从保存到再加载的过程就是⼀次上下⽂切换。


# --------------JVM-------------------------------------------------------------------------------------------------

# 1.类加载

## 1.1：类的生命周期

类的生命周期包括：加载、连接、初始化、使用和卸载

## 1.2：类的加载过程

类的加载过程分为：加载->连接->初始化。连接过程又可分为三步:验证->准备->解析

1. 加载，

      1. 通过全类名获取定义此类的二进制字节流
      2. 将字节流所代表的静态存储结构转换为方法区的运行时数据结构
      3. 在内存中生成一个代表该类的 Class 对象,作为方法区这些数据的访问入口

2. 连接，连接又包含三块内容：验证、准备、初始化。
   * 1）验证，文件格式验证、元数据验证、字节码验证、符号引用验证；
   * 2）准备，为类的静态变量分配内存，并将其初始化为默认值；
   * 3）解析，虚拟机将常量池内的符号引用转换为直接引用

3. 初始化，开始执行java代码

4. 使用，new出对象程序中使用

5. 卸载，执行垃圾回收
   
    卸载类需要满足3个要求:
         1. 该类的所有的实例对象都已被GC，也就是说堆不存在该类的实例对象。
         2. 该类没有在其他任何地方被引用
         3. 该类的类加载器的实例已被GC

* 理解：在JVM生命周期类，由jvm自带的类加载器加载的类是不会被卸载的。但是由我们自定义的类加载器加载的类是可能被卸载的。

## 1.3：类加载机制

1. 全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用
   另外一个类加载器来载入

2. 父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类

3. 缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要���用某个Class时，类加载器先从缓存区寻找该Class，
   只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，
   必须重启JVM，程序的修改才会生效

## 1.4：知道哪些类加载器?

引导类加载器 bootstrap class loader
　　启动类加载器主要加载的是JVM自身需要的类，这个类加载使用C++语言实现的，是虚拟机自身的一部分，它负责将 /lib路径下的核心类库或-Xbootclasspath参数指定的路径下的jar包加载到内存中，注意必由于虚拟机是按照文件名识别加载jar包的，如rt.jar，如果文件名不被虚拟机识别，即使把jar包丢到lib目录下也是没有作用的(出于安全考虑，Bootstrap启动类加载器只加载包名为java、javax、sun等开头的类

扩展类加载器 extensions class loader
　　它负责加载JAVA_HOME/lib/ext目录下或者由系统变量-Djava.ext.dir指定位路径中的类库，开发者可以直接使用标准扩展类加载器。

应用程序类加载器 application class loader
　　应用程序加载器是指 Sun公司实现的sun.misc.Launcher$AppClassLoader。它负责加载系统类路径java -classpath或-D java.class.path 指定路径下的类库，也就是我们经常用到的classpath路径，开发者可以直接使用系统类加载器，一般情况下该类加载是程序中默认的类加载器，通过ClassLoader#getSystemClassLoader()方法可以获取到该类加载器。

自定义类加载器 java.lang.classloder
　　就是自定义啦，通过继承java.lang.ClassLoader类的方式

类加载器之间的关系
　　启动类加载器，由C++实现，没有父类。
　　拓展类加载器(ExtClassLoader)，由Java语言实现，父类加载器为null
　　系统类加载器(AppClassLoader)，由Java语言实现，父类加载器为ExtClassLoader
　　自定义类加载器，父类加载器肯定为AppClassLoader。


# 2.双亲委派模型

## 2-1：双亲委派模型流程

每一个类都有一个对应��的类加载器。系统中的 ClassLoder 在协同工作的时候会默认使用 双亲委派模型 。即
在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。加载
的时候，首先会把该请求委派该父类加载器的 loadClass() 处理，因此所有的请求最终都应该传送到顶层的启
动类加载器 BootstrapClassLoader 中。当父类加载器无法处理时，才由自己来处理。当父类加载器为null
时，会使用启动类加载器 BootstrapClassLoader 作为父类加载器。

## 2-2：双亲委派模型带来了什么好处呢？

双亲委派模型保证了Java程序的稳定运行，可以避免类的重复加载（JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类），也保证了 Java 的核心 API 不被篡改。如果没有使用双亲委派模型，而是每个类加载器加载自己的话就会出现一些问题，比如我们编写一个称为 java.lang.Object 类的话，那么程序运行的时候，系统就会出现多个不同的 Object 类。

## 2-3：如果我们不想⽤双亲委派模型怎么办？

自定义加载器的话，需要继承 ClassLoader 。如果我们不想打破双亲委派模型，就重写 ClassLoader 类中的 findClass() 方法即可，无法被父类加载器加载的类最终会通过这个方法被加载。但是，如果想打破双亲委派模型则需要重写 loadClass() 方法

## 2-4：自己写一个类能不能被加载？

不能，因为双亲委派机制可以打破，但是不会实现成功的原因在于针对java开头的类，jvm实现中已经保证了必须由bootatrp来加载

但是如果非要加载的话，可以放在用户目录下进行加载


# 3.垃圾回收

## 3-1：如何判断对象已经死亡？

1. 引用计数法
给对象中添加一个引用计数器，每当有一个地方引用它，计数器就加 1；当引用失效，计数器就减 1；任何时候计数器为 0 的对象就是不可能再被使用的。

这个方法实现简单，效率高，但是目前主流的虚拟机中并没有选择这个算法来管理内存，其最主要的原因是它很难解决对象之间相互循环引用的问题。 所谓对象之间的相互引用问题，比如说对象 objA 和 objB 相互引用着对方之外，这两个对象之间再无任何引用。但是他们因为互相引用对方，导致它们的引用计数器都不为 0，于是引用计数算法无法通知 GC 回收器回收他们。

2. 可达性分析算法
这个算法的基本思想就是通过一系列的称为 “GC Roots” 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，则证明此对象是不可用的。

## 3-2：不可达的对象是否非死不可

即使在可达性分析法中不可达的对象，也并非是“非死不可”的，这时候它们暂时处于“缓刑阶段”，要真正宣告一
个对象死亡，至少要经历两次标记过程;可达性分析法中不可达的对象被第一次标记并且进行一次筛选，筛选的
条件是此对象是否有必要执行finalize方法。当对象没有覆盖finalize方法，或finalize方法已经被虚拟机调
用过时，虚拟机将这两种情况初为沿右必要执行。被判定为需要执行的对象将会被放在一个队列中进行第二次标
记，除非这个对象与引用链上的任何一个对象简历关联，否则就会真的回收。

## 3-2：强、软、弱、虚引用

1．强引用（StrongReference）

如果一个对象具有强引用，垃圾回收器绝不会回收它。当内存空间不足，Java 虚拟机宁愿抛出 OutOfMemoryError 错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。

2．软引用（SoftReference）

如果一个对象只具有软引用，如果内存空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。

软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收，JAVA 虚拟机就会把这个软引用加入到与之关联的引用队列中。

3．弱引用（WeakReference）

如果一个对象只具有弱引用，弱引用关联的对象只能生存到下一次垃圾回收之前。

弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程， 因此不一定会很快发现那些只具有弱引用的对象。

弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java 虚拟机就会把这个弱引用加入到与之关联的引用队列中。

4．虚引用（PhantomReference）

虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。

虚引用主要用来跟踪对象被垃圾回收的活动。

虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。

在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速 JVM 对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。

## 3-3：如何减少 GC 的次数

1. 对象不用时最好显示置为 NULL

2. 尽量少使用 System,gc()

3. 尽量少使用静态变量

4. 尽量使用 StringBuffer,而不使用 String 来累加字符串
5. 分散对象创建或删除的时间

6. 尽量少用 finaliza 函数

7. 如果有需要使用经常用到的图片，可以使用软引用类型，将图片保存在内存中，而不引起 outofmemory

8. 能用基本类型入 INT 就不用对象 Integer

9. 增大-Xmx 的值

## 3-4：GC 是什么?为什么要有 GC?

GC是垃圾收集的意思

内存处理是编程人员容易出现问题的地方，忘记或者错误的内存回收会导致程序或系统的不稳定甚至崩溃， Java提供的GC功能可以自动监测对象是否超过作用域从而达到自动回收内存的目的， Java 语言没有提供释放已分配内存的显示操作方法

GC是在堆空间和永久区

## 3-5：垃圾回收的优点

1. 可以有效的防止内存泄露
2. 有效的使用可以使用的内存。

## 3-6：垃圾回收器的基本原理是什么？

对于 GC 来说，当程序员创建对象时， GC 就开始监控这个对象的地址、大小以及使用情况。
通常， GC 采用有向图的方式记录和管理堆(heap)中的所有对象。通过这种方式确定哪些对象是"可达的"，哪些对象是"不可达的"。当 GC 确定一些对象为"不可达"时， GC 就有责任回收这些内存空间。

## 3-7：什么样的对象需要回收

对象到GC Roots没有引用链， 那么这个对象不可用， 需要回收

## 3-8：可作为GC Roots的对象？

1. 虚拟机栈中引用的对象
2. 方法区中类静态属性引用的对象
3. 方法区中常量引用的对象
4. 本地方法栈中Native方法引用的对象

## 3-9：垃圾回收器可以马上回收内存吗？

不可以？？？？？？

## 3-10：有什么办法主动通知虚拟机进行垃圾回收？

可以。程序员可以手动执行 System.gc()，通知 GC 运行，但是 Java 语言规范并不保证 GC 一定会执行。

## 3-11：如何判断一个类是无用的类

1. 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。
2. 加载该类的 ClassLoader 已经被回收。
3. 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。

虚拟机可以对满足上述 3 个条件的无用类进行回收，这里说的仅仅是“可以”，而并不是和对象一样不使用了就会必然被回收。

## 3-12：如何判断一个常量是废弃常量？

假如在常量池中存在字符串 "abc"，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 "abc" 就是废弃常量，如果这时发生内存回收的话而且有必要的话，"abc" 就会被系统清理出常量池。

## 3-11：垃圾回收算法

1. 标记-清除算法
   
算法分为“标记”和“清除”阶段：⾸先标记出所有需要回收的对象，在标记完成后统⼀回收所有被标记的对象。它是最基础的收集算法，后续的算法都是对其不⾜进⾏改进得到。

这种垃圾收集算法会带来两个明显的问题：

1. 效率问题
2. 空间问题（标记清除后会产⽣⼤量不连续的碎⽚）

2. 复制算法

为了解决效率问题， 它可以将内存分为⼤⼩相同的两块，每次使⽤其中的⼀块。当这⼀块的内存使⽤完后，就
将还存活的对象复制到另⼀块去，然后再把使⽤的空间⼀次清理掉。这样就使每次的内存回收都是对内存区间的
⼀半进⾏回收。

3. 标记-整理算法

根据⽼年代的特点特出的⼀种标记算法，标记过程仍然与“标记-清除”算法⼀样，但后续步骤不是直接对可回收
对象回收，⽽是让所有存活的对象向⼀端移动，然后直接清理掉端边界以外的内存。

4. 分代收集算法

根据对象存活周期的不同将内存分为⼏块。⼀般将java堆分为新⽣代和⽼年代，这样我们就可以根据各个年代的
特点选择合适的垃圾收集算法。

## 3-12：Minor Gc和Full GC 有什么不同呢？

⼤多数情况下，对象在新⽣代中eden 区分配。当 eden 区没有⾜够空间进⾏分配时，虚拟机将发起⼀次Minor GC。

1. 新⽣代GC（Minor GC） :指发⽣新⽣代的的垃圾收集动作， Minor GC⾮常频繁，回收速度⼀般也⽐较快。

2. ⽼年代GC（Major GC/Full GC） :指发⽣在⽼年代的GC，出现了Major GC经常会伴随⾄少⼀次的Minor GC
   （并⾮绝对），Major GC的速度⼀般会⽐Minor GC的慢10倍以上。


## 3-13：何时发生full gc

1. System.gc()方法的调用 ，system.gc(), 此方法的调用是建议JVM进行Full GC, 可通过通过-XX:+ DisableExplicitGC来禁止RMI调用System.gc。 

2. old/Tenured 空间不足 

3. perm/metaspace 空间不足

4. CMS GC时出现promotion failed和concurrent mode failure 

5. 判断当前新生代的对象是否能够全部顺利的晋升到老年代，如果不能，就提早触发一次老年代的收��

## CMS 出现FullGC的原因：

1、年轻代晋升到老年代没有足够的连续空间，很有可能是内存碎片导致的，因此会触发FULL GC

2、在并发过程中JVM觉得在并发过程结束之前堆就会满，需要提前触发FullGC

CMS失败后使用备案SerialOld收集器

# 4.常⻅的垃圾回收器有那些?

## 4-1：Serial收集器

不仅只会使⽤⼀条垃圾收集线程去完成垃圾收集⼯作，更重要的是它在进⾏垃圾收集⼯作的时候必须暂停其他所有的⼯作线程，直到它收集结束。

优势：

1. 简单⽽⾼效
2. 由于没有线程交互的开销，⾃然可以获得很⾼的单线程收集效率。 

## 4-2：ParNew收集器

除了使⽤多线程进⾏垃圾收集外，其余⾏为（控制参数、收集算法、回收策略等等）和Serial收集器完全⼀样。

新⽣代采⽤复制算法，⽼年代采⽤标记-整理算法。

## 4-3：Parallel Scavenge收集器

Parallel Scavenge 收集器关注点是吞吐量（高效率的利用 CPU）。CMS 等垃圾收集器的关注点更多的是用户线程的停顿时间（提高用户体验）。所谓吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。 Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运作不太了解的话，手工优化存在困难的话可以选择把内存管理优化交给虚拟机去完成也是一个不错的选择。

新生代采用复制算法，老年代采用标记-整理算法。 

## 4-4：Serial Old收集器

Serial 收集器的老年代版本，它同样是一个单线程收集器。它主要有两大用途：一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用，另一种用途是作为 CMS 收集器的后备方案。

## 4-5：Parallel Old收集器

Parallel Scavenge 收集器的老年代版本。使用多线程和“标记-整理”算法。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。

## 4-6：CMS收集器

CMS（Concurrent Mark Sweep）收集器是一种以获取最短回收停顿时间为目标的收集器。它非常符合在注重用户体验的应用上使用。

CMS（Concurrent Mark Sweep）收集器是 并发收集器，

它第一次基本上实现了让垃圾收集线程与用户线程同时工作。

整个过程分为四个步骤：

1. 初始标记： 暂停所有的其他线程，并记录下直接与 root 相连的对象，速度很快 ；
2. 并发标记： 同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构
              并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方。
3. 重新标记： 重新标记阶段就是为了修正并发标记期间因为用户程序继续运行而导致标记产生变动的那一部分
              对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短
4. 并发清除： 开启用户线程，同时 GC 线程开始对未标记的区域做清扫。

优点:
并发，低停顿

缺点：
1、对CPU非常敏感：在并发阶段虽然不会导致用户线程停顿，但是会因为占用了一部分线程使应用程序变慢

2、无法处理浮动垃圾：在最后一步并发清理过程中，用户线程执行也会产生垃圾，但是这部分垃圾是在标记之后，所以只有等到下一次gc的时候清理掉，这部分垃圾叫浮动垃圾。由于并发清理的时候，用户线程也在运行，就需要保证用户线程在运行的时候需要留有部分内存以供使用。但是当这部分内存不足以给用户线程正常使用时，就会出现一次 “Concurrent Mode Failure”，一旦出现了“Concurrent Mode Failure”，便会开启后备方案，临时使用SerialOld收集器进行收集工作。

3、CMS使用“标记-清理”法会产生大量的空间碎片，当碎片过多，将会给大对象空间的分配带来很大的麻烦，往往会出现老年代还有很大的空间但无法找到足够大的连续空间来分配当前对象，不得不提前触发一次FullGC，

为了解决这个问题CMS提供了一个开关参数，用于在CMS顶不住，要进行FullGC时开启内存碎片的合并整理过程，但是内存整理的过程是无法并发的，空间碎片没有了但是停顿时间变长了

## 4-7：G1收集器

G1 (Garbage-First) 是一款面向服务器的垃圾收集器,主要针对配备多颗处理器及大容量内存的机器. 以极高概率满足 GC 停顿时间要求的同时,还具备高吞吐量性能特征.

它具备一下特点：

特点:并发性强、分代收集、标记整理进行空间整合，可以预测停顿时间。

1. 并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU（CPU 或者 CPU 核心）来缩短 
   Stop-The-World 停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 java 程序继续执行。
2. 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念。
3. 空间整合：与 CMS 的“标记--清理”算法不同，G1 从整体来看是基于“标记整理”算法实现的收集器；从局部
   上来看是基于“复制”算法实现的。
4. 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 
   除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定在一个长度为 M 毫秒的时间片段内。

G1 收集器的运作大致分为以下几个步骤：

1. 初始标记
2. 并发标记
3. 最终标记
           将并发阶段对象变化记录在线程Remenbered Set Logs里面，最终把Remembered Set Logs的数据合
           并到Remembered Set中，这一阶段需要停顿线程，但是可并行执行。
4. 筛选回收
           筛选回收，对每一个region的价值和成本进行筛选，根据用户期望的GC停顿时间，得到最好的回收方案并回收。

优点：

1、空间整合：g1使用Region独立区域概念，g1利用的是标记复制法，不会产生垃圾碎片

2、分代收集：g1可以自己管理新生代和老年代

3、并行于并发：g1可以通过机器的多核来并发处理 stop - The - world停顿，减少停顿时间，并且可不停顿java线程执行GC动作，可通过并发方式让GC和java程序同时执行。

4、可预测停顿：g1除了追求停顿时间，还建立了可预测停顿时间模型，能让制定的M毫秒时间片段内，消耗在垃圾回收器上的时间不超过N毫秒

## CMS与G1区别

区别一： 使用范围不一样
CMS收集器是老年代的收集器，可以配合新生代的Serial和ParNew收集器一起使用
G1收集器收集范围是老年代和新生代。不需要结合其他收集器使用

区别二： STW的时间
CMS收集器以最小的停顿时间为目标的收集器。

G1收集器可预测垃圾回收的停顿时间（建立可预测的停顿时间模型）

区别三： 垃圾碎片
CMS收集器是使用“标记-清除”算法进行的垃圾回收，容易产生内存碎片

G1收集器使用的是“标记-整理”算法，进行了空间整合，降低了内存空间碎片。

区别四： 垃圾回收的过程不一样

作者：不怕天黑_0819
链接：https://www.jianshu.com/p/ab54489f5d71
来源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。


## 4-8：吞吐有限和响应有限的垃圾收集器如何选择

1. 吞吐量优先
新生代采用Paralle Scavenge,老年代采用Parallel Old.并配置 多个线程进行回收。设置参数来调整最大垃圾收集停顿时间和吞吐量的大小。
2. 响应时间优先
设置老年代的收集器是CMS (最短时间，spark streaming采用这个)。年轻代是ParnNiew(多线程)。


# 5.Java内存结构（JMM）

## 5-1：为什么需要Java内存模型？

屏蔽各种硬件和操作系统的内存访问差异

## 5-2：什么是JMM

JMM是Java内存模型，本身是一种抽象的概念，实际上并不存在，它描述的是一组规则或规范，通过这组规范定义了程序中各个变量（包括实例字段，静态字段和构成数组对象的元素）的访问方式。

## 5-3：什么是Java内存模型？

1. 定义程序中各种变量的访问规则

2. 把变量值存储到内存的底层细节

3. 从内存中取出变量值的底层细节

## 5-4：Java内存模型的两大内存是啥？

1. 主内存
  * Java堆中对象实例数据部分
  * 对应于物理硬件的内存
2. 工作内存
  * Java栈中的部分区域
  * 优先存储于寄存器和高速缓存

## 5-5：内存如何工作

线程对变量的操作（读取赋值等）必须在工作内存中进行，首先要将变量从主内存拷贝到自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写会主内存

## 5-6：Java内存模型三大特性

可见性（当一个线程修改了共享变量的值时，其他线程能够立即得知这个修改）
原子性（一个操作或一系列操作是不可分割的，要么同时成功，要么同时失败）
有序性（变量赋值操作的顺序与程序代码中的执行顺序一致）

## 5-7：运行时数据区

1. 堆
Java堆是用来存放实例对象和数组对象的，由于存在逃逸分析找术(分析这个对象不会被其他方法或者线程调用)，也可以分布在栽上，随着出栈而销毁，同时，java堆也是垃圾回收的主要区域，由于现在垃圾收集器基本都采用分代垃圾收集算法，所以Java堆还可以细分为:新生代和老年代

Java堆在物理上可以不连续，只要逻辑连续就好。在堆上分配对象的方法有:指针碰撞和空闲列表，前者是在堆内存规整的情景下，所有用过和空闲的内存中间有明确的分界线，而后者用空闲列表来记录内存的使用情况，规整是由垃圾回收器是否压缩整理决定。空间不足抛出OutOfMemoryError.

堆上对象的访问方式:通过栈上的 reference数据来操作堆上的具体对象。目前主流的访问了式有使用句柄和直接指针两种。句柄的话，Java堆中将会划分出一块内存来作为句柄池reference中存储的就是对像的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息，直接指针的话，reference中存储的直接就是对象的地址，前者稳定后者效率高

2. 方法区

方法区与Java堆一样，是各个线程共享的内存区域，特用于存储已被虚拟机加载的类信息，常量、静态变量，其中运行时常量池、用于存放编译器生成的各类字面量和符号引用(字面量：1.文本字符串，2.八种基本数据类型的值，3.被声明为final的常量，符号引用：1.类和方法的权限定名，2.字段的名称和描述符3.方法的名称和描述符)运行时常量池相对于Class常量池具有动态性，可以在运行期间利用intern方法将常量池放入池中，空间不足抛出OOMError


3. 虚拟机栈

虚拟机栈是java方法执行的内存模型，线程私有，每个方法执行都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接(运行时将方法区的符号引用转化为直接引用，表示真的可以调用了)和方法出口等信息围每一个方法从调用直至执行结束，就对应着一个栈帧从虚拟机栈中入栈到出栈的过程。

StackOverflowError:线程请求的栈深度大于虚拟机所允许的深度。

OutofMemoryError:如果虚拟机栈可以动态扩展，而扩展时无法申请到足够的内存。

4. 本地方法栈

本地方法栈则是为虚拟机使用到的Native方法服务

作用：本地方法栈用于管理本地方法的调用

1. 程序计数器
记录当前线程所执行到的字节码的行号。每个线程都有一个程序计数器，唯一没有OutOfMemoryError情况的内存
区域。

运行时内存区域外规定的堆外内存:直接使用 Native函数库直接分配堆外内存，然后通过一个存储在java堆中的
DirectByteBuffer对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在Java
堆和Native堆之间来回复制数据。

## 5-8：程序计数器为什么是私有的?

程序计数器私有主要是为了线程切换后能恢复到正确的执⾏位置。

## 5-9：虚拟机栈和本地⽅法栈为什么是私有的?

为了保证线程中的局部变量不被别的线程访问到，虚拟机栈和本地⽅法栈是线程私有的。

## 5-10：堆和栈的区别是什么？

一个是线程独享的，一个是线程共享的

堆中主要存放对象实例。栈（局部变量表）中主要存放各种基本数据类型、对象的引用。

## 5-11：Java中的数组是存储在堆上还是栈上的？

所以，数组的实例是保存在堆中，而数组的引用是保存在栈上的。

## 5-12：Java 8的metaspace (元空间)

方法区是所有线程共享。主要用于存储类的信息、常量池、方法数据、方法代码等。方法区是JVM的规范，

永久代(PermGen space )是HotSpot对这种规范的实现。在JDK1.8中，HotSpot已经没有永久代，取而代之的是Metaspace( 元空间)。

元空间的本质和永久代类似，都是对JVM规范中方法区的实现。不过元空间与永久代之间最大的区别在于:元空间并不在虚拟机中，而是使用本地内存。

## 5-13：为什么要进行元空间代替持久代呢?

1. 字符串存在永久代中，容易出现性能问题和内存溢出。

2. 类及方法的信息等比较难确定其大小，因此对于永久代的大小指定比较困难，太小容易出现永久代溢出，太大则容易导致老年代溢出。

3. 永久代会为GC带来不必要的复杂度，并且回收效率偏低。

## 5-14：Java中的对象一定在堆上分配内存吗？

前面我们说过，Java堆中主要保存了对象实例，但是，

在编译期间，JIT会对代码做很多优化。其中有一部分优化的目的就是减少内存堆分配压力，其中一种重要的技术叫做逃逸分析。

如果JIT经过逃逸分析，发现有些对象没有逃逸出方法，那么有可能堆内存分配会被优化成栈内存分配。

## 5-15：怎么如何获取堆和栈的dump文件？

是一个Java虚拟机的运行时快照。将Java虚拟机运行时的状态和信息保存到文件。

可以使用在服务器上使用jmap命令来获取堆dump，使用jstack命令来获取线程的调用栈dump。

## 5-16：不同的虚拟机在实现运行时内存的时候有什么区别？

前面提到过《Java虚拟机规范》定义的JVM运行时所需的内存区域，不同的虚拟机实现上有所不同，而在这么多区域中，规范对于方法区的管理是最宽松的，规范中关于这部分的描述如下：
方法区在虚拟机启动的时候创建，虽然方法区是堆的逻辑组成部分，但是简单的虚拟机实现可以选择在这个区域不实现垃圾收集与压缩。本版本的规范也不限定实现方法区的内存位置和代码编译的管理策略。方法区的容量可以是固定的，也可以随着程序执行的需求动态扩展，并在不需要过多的空间时自行收缩。方法区在实际内存空间站可以是不连续的。
这一规定，可以说是给了虚拟机厂商很大的自由。
虚拟机规范对方法区实现的位置并没有明确要求，在最著名的HotSopt虚拟机实现中（在Java 8 之前），方法区仅是逻辑上的独立区域，在物理上并没有独立于堆而存在，而是位于永久代中。所以，这时候方法区也是可以被垃圾回收的。
实践证明，JVM中存在着大量的声明短暂的对象，还有一些生命周期比较长的对象。为了对他们采用不同的收集策略，采用了分代收集算法，所以HotSpot虚拟机把的根据对象的年龄不同，把堆分位新生代、老年代和永久代。
在Java 8中 ，HotSpot虚拟机移除了永久代，使用本地内存来存储类元数据信息并称之为：元空间（Metaspace）

# 6.分区——新生代， 老年代， 持久代

## 6-1：分区目的

JVM在程序运行过程当中，会创建大量的对象，

这些对象，大部分是短周期的对象，小部分是长周期的对象，

对于短周期的对象，需要频繁地进行垃圾回收以保证无用对象尽早被释放掉，

对于长周期对象，则不需要频率垃圾回收以确保无谓地垃圾扫描检测。

为解决这种矛盾，Sun JVM的内存管理采用分代的策略。

新生区由于对象产生的比较多并且大都是朝生夕灭的，

所以直接采用复制算法。而养老区生命力很强，则采用标记-清理算法，针对不同情况使用不同算法。

## 6-2：年轻代

年轻代主要存放新创建的对象，内存大小相对会比较小，

垃圾回收会比较频繁。年轻代分成1个Eden Space和2个Suvivor Space（命名为A和B）。

当对象在堆创建时，将进入年轻代的Eden Space。垃圾回收器进行垃圾回收时，

扫描Eden Space和A Suvivor Space，如果对象仍然存活，则复制到B Suvivor Space，

如果B Suvivor Space已经满，则复制到Old Gen。同时，在扫描Suvivor Space时，

如果对象已经经过了几次的扫描仍然存活，JVM认为其为一个持久化对象，

则将其移到Old Gen。扫描完毕后，JVM将Eden Space和A Suvivor Space清空，

然后交换A和B的角色（即下次垃圾回收时会扫描Eden Space和B Suvivor Space。这么做主要是为了减少内存碎片的产生。

Young Gen垃圾回收时，采用将存活对象复制到到空的Suvivor Space的方式来确保尽量不存在内存碎片，

采用空间换时间的方式来加速内存中不再被持有的对象尽快能够得到回收。

## 6-3：为什么会有年轻代

分代的理由就是优化GC性能。

如果没有分代，那我们所有的对象都在一块，

GC的时候我们要找到哪些对象没用，这样就会对堆的所有区域进行扫描。

而我们的很多对象都是朝生夕死的，如果分代的话，我们把新创建的对象放到某一地方，

当GC的时候先把这块存“朝生夕死”对象的区域进行回收，这样就会腾出很大的空间出来。

## 6-4：年轻代中的GC

HotSpot JVM把年轻代分为了三部分：

1个Eden区和2个Survivor区（分别叫from和to）。默认比例为8：1,

一般情况下，新创建的对象都会被分配到Eden区(一些大对象特殊处理),

这些对象经过第一次Minor GC后，如果仍然存活，将会被移到Survivor区。

对象在Survivor区中每熬过一次Minor GC，年龄就会增加1岁，

当它的年龄增加到一定程度时，就会被移动到年老代中。因为年轻代中的对象基本都是朝生夕死的(80%以上)，

所以在年轻代的垃圾回收算法使用的是复制算法，复制算法的基本思想就是将内存分为两块，

每次只用其中一块，当这一块内存用完，就将还活着的对象复制到另外一块上面。复制算法不会产生内存碎片。

在GC开始的时候，对象只会存在于Eden区和名为“From”的Survivor区，Survivor区“To”是空的。

紧接着进行GC，Eden区中所有存活的对象都会被复制到“To”，而在“From”区中，

仍存活的对象会根据他们的年龄值来决定去向。

年龄达到一定值(年龄阈值，可以通过-XX:MaxTenuringThreshold来设置)的对象会被移动到年老代中，

没有达到阈值的对象会被复制到“To”区域。经过这次GC后，Eden区和From区已经被清空。

这个时候，“From”和“To”会交换他们的角色，也就是新的“To”就是上次GC前的“From”，

新的“From”就是上次GC前的“To”。不管怎样，都会保证名为To的Survivor区域是空的。

Minor GC会一直重复这样的过程，直到“To”区被填满，“To”区被填满之后，会将所有对象移动到年老代中。

## 6-5：为什么是8：1：1

假设当内存使用达到98%时才GC就有点晚了，应该是多一些预留10%内存空间，

这预留下来的空间我们称为S区（有两个s区  s1 和  s0），

S区是用来存储新生代GC后存活下来的对象，而我们知道新生代GC算法使用的是复制回收算法。

所以我们实际GC发生是在，新生代内存使用达到90%时开始进行，

复制存活的对象到S1区，要知道GC结束后在S1区活下来的对象，

在下一次GC的范围是，eden区和S1，把这两部分存活的对象放入S0区，

如此反复，下一次GC范围是eden区和S0区，一句话每次GC范围是eden区+一个S区。

（比例是，eden：s1:s0=80%:10%:10%=8:1:1）这里的eden区（80%） 和其中的一个  S区（10%） 合起来共占据90%，

GC就是清理的他们，始终保持着其中一个  S  区是空留的，保证GC的时候复制存活的对象有个存储的地方。

这样做的好处是

高效！！！，GC 算法总体就是三种：1 复制  2 标记  3标记整理，

垃圾回收算法将这几种选择起来相互组合。毫无疑问，只存在少量存活的对象，

只需复制少量存活的对象，远远比标记和标记整理高效多。

## 6-5：老年代

年老代主要存放JVM认为生命周期比较长的对象

（经过几次的Young Gen的垃圾回收后仍然存在），

内存大小相对会比较大，垃圾回收也相对没有那么频繁（譬如可能几个小时一次）。

年老代主要采用压缩的方式来避免内存碎片（将存活对象移动到内存片的一边，也就是内存整理）。

当然，有些垃圾回收器（譬如CMS垃圾回收器）出于效率的原因，可能会不进行压缩。

## 6-6：持久代

持久代主要存放类定义、字节码和常量等很少会变更的信息。

# 7. HotSpot虚拟机对象

## 7-1：说⼀下Java对象的创建过程

Step1:类加载检查
虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。

Step2:分配内存
在类加载检查通过后，接下来虚拟机将为新生对象分配内存。对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆���划分出来。分配方式有 “指针碰撞” 和 “空闲列表” 两种，选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。

内存分配的两种方式：（补充内容，需要掌握）

选择以上两种方式中的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存是否规整，取决于 GC 收集器的算法是"标记-清除"，还是"标记-整理"（也称作"标记-压缩"），值得注意的是，复制算法内存也是规整的

内存分配的两种方式

内存分配并发问题（补充内容，需要掌握）

在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全：

CAS+失败重试： CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性。
TLAB： 为每一个线程预先在 Eden 区分配一块儿内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中的剩余内存或 TLAB 的内存已用尽时，再采用上述的 CAS 进行内存分配

Step3:初始化零值
内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。

Step4:设置对象头
初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。

Step5:执行 init 方法
在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从 Java 程序的视角来看，对象创建才刚开始，<init> 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 <init> 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。

## 7-2：内存分配的两种⽅式选择

分配⽅式有 “指针碰撞” 和 “空闲列表” 两种

选择以上两种⽅式中的哪⼀种，取决于 Java 堆内存是否规整。⽽ Java 堆内存是否规整，取决于 GC收集器的算法是"标记-清除"，还是"标记-整理"，

## 7-3：虚拟机如何保证线程安全

1. CAS+失败重试： 虚拟机采⽤ CAS 配上失败重试的⽅式保证更新操作的原⼦性。
2. TLAB： 为每⼀个线程预先在Eden区分配⼀块内存， JVM在给线程中的对象分配内存时，⾸先在TLAB分配，当对象⼤于TLAB中的剩余内存或TLAB的内存已⽤尽时，再采⽤上述的CAS进⾏内存分配

## 7-4：对象的访问定位有哪两种⽅式?

①使⽤句柄

   * 如果使⽤句柄的话，那么Java堆中将会划分出⼀块内存来作为句柄池， reference 中存储的就是对象的句柄地址，⽽句柄中包含了对象实例数据与类型数据各⾃的具体地址信息；
②直接指针

  * 如果使⽤直接指针访问，那么 Java 堆对象的布局中就必须考虑如何放置访问类型数据的相关信息，⽽reference 中存储的直接就是对象的地址


## 7-5：访问定位两种方式的优缺点

1. 使⽤句柄来访问的最⼤好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，⽽ reference 本身不需要修改。
2. 使⽤直接指针访问⽅式最⼤的好处就是速度快，它节省了⼀次指针定位的时间开销。

## 7-6：对象分配规则

1. 对象优先分配在Eden区，如果Eden区没有足够的空间时，虚拟机执行一次Minor GC。

2. 大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在Eden区和两个Survivor区之间发生大量的内存拷贝（新生代采用复制算法收集内存）。

3. 长期存活的对象进入老年代。虚拟机为每个对象定义了一个年龄计数器，如果对象经过了1次Minor GC那么对象会进入Survivor区，之后每经过一次Minor GC那么对象的年龄加1，知道达到阀值对象进入老年区。

4. 动态判断对象的年龄。如果Survivor区中相同年龄的所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象可以直接进入老年代。

5. 空间分配担保。每次进行Minor GC时，JVM会计算Survivor区移至老年区的对象的平均大小，如果这个值大于老年区的剩余值大小则进行一次Full GC，如果小于检查HandlePromotionFailure设置，如果true则只进行Monitor GC,如果false则进行Full GC。 


# 8.内存泄露与内存溢出

## 8-1：什么是内存泄漏

指一个不再被程序使用的对象或变量一直被占据在内存中。 

## 8-2：什么是内存溢出

指程序申请内存时，没有足够的内存供申请者使用，或者说，给了你一块存储int类型数据的存储空间，但是你却存储long类型的数据，那么结果就是内存不够用，

## 8-3：内存溢出， 内存泄漏区别？

1. 内存泄露积累起来将导致内存溢出。

2. 内存泄露可以通过完善代码来避免； 内存溢出可以通过调整配置来减少发生频率， 但无法彻底避免。

## 8-4：如何避免内存泄露、 溢出？

1. 尽早释放无用对象的引用。
2. 使用临时变量的时候， 让引用变量在退出活动域后自动设置为null， 暗示垃圾收集器来收集该对象， 防止发生内存泄露。
3. 程序进行字符串处理时， 尽量避免使用String， 而应使用StringBuffer， 因为每一个String对象都会独立占用内存一块区域

## 8-5：如何检测内存泄露？

可以通过一些性能监测分析工具， 如 JProfiler、 Optimizeit Profiler。

## 8-6：java中会存在内存泄露呢？什么时候发生

会存在内存泄露

但是也有几种情况会造成内存泄漏：

1. 静态集合类，容器中的对象在程序结束之前将不能被释放，从而造成内存泄漏。

2. 各种连接，如数据库连接、网络连接和IO连接等。只有连接被关闭后，垃圾回收器才会回收对应的对象。否则，将会造成大量的对象无法被回收，从而引起内存泄漏。

3. 变量不合理的作用域。一个变量的定义的作用范围大于其使用范围，很有可能会造成内存泄漏。

4. 内部类持有外部类，由于内部类持有外部类的实例对象，这个外部类对象将不会被垃圾回收，这也会造成内存泄露。

5. 改变哈希值，造成内存泄露

## 8-7：什么情况下会发生堆内存溢出，栈内存溢出

栈溢出(StackOverflowError)

栈是线程私有的，他的生命周期与线程相同，

每个方法在执行的时候都会创建一个栈帧，用来存储局部变量表，操作数栈，动态链接，方法出口灯信息。

局部变量表又包含基本数据类型，对象引用类型（局部变量表编译器完成，运行期间不会变化）

栈溢出就是方法执行是创建的栈帧超过了栈的深度。那么最有可能的就是方法递归调用产生这种结果。

堆溢出(OutOfMemoryError:java heap space)

堆中主要存储的是对象。如果不断的new对象则会导致堆中的空间溢出

```java
public class Test {

    public void testHeap(){
        for(;;){
              ArrayList list = new ArrayList (2000);
          }
    }
    int num=1;
    public void testStack(){
        num++;
        this.testStack();
     }
    
    public static void main(String[] args){
        Test  t  = new Test ();
        t.testHeap();
        t.testStack();   
    }
}
```

# 9.调优工具

## 9-1：调优工具有哪些？

常用调优工具分为两类

1. jdk自带监控工具：jconsole和jvisualvm，
2. 第三方监控工具：MAT(Memory Analyzer Tool)、GChisto。

jconsole，在JDK中自带的java监控和管理控制台，用于对JVM中内存，线程和类等的监控

jvisualvm，jdk自带全能工具，可以分析内存快照、线程快照；监控内存变化、GC变化等。

MAT，一个基于Eclipse的内存分析工具，是一个快速、功能丰富的Java heap分析工具，它可以帮助我们查找内存泄漏和减少内存消耗

GChisto，一款专业分析gc日志的工具


# 10.JVM进程有哪些线程启动? (拼多多)

1. main主线程，执行我们指定的启动类的main方法
2. Reference Handler处理引 用的线程，用于处理引用对象本身(软引用、弱引用、虚引用)的垃圾回收问题
3. Finalizer调用对象的finalize方法的线程，就是垃圾回收的线程
4. Signal Dispatcher分发处理发送给JVM信号的线程
5. Attach Listener负责接收外部的命令的线程

# 11.jvm启动模式之client 与server

jvm启动时，通过-server 或-client参数指定启动模式。

(1)编译器方面:
当虚拟机运行在client 模式时，使用的是一一个代号为 c1的轻量级编译器，而server模式启动时，虚拟机采用的是相对重量级，代号为c2的编译器: c2编译器比cl编译器编译的相对彻底，服务起来之后，性能高。

(2)gc方面:
cilent模式下的新生代(Serial 收集器)和老年代(Serial Old)选择的是串行gc server模式下的新生代选择并行回收ge,老年代选择并行ge

(3)启动方面:
client模式启动快，编译快，内存占用少，针对桌面应用程序设计，优化客户端环境的启动时间。server模式启动慢，编译更完全，编译器是自适应编译器，效率高，针对服务端应用设计，优化服务器环境的最大化程序执行速度

# 12.简述JVM中静态分派和动态分派(引申:重载和重写)。

1.静态分派:依赖静态类型定位方法的分派，发生在编译时期，奥型应用为方法的秋.
(重载的参数是通过静态类型确定的，直接调用父类)
2、动态分配:在运行时期根据实际类型来确定方法的分派，发生在程序运行时，
典型应用
是方法的重写，也是多态的一种体现。 根据转型来确定是否调用父类还是子类的方法。
虚方法和非虚方法:
(1)非虚方法(所有statie方法+final/private方法)通过invokespecial指令调用，对这个
非虚方法的符号引用将转为对应的直接引用，即转为直接引用方法，在编译完成时就确定唯
一的调用方法。
(2)虚方法是通过invokevirtual 指令调用，且会有静态或者动态分派分派。具体先根据编
译期时方法接收者和方法参数的静态类型来分派，再在运行期根据只根据方法接收者的实际
类型来分派。
 

