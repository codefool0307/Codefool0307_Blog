<!-- TOC -->

- [1.线程与进程](#1线程与进程)
  - [1-1：什么是进程](#1-1什么是进程)
  - [1-2：何为线程?](#1-2何为线程)
  - [1-3：线程与进程的区别](#1-3线程与进程的区别)
  - [1-4：进程的通信方式](#1-4进程的通信方式)
  - [1-5：并发级别](#1-5并发级别)
  - [1-6：happen-before原则是什么](#1-6happen-before原则是什么)
- [2.什么是上下⽂切换?](#2什么是上下切换)
- [3.线程死锁](#3线程死锁)
  - [3-1：什么是线程死锁](#3-1什么是线程死锁)
  - [3-2：产生死锁的条件](#3-2产生死锁的条件)
  - [3-3：如何解决线程死锁问题](#3-3如何解决线程死锁问题)
- [4.synchronized关键字](#4synchronized关键字)
  - [4-1：synchronized关键字理解](#4-1synchronized关键字理解)
  - [4-2：JDK1.6优化有哪些？](#4-2jdk16优化有哪些)
  - [4-3：底层原理](#4-3底层原理)
  - [4-4：谈谈 synchronized和ReentrantLock 的区别](#4-4谈谈-synchronized和reentrantlock-的区别)
  - [4-5：Lock和synchronized的区别](#4-5lock和synchronized的区别)
  - [4-6：synchronized的优势](#4-6synchronized的优势)
  - [4-7：synchronized锁的膨胀过程（升级过程）](#4-7synchronized锁的膨胀过程升级过程)
  - [4-8：那如何判断共享数据不会被线程竞争？](#4-8那如何判断共享数据不会被线程竞争)
- [5.volatile关键字](#5volatile关键字)
  - [5-1：为什么要是用volatile关键字](#5-1为什么要是用volatile关键字)
  - [5-2：为什么其他线程能感知到变量更新](#5-2为什么其他线程能感知到变量更新)
  - [5-3：volatile为什么不保证原子性吗？](#5-3volatile为什么不保证原子性吗)
  - [5-4：怎么保证输出结果是20000呢？](#5-4怎么保证输出结果是20000呢)
  - [5-5：为什么要重排](#5-5为什么要重排)
  - [5-6： 有哪几种重排](#5-6-有哪几种重排)
  - [5-7：举例说一下指令重排](#5-7举例说一下指令重排)
  - [5-8： volatile怎么实现禁止指令重排？](#5-8-volatile怎么实现禁止指令重排)
  - [5-9：volatile都不保证原子性，为啥我们还要用它？](#5-9volatile都不保证原子性为啥我们还要用它)
  - [5-10：synchronized 关键字和 volatile 关键字的区别](#5-10synchronized-关键字和-volatile-关键字的区别)
- [6.并发基础](#6并发基础)
  - [6-1：并发特性](#6-1并发特性)
  - [6-2：并发级别](#6-2并发级别)
  - [6-3：快速失败与安全失败](#6-3快速失败与安全失败)
  - [6-4：说说并发与并⾏的区别?](#6-4说说并发与并的区别)
  - [6-5：为什么要使⽤多线程呢?](#6-5为什么要使多线程呢)
  - [6-6：使⽤多线程可能带来什么问题?](#6-6使多线程可能带来什么问题)
  - [6-7：线程的生命周期和状态](#6-7线程的生命周期和状态)
  - [6-8：一般线程和守护线程的区别](#6-8一般线程和守护线程的区别)
  - [6-9：多线程公共用一个数据注意什么](#6-9多线程公共用一个数据注意什么)
  - [6-10：如何确保 N 个线程可以访问 N 个资源同时又不导致死锁？](#6-10如何确保-n-个线程可以访问-n-个资源同时又不导致死锁)
- [7.创建线程方式](#7创建线程方式)
- [8.线程基本操作与线程协作](#8线程基本操作与线程协作)
  - [8-1：说说 sleep() ⽅法和 wait() ⽅法区别和共同点?](#8-1说说-sleep-法和-wait-法区别和共同点)
  - [8-2：yield join notify notifyAll](#8-2yield-join-notify-notifyall)
  - [8-3：为什么我们调⽤ start() ⽅法时会执⾏ run() ⽅法，为什么我们不能直接调⽤run() ⽅法？](#8-3为什么我们调-start-法时会执-run-法为什么我们不能直接调run-法)
  - [8-4：中断线程方法](#8-4中断线程方法)
- [9.线程同步](#9线程同步)
- [10.线程池](#10线程池)
  - [10-1：ThreadLocal内存泄露问题](#10-1threadlocal内存泄露问题)
  - [10-2：使⽤线程池的好处](#10-2使线程池的好处)
  - [10-3：常规实现线程池方法](#10-3常规实现线程池方法)
  - [10-4：线程池增长策略](#10-4线程池增长策略)
  - [10-5：线程池拒绝策略](#10-5线程池拒绝策略)
  - [10-6：BlockingQueue](#10-6blockingqueue)
  - [10-7：实现Runnable接⼝和Callable接⼝的区别](#10-7实现runnable接和callable接的区别)
  - [10-8：实现 Runnable 接口比继承 Thread 类所具有的优势](#10-8实现-runnable-接口比继承-thread-类所具有的优势)
  - [10-9：执⾏execute()⽅法和submit()⽅法的区别是什么呢？](#10-9执execute法和submit法的区别是什么呢)
- [11.Atomic原子类](#11atomic原子类)
  - [11-1：什么是原子类](#11-1什么是原子类)
  - [11-2：原子类的作用？](#11-2原子类的作用)
  - [11-3：i++自增操作不是原子性的，如何决绝原子性问题](#11-3i自增操作不是原子性的如何决绝原子性问题)
  - [11-4：CAS](#11-4cas)
  - [11-5：CAS的ABA问题](#11-5cas的aba问题)
  - [11-6：基本数据类型原子类的优势](#11-6基本数据类型原子类的优势)
- [12.AQS](#12aqs)
  - [12-1：对AQS原理分析](#12-1对aqs原理分析)
  - [12-2：AQS 对资源的共享⽅式](#12-2aqs-对资源的共享式)
  - [12-3：AQS 组件](#12-3aqs-组件)
- [13.锁](#13锁)
  - [13-1：锁](#13-1锁)
  - [13-2：乐观锁与悲观锁](#13-2乐观锁与悲观锁)
  - [13-3：两种锁的使用场景](#13-3两种锁的使用场景)
  - [13-4：乐观锁常见的两种实现方式](#13-4乐观锁常见的两种实现方式)
  - [13-5：乐观锁的缺点](#13-5乐观锁的缺点)
  - [15-6：自旋锁](#15-6自旋锁)
  - [13-7：自旋锁的优缺点](#13-7自旋锁的优缺点)
  - [13-8：自旋锁的升级——自适应自旋](#13-8自旋锁的升级自适应自旋)
  - [13-9：自旋锁使用场景](#13-9自旋锁使用场景)
  - [13-10：可重入锁（递归锁）](#13-10可重入锁递归锁)
  - [13-11：可重入锁使用场景](#13-11可重入锁使用场景)
  - [13-12：可重入锁如果加了两把，但是只释放了一把会出现什么问题？](#13-12可重入锁如果加了两把但是只释放了一把会出现什么问题)
  - [13-13：如果只加了一把锁，释放两次会出现什么问题？](#13-13如果只加了一把锁释放两次会出现什么问题)
  - [13-14：读写锁](#13-14读写锁)
  - [13-15：公平锁](#13-15公平锁)
  - [13-16：非公平锁](#13-16非公平锁)
  - [13-17：公平锁与非公平锁优缺点](#13-17公平锁与非公平锁优缺点)
  - [13-18：公平锁与非公平锁使用场景](#13-18公平锁与非公平锁使用场景)
  - [13-19：共享锁](#13-19共享锁)
  - [13-20：共享锁使用场景](#13-20共享锁使用场景)
  - [13-21：独占锁](#13-21独占锁)
  - [13-22：独占锁使用场景](#13-22独占锁使用场景)
  - [13-23：重量级锁](#13-23重量级锁)
  - [13-24：重量级锁使用场景](#13-24重量级锁使用场景)
  - [13-25：轻量级锁](#13-25轻量级锁)
  - [13-26：轻量级锁优缺点](#13-26轻量级锁优缺点)
  - [13-27：偏向锁](#13-27偏向锁)
  - [13-28：偏向锁优缺点](#13-28偏向锁优缺点)
  - [13-29：分段锁](#13-29分段锁)
  - [13-30：互斥锁](#13-30互斥锁)
  - [13-31：同步锁](#13-31同步锁)
  - [13-32：死锁](#13-32死锁)
  - [13-33：锁粗化](#13-33锁粗化)
  - [13-34：锁消除](#13-34锁消除)
- [15.并发容器](#15并发容器)
  - [15-1：JDK 提供的并发容器总结](#15-1jdk-提供的并发容器总结)
  - [15-2：CopyOnWriteArrayList 是如何做到的？](#15-2copyonwritearraylist-是如何做到的)

<!-- /TOC -->


# 1.线程与进程

## 1-1：什么是进程

系统运行一个程序，从创建，运行到消亡的过程这个是一个进程

## 1-2：何为线程?

线程是进程内的一个执行单元

## 1-3：线程与进程的区别

1. 拥有资源
   进程是资源分配的基本单位，虽然线程不拥有资源，线程可以访问隶属进程的资源

2. 调度
   线程是独立调度的基本单位

3. 系统开销
   创建或者撤销进程的开销大于线程的开销

4. 通信方面
   线程间可以通过读写进行通信，进程通信需要PIC

## 1-4：进程的通信方式

1. 管道

管道分为有名管道和无名管道,无名管道数据只能单向流动,而且只能在具有亲缘关系的进程间使用;有名管道也是一种半双工的通信方式,但是它允许无亲缘关系进程间的通信。

2. 信号量

信号量是一个计数器,可以用来控 制多个线程对共享资源的访问.它常作为一种锁机制,防止某进程在访问资源时其它进程也访问该资源.因此,主要作为进程间以及同一个进程内不同线程之间的同步手段.

3. 信号

信号是一种比较复杂的通信方式,用于通知接收进程某个事件已经发生.

4. 消息队列

消息队列是消息的链表,存放在内核中并由消息队列标识符标识.消息队列克服了信号传递信息少,管道只能承载无格式字节流以及缓冲区大小受限等特点.

5. 共享内存

共享内存就是映射一段能被其他进程所访问的内存,这段共享内存由一个进程创建,但多个进程都可以访问.

6. 套接字：可用于不同及其间的进程通信

## 1-5：并发级别

书本

## 1-6：happen-before原则是什么

书本

# 2.什么是上下⽂切换?

当前任务在执⾏完 CPU时间⽚ 切换到另⼀个任务 之前 会先保存⾃⼰的状态，以便下次再切换回这个任务时，可以再加载这个任务的状态。 任务从保存到再加载的过程就是⼀次上下⽂切换。

# 3.线程死锁

## 3-1：什么是线程死锁

多个线程同时被阻塞，它们中的⼀个或者全部都在等待某个资源被释放。由于线程被⽆限期地阻塞，因此程序不可能正常终⽌。

## 3-2：产生死锁的条件

1. 该资源任意⼀个时刻只由⼀个线程占⽤。
2. ⼀个进程因请求资源⽽阻塞时，对已获得的资源保持不放。
3. 线程已获得的资源在末使⽤完之前不能被其他线程强⾏剥夺，只有⾃⼰使⽤完毕后才释放资源。
4. 若⼲进程之间形成⼀种头尾相接的循环等待资源关系。

## 3-3：如何解决线程死锁问题

1. ⼀次性申请所有的资源。
2. 占⽤部分资源的线程进⼀步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
3. 靠按序申请资源来预防。按某⼀顺序申请资源，释放资源则反序释放。破坏循环等待条件。

# 4.synchronized关键字

## 4-1：synchronized关键字理解

1. 解决的是多个线程之间访问资源的同步性，synchronized关键字可以保证被它修饰的⽅法或者代码块在任意时刻只能有⼀个线程执
   ⾏。
2. 在Java早期版本中， synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的 Mutex Lock 来实现的， Java 的线程是映射到操
   作系统的原⽣线程之上的。如果要挂起或者唤醒⼀个线程，都需要操作系统帮忙完成，⽽操作系统实现线程之间的切换时需要从⽤户态转换到内核态，这个状态之间的转换需要相对⽐较⻓的时间，时间成本相对较⾼，但是在JDK1.6对锁的实现引⼊了⼤量的优化，如⾃旋锁、适应性⾃旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。

## 4-2：JDK1.6优化有哪些？

JDK1.6 对锁的实现引⼊了⼤量的优化，如偏向锁、轻量级锁、⾃旋锁、适应性⾃旋锁、锁消除、锁粗化等技术来减少锁操作的开销。

1. 偏向锁

引入偏向锁的目是为了没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。但是不同是：轻量级锁在无竞争的情况下使用 CAS 操作去代替
使用互斥量。而偏向锁在无竞争的情况下会把整个同步都消除掉。

2. 轻量级锁

轻量级锁不是为了代替重量级锁，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗，因为使用轻量级锁时，不需要申请互斥量。

如果没有竞争，轻量级锁使用CAS操作避免了使用互斥操作的开销。但如果存在锁竞争，除了互斥量开销外，还会额外发生CAS操作，因此在有锁竞争的情况下，轻量级锁比传统的重量级锁更慢！如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁！

3. 自旋锁和自适应自旋

一般线程持有锁的时间都不是太长，所以仅仅为了这一点时间去挂起线程/恢复线程是得不偿失的。为了让一个线程等待，我们只需要让线程执行一个忙循环（自旋）也就是自旋。


另外,在 JDK1.6 中引入了自适应的自旋锁。自适应的自旋锁带来的改进就是：自旋的时间不在固定了，而是和前一次同一个锁上的自旋时间以及锁的拥有者的状态来决定。

4. 锁消除

就是把锁干掉。当Java虚拟机运行时发现有些共享数据不会被线程竞争时就可以进行锁消除。

5. 锁粗化

如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作都是出现在循环体体之中，就算真的没有线程竞争，频繁地进行互斥同步操作将会导致不必要的性能
损耗，所以就采取了一种方案：把加锁的范围扩展（粗化）到整个操作序列的外部，这样加锁解锁的频率就会大大降低，从而减少了性能损耗。
   
## 4-3：底层原理

每个对象都有个 monitor 对象， 加锁就是在竞争 monitor 对象，代码块加锁是在代码块前后分别加上 monitorenter 和 monitorexit 指令来实现的，方法加锁是通过一个标记位来判断的。

## 4-4：谈谈 synchronized和ReentrantLock 的区别

1. 两者都是可重入锁

自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的。

2. synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API

3. ReentrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。

4. ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。ReentrantLock默认情况是非公平的，可以通过 ReentrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。

5. synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类借助于
   Condition接口与newCondition() 方法。 在使用notify()/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” ，

## 4-5：Lock和synchronized的区别

1. Lock需要手动获取锁和释放锁。
2. Lock 是一个接口，而 synchronized 是 Java 中的关键字， synchronized 是内置的语言实现。
3. synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁，则很可能造成死
   锁现象，因此使用 Lock 时需要在 finally 块中释放锁。
4. Lock 可以让等待锁的线程响应中断，而 synchronized 却不行，使用 synchronized 时，等待的线程会一直等待下去，不能够响应中断。
5. 通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。
6. Lock 可以通过实现读写锁提高多个线程进行读操作的效率。

## 4-6：synchronized的优势

1. 只需要基础的同步功能时，用synchronized。

2. Lock应该确保在finally块中释放锁。如果使用synchronized，JVM确保即使出现异常，锁也能被自动释放。

3. 使用Lock时，Java虚拟机很难得知哪些锁对象是由特定线程锁持有的。

## 4-7：synchronized锁的膨胀过程（升级过程）

1. 整个膨胀过程在自旋下完成；

2. mark->has_monitor()方法判断当前是否为重量级锁，即Mark Word的锁标识位为 10，如果当前状态为重量级锁，执行步骤（3），否则执行步骤（4）；

3. mark->monitor()方法获取指向ObjectMonitor的指针，并返回，说明膨胀过程已经完成；

4. 如果当前锁处于膨胀中，说明该锁正在被其它线程执行膨胀操作，则当前线程就进行自旋等待锁膨胀完成，这里需要注意一点，虽然是自旋操作，但不会一直占用cpu资
   源，每隔一段时间会通过os::NakedYield方法放弃cpu资源，或通过park方法挂起；如果其他线程完成锁的膨胀操作，则退出自旋并返回；

5. 如果当前是轻量级锁状态，即锁标识位为 00，膨胀过程如下：

    通过omAlloc方法，获取一个可用的ObjectMonitor monitor，并重置monitor数据；
    通过CAS尝试将Mark Word设置为markOopDesc:INFLATING，标识当前锁正在膨胀中，如果CAS失败，说明同一时刻其它线程已经将Mark Word设置为
    markOopDesc:INFLATING，当前线程进行自旋等待膨胀完成；
    如果CAS成功，设置monitor的各个字段：_header、_owner和_object等，并返回；

6. 如果是无锁，重置监视器值；

## 4-8：那如何判断共享数据不会被线程竞争？

利用逃逸分析技术：分析对象的作用域，如果对象在A方法中定义后，被作为参数传递到B方法中，则称为方法逃逸；如果被其他线程访问，则称为线程逃逸。

在堆上的某个数据不会逃逸出去被其他线程访问到，就可以把它当作栈上数据对待，认为它是线程私有的，同步加锁就不需要了。

# 5.volatile关键字

## 5-1：为什么要是用volatile关键字

目前的 Java 内存模型下，线程可以把变量保存本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。

要解决这个问题，就需要把变量声明为volatile，这就指示JVM，这个变量是不稳定的，每次使用它都到主存中进行读取。

volatile 关键字的主要作用就是保证变量的可见性然后还有一个作用是防止指令重排序。

## 5-2：为什么其他线程能感知到变量更新

当多个CPU持有的缓存都来自同一个主内存的拷贝，当有其他CPU偷偷改了这个主内存数据后，其他CPU并不知道，那拷贝的内存将会和主内存不一致，那我们为了保证缓存一致，这里就需要操作系统来共同制定一个同步规则来保证，而这个规则就有MESI协议。

当CPU写数据时，如果发现操作的变量是共享变量，即在其它CPU中也存在该变量的副本，系统会发出信号通知其它CPU将该内存变量的缓存行设置为无效。

当其它CPU读取这个变量的时，发现自己缓存该变量的缓存行是无效的，那么它就会从内存中重新读取。

为了让其他CPU是怎么知道要将缓存更新为失效的，这里是用到了总线嗅探技术。

每个CPU不断嗅探总线上传播的数据来检查自己缓存值是否过期了，如果处理器发现自己的缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置为无效状态，当处理器对这个数据进行修改操作的时候，会重新从内存中把数据读取到处理器缓存中。

## 5-3：volatile为什么不保证原子性吗？

比如说，当20个线程同时给number自增1，执行1000次以后，单线程情况下，肯定是20000，但是在多线程情况下，执行了某个指令number的值取到操作栈顶时，volatile关
键字保证了number的值在此时是正确的，但是在执行压栈等指令的时候，其他线程可能已经把number的值改变了，而操作栈顶的值就变成了过期的数据，就可能把较小的
number值同步回主内存之中。

## 5-4：怎么保证输出结果是20000呢？

1. synchronized同步代码块

我们可以通过使用synchronized同步代码块来保证原子性。

但是使用synchronized太重了，会造成阻塞，只有一个线程能进入到这个方法。

我们可以使用Java并发包（JUC）中的AtomicInterger工具包。

2. AtomicInterger原子性操作

两个线程，线程1和线程2都有主内存中变量的拷贝，值都等于10

线程1想要将值更新为20，先要将工作内存中的变量值与主内存中的变量进行比较，值都等于10，所以可以将主内存中的值替换成20

线程1将主内存中的值替换成20，并将线程1中的工作内存中的副本更新为20

线程2想要将变量更新为30，先要将线程2的工作内存中的值与主内存进行比较10不等于20，所以不能更新

线程2将工作内存的副本更新为与主内存一致：20

## 5-5：为什么要重排

计算机在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。

## 5-6： 有哪几种重排

1. 编译器优化重排：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。

2. 指令级的并行重排：现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。

3. 内存系统的重排：由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

## 5-7：举例说一下指令重排

定义了变量num=0和变量flag=false，线程1调用初始化函数init()执行后，线程调用add()方法，当另外线程判断flag=true后，执行num+100操作，那么我们预期的结果是num会等于101，但因为有指令重排的可能，num=1和flag=true执行顺序可能会颠倒，以至于num可能等于100

## 5-8： volatile怎么实现禁止指令重排？

在volatile生成的指令序列前后插入内存屏障来禁止处理器重排序。

volatile写的场景

在每个volatile写操作的前面插入一个StoreStore屏障（写-写 屏障）。

在每个volatile写操作的后面插入一个StoreLoad屏障（写-读 屏障）。

volatile读场景

在每个volatile读操作的后面插入一个LoadLoad屏障（读-读 屏障）。

在每个volatile读操作的后面插入一个LoadStore屏障（读-写 屏障）。

## 5-9：volatile都不保证原子性，为啥我们还要用它？

1. volatile是轻量级的同步机制，对性能的影响比synchronized小。

  * 比如线程试图通过类似于数绵羊的传统方法进入休眠状态，为了使这个示例能正确执行，asleep必须为volatile变量。否则，当asleep被另一个线程修改时，执行判断
  的线程却发现不了。

2. 因为synchorized和lock是排他锁（悲观锁），如果有多个线程需要访问这个变量，将会发生竞争，只有一个线程可以访问这个变量，其他线程被阻塞了，会影响程序的
   性能。


## 5-10：synchronized 关键字和 volatile 关键字的区别

1. volatile关键字是线程同步的轻量级实现，但是volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块。
   synchronized关键字在1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，实际开发中使用 synchronized 关键字的场景还是更多一些。

2. 多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞

3. volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。

4. volatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized关键字解决的是多个线程之间访问资源的同步性。


# 6.并发基础

## 6-1：并发特性

1. 原子性 : 要么所有的操作都执行，要么都不执行。
2. 可见性 ：当一个变量对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。
3. 有序性 ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。
            volatile 关键字可以禁止指令进行重排序优化。

## 6-2：并发级别

## 6-3：快速失败与安全失败

## 6-4：说说并发与并⾏的区别?
1. 并发： 同⼀时间段，多个任务都在执⾏；
2. 并⾏： 单位时间内，多个任务同时执⾏。

## 6-5：为什么要使⽤多线程呢?

1. 线程间的切换和调度的成本远远⼩于进程。减少了线程上下⽂切换的开销。
2. 现在的系统动不动就要求百万级甚⾄千万级的并发量，⽽多线程并发编程正是开发⾼并发系统的基础，利⽤好多线程机制可以⼤⼤提⾼系统整体的并发能⼒以及性能。
3. 发挥多核 CPU 的优势
4. 防止阻塞

## 6-6：使⽤多线程可能带来什么问题?

并发编程的⽬的就是为了能提⾼程序的执⾏效率提⾼程序运⾏速度，但是并发编程并不总是能提⾼程序运⾏速度的，⽽且并发编程可能会遇到很多题，⽐如：内存泄漏、上下⽂切换、死锁还有受限于硬件和软件的资源闲置问题。

## 6-7：线程的生命周期和状态

1. 新建状态（New） ： 新创建了一个线程对象。
2. 就绪状态（Runnable） ： 线程对象创建后， 其他线程调用了该对象的 start()方法。该状态的线程位于可运行线程池中， 变得
   可运行， 等待获取 CPU 的使用权。
3. 运行状态（Running） ： 就绪状态的线程获取了 CPU， 执行程序代码。
4. 阻塞状态（Blocked） ： 阻塞状态是线程因为某种原因放弃 CPU 使用权， 暂时停止运行。 直到线程进入就绪状态， 才有机会
   转到运行状态。 阻塞的情况分三种：
5. 死亡状态（Dead） ： 线程执行完了或者因异常退出了 run()方法， 该线程结束生命周期

## 6-8：一般线程和守护线程的区别

所谓守护线程是指在程序运行的时候在后台提供一种通用服务的线程， 比如垃圾回收线程就是一个很称职的守护者， 并且这种线程并不属于程序中不可或缺的部分。 因 此，当所有的非守护线程结束时， 程序也就终止了， 同时会杀死进程中的所有守护线程。 反过来说， 只要任何非守护线程还在运行， 程序就不会终止。

区别：
为守护线程是 JVM 自动创建的线程， 用户线程是程序创建的线程； 比如 JVM的垃圾回收线程是一个守护线程， 当所有线程已经撤离， 不再产生垃圾， 守护线程自然就没事可干了， 当垃圾回收线程是 Java 虚拟机上仅剩的线程时， Java 虚拟机会自动离开。


## 6-9：多线程公共用一个数据注意什么

1. 当我们在线程对象( Runnable )中定义了全局变量, run方法会修改该变量时,如果有多个线程同时使用刻线程对象, 那么就会造成全局变量的值被同时修改,造成错误
2. ThreadLocal是JDK引入的一种机制,它用于解决线程间共享变量,使用ThreadLocal声明的变量，即使在线程中属于全局变量,针对每个线程来讲,这个变量也是独立的。
3. volatile变量每次被线程访问时,都强迫线程从主内存中重读该变量的最新值,而当该变量发生修改变化时,也会强迫线程将最新的值刷新回主内存中。这样一来 ,不同的线程都能及时的看到该变量的最新值。

## 6-10：如何确保 N 个线程可以访问 N 个资源同时又不导致死锁？
1. 加锁顺序（线程按照一定的顺序加锁）
2. 加锁时限（线程尝试获取锁的时候加上一定的时限， 超过时限则放弃对该锁的请求，并释放自己占有的锁）
3. 死锁检测


# 7.创建线程方式


# 8.线程基本操作与线程协作

## 8-1：说说 sleep() ⽅法和 wait() ⽅法区别和共同点?

1. sleep ⽅法没有释放锁，⽽ wait ⽅法释放了锁 。
2. 两者都可以暂停线程的执⾏。
3. Wait 通常被⽤于线程间交互/通信， sleep 通常被⽤于暂停执⾏。
4. wait() ⽅法被调⽤后，线程不会⾃动苏醒，需要别的线程调⽤同⼀个对象上的 notify() 或notifyAll() ⽅法。 sleep() ⽅法执⾏完成后，线程会⾃动苏醒。或者可以使⽤ wait(longtimeout)超时后线程会⾃动苏醒。

## 8-2：yield join notify notifyAll

1. yield()方法是停止当前线程， 让同等优先权的线程或更高优先级的线程有执行的机会。如果没有的话， 那么 yield()方法将不会起作用， 并且由可执行状态后马上又被执行。

2. join 方法是用于在某一个线程的执行过程中调用另一个线程执行， 等到被调用的线程执行结束后， 再继续执行当前线程。 如： t.join();//主要用于等待 t 线程运行结束， 若无此句，main 则会执行完毕， 导致结果不可预测。

3. notify 方法只唤醒一个等待（对象的） 线程并使该线程开始执行。 所以如果有多个线程等待一个对象， 这个方法只会唤醒其中一个线程， 选择哪个线程取决于操作系统对多线程管理的实现。

4. notifyAll 会唤醒所有等待(对象的)线程， 尽管哪一个线程将会第一个处理取决于操作系统的实现


## 8-3：为什么我们调⽤ start() ⽅法时会执⾏ run() ⽅法，为什么我们不能直接调⽤run() ⽅法？

new ⼀个 Thread，线程进⼊了新建状态;调⽤ start() ⽅法，会启动⼀个线程并使线程进⼊了就绪状态，当分配到时间⽚后就可以开
始运⾏了。 start() 会执⾏线程的相应准备⼯作，然后⾃动执⾏run() ⽅法的内容，这是真正的多线程⼯作。 ⽽直接执⾏ run() ⽅
法，会把 run ⽅法当成⼀个 main线程下的普通⽅法去执⾏，并不会在某个线程中执⾏它，所以这并不是多线程⼯作。

## 8-4：中断线程方法 
1. 使用退出标志， 使线程正常退出， 也就是当 run 方法完成后线程终止。 
2. 通过 return 退出 run 方法
3. 通过对有些状态中断抛异常退出thread.interrupt() 中断。 
4. 使用 stop 方法强行终止线程（过期）

# 9.线程同步

# 10.线程池

## 10-1：ThreadLocal内存泄露问题

ThreadLocalMap 中使⽤的 key 为 ThreadLocal 的弱引⽤,⽽ value 是强引⽤。所以，如ThreadLocal 没有被外部强引⽤的情况下，在垃圾回收的时候， key 会被清理掉，⽽ value 不会被清理掉。这样⼀来， ThreadLocalMap 中就会出现key为null的Entry。假如我们不做任何措施的话，value 永远⽆法被GC 回收，这个时候就可能会产⽣内存泄露。 ThreadLocalMap实现中已经考虑了这种情况，在调⽤ set() 、 get() 、 remove() ⽅法的时候，会清理掉 key 为 null 的记录。使⽤完ThreadLocal ⽅法后 最好⼿动调⽤ remove() ⽅法

## 10-2：使⽤线程池的好处

1. 降低资源消耗。通过重复利⽤已创建的线程降低线程创建和销毁造成的消耗。
2. 提⾼响应速度。当任务到达时，任务可以不需要的等到线程创建就能⽴即执⾏。
3. 提⾼线程的可管理性。线程是稀缺资源，如果⽆限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使⽤线程池可以进⾏统⼀的分配，调优和监控。

## 10-3：常规实现线程池方法

## 10-4：线程池增长策略

## 10-5：线程池拒绝策略

## 10-6：BlockingQueue

## 10-7：实现Runnable接⼝和Callable接⼝的区别

Runnable ⾃Java 1.0以来⼀直存在，但 Callable 仅在Java 1.5中引⼊,⽬的就是为了来处理 Runnable
不⽀持的⽤例。 Runnable 接⼝不会返回结果或抛出检查异常，但是 Callable 接⼝可以。所以，如果
任务不需要返回结果或抛出异常推荐使⽤ Runnable 接⼝，这样代码看起来会更加简洁。

## 10-8：实现 Runnable 接口比继承 Thread 类所具有的优势
1. 适合多个相同的程序代码的线程去处理同一个资源 
2. 可以避免 java 中的单继承的限制 
3. 增加程序的健壮性， 代码可以被多个线程共享， 代码和数据独立
4. 线程池只能放入实现 Runable 或 callable 类线程， 不能直接放入继承 Thread 的类 
5. runnable 实现线程可以对线程进行复用， 因为 runnable 是轻量级的对象， 重复 new 不会耗费太大资源， 而 Thread 则不然， 它是重量级对象， 而且线程执行完就完了， 无法再次利用


## 10-9：执⾏execute()⽅法和submit()⽅法的区别是什么呢？

1. execute() ⽅法⽤于提交不需要返回值的任务，所以⽆法判断任务是否被线程池执⾏成功与否；
2. submit() ⽅法⽤于提交需要返回值的任务。线程池会返回⼀个 Future 类型的对象，通过这个Future 对象可以判断任务是否执⾏成功，并且可以通过 Future 的 get() ⽅法来获取返回值， get() ⽅法会阻塞当前线程直到任务完成，⽽使⽤ get（long timeout， TimeUnit unit） ⽅法则会阻塞当前线程⼀段时间后⽴即返回，这时候有可能任务没有执⾏完。


# 11.Atomic原子类

## 11-1：什么是原子类

原子操作是指不会被线程调度机制打断的操作，这种操作一旦开始，就一直运行到结束，中间不会有任何线程上下文切换。

原子操作可以是一个步骤，也可以是多个操作步骤，但是其顺序不可以被打乱，也不可以被切割而只执行其中的一部分，将整个操作视作一个整体是原子性的核心特征。

## 11-2：原子类的作用？

提供一种简单、性能高效、线程安全地更新一个变量的方式。

## 11-3：i++自增操作不是原子性的，如何决绝原子性问题

Atomic原子类就是来解决这个问题的，


## 11-4：CAS

CAS是比较并交换。比较变量的现在值与之前的值是否一致，若一致则替换，否则不替换。

CAS的作用：原子性更新变量值，保证线程安全。

需要有三个操作数，变量的当前值（V），旧的预期值（A），准备设置的新值（B）。

CAS指令执行条件：当且仅当V=A时，处理器才会设置V=B，否则不执行更新。

CAS的返回值：V的之前值。

CAS处理过程：原子操作，执行期间不会被其他线程中断，线程安全。

## 11-5：CAS的ABA问题




## 11-6：基本数据类型原子类的优势

多线程环境使用原子类保证线程安全（基本数据类型）

# 12.AQS

## 12-1：对AQS原理分析

如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的⼯作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占⽤，那么就需要⼀套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是⽤CLH队列锁实现的，即将暂时获取不到锁的线程加⼊到队列中。

## 12-2：AQS 对资源的共享⽅式

1. Exclusive（独占）：只有⼀个线程能执⾏，如ReentrantLock。⼜可分为公平锁和⾮公平锁：
   * 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁
   * ⾮公平锁：当线程要获取锁时，⽆视队列顺序直接去抢锁，谁抢到就是谁的
2. Share（共享）：多个线程可同时执⾏，如Semaphore/CountDownLatch。 Semaphore、
CountDownLatch、 CyclicBarrier、 ReadWriteLock 我们都会在后⾯讲到。

## 12-3：AQS 组件

Semaphore(信号量)-允许多个线程同时访问： synchronized 和 ReentrantLock 都是一次只允许一个线程访问某个资源，Semaphore(信号量)可以指定多个线程同时访问某个资源。
CountDownLatch （倒计时器）： CountDownLatch是一个同步工具类，用来协调多个线程之间的同步。这个工具通常用来控制线程等待，它可以让某一个线程等待直到倒计时结束，再开始执行。
CyclicBarrier(循环栅栏)： CyclicBarrier 和 CountDownLatch 非常类似，它也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。主要应用场景和 CountDownLatch 类似。CyclicBarrier 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier默认的构造方法是 CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await()方法告诉 CyclicBarrier 我已经到达了屏障，然后当前线程被阻塞。

# 13.锁

## 13-1：锁

| 序号 | 锁名称  | 应用                                                              |
|----|------|-----------------------------------------------------------------|
| 1  | 乐观锁  | CAS                                                             |
| 2  | 悲观锁  | synchronized、vector、hashtable                                   |
| 3  | 自旋锁  | CAS                                                             |
| 4  | 可重入锁 | synchronized、Reentrantlock、Lock                                 |
| 5  | 读写锁  | ReentrantReadWriteLock，CopyOnWriteArrayList、CopyOnWriteArraySet |
| 6  | 公平锁  | Reentrantlock(true)                                           |
| 7  | 非公平锁 | synchronized、reentrantlock(false)                             |
| 8  | 共享锁  | ReentrantReadWriteLock中读锁                                       |
| 9  | 独占锁  | synchronized、vector、hashtable、ReentrantReadWriteLock中写锁         |
| 10 | 重量级锁 | synchronized                                                    |
| 11 | 轻量级锁 | 锁优化技术                                                           |
| 12 | 偏向锁  | 锁优化技术                                                           |
| 13 | 分段锁  | concurrentHashMap                                               |
| 14 | 互斥锁  | synchronized                                                    |
| 15 | 同步锁  | synchronized                                                    |
| 16 | 死锁   | 相互请求对方的资源                                                       |
| 17 | 锁粗化  | 锁优化技术                                                           |
| 18 | 锁消除  | 锁优化技术                                                           |

## 13-2：乐观锁与悲观锁

1. 乐观锁

假定当前环境是读多写少，遇到并发写的概率比较低，读数据时认为别的线程不会正在进行修改也因此没有上锁。写数据时，判断当前与期望值是否相同，如果相同则进行
更新，更新期间加锁，保证是原子性的。

可以同时进行读操作，读的时候其他线程不能进行写操作。

2. 悲观锁

认为写多读少，遇到并发写的可能性高，每次去拿数据的时候都认为其他线程会修改，所以每次读写数据都会认为其他线程会修改，所以每次读写数据时都会上锁。其他线程想要读写这个数据时，会被这个线程block，直到这个线程释放锁然后其他线程获取到锁。

只能有一个线程进行读操作或者写操作，其他线程的读写操作均不能进行。

## 13-3：两种锁的使用场景

Java中的乐观锁：

CAS---比较并替换，比较当前值（主内存中的值），与预期值（当前线程中的值，主内存中值的一份拷贝）是否一样，一样则更新，否则继续进行CAS操作。

Java中的悲观锁： 

synchronized修饰的方法和方法块、ReentrantLock。

## 13-4：乐观锁常见的两种实现方式

乐观锁一般会使用版本号机制或CAS算法实现。

1. 版本号机制
一般是在数据表中加上一个数据版本号version字段，表示数据被修改的次数，当数据被修改时，version值会加一。当线程A要更新数据值时，在读取数据的同时也会读取
version值，在提交更新时，若刚才读取到的version值为当前数据库中的version值相等时才更新，否则重试更新操作，直到更新成功。

2. CAS算法

## 13-5：乐观锁的缺点

1. ABA 问题

JDK 1.5 以后的 AtomicStampedReference 类就提供了此种能力，其中的 compareAndSet 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标
志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

2. 循环时间长开销大

自旋CAS（也就是不成功就一直循环执行直到成功）如果长时间不成功，会给CPU带来非常大的执行开销。 如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，
pause指令有两个作用，第一它可以延迟流水线执行指令,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避
免在退出循环的时候因内存顺序冲突而引起CPU流水线被清空，从而提高CPU的执行效率。

3. 只能保证一个共享变量的原子操作

CAS 只对单个共享变量有效，当操作涉及跨多个共享变量时 CAS 无效。但是从 JDK 1.5开始，提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量
放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用AtomicReference类把多个共享变量合并成一个共享变量来操作。

## 15-6：自旋锁

## 13-7：自旋锁的优缺点

1. 自旋锁的优点： 避免了线程切换的开销。挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作给Java虚拟机的并发性能带来了很大的压力。

2. 自旋锁的缺点： 占用处理器的时间，如果占用的时间很长，会白白消耗处理器资源，而不会做任何有价值的工作，带来性能的浪费。因此自旋等待的时间必须有一定的
   限度，如果自旋超过了限定的次数仍然没有成功获得锁，就应当使用传统的方式去挂起线程。

## 13-8：自旋锁的升级——自适应自旋

自适应意味着自旋的时间不再是固定的，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定的。有了自适应自旋，随着程序运行时间的增长及性能监控信息
的不断完善，虚拟机对程序锁的状态预测就会越来越精准。

## 13-9：自旋锁使用场景

Java中的自旋锁： CAS操作中的比较操作失败后的自旋等待。

## 13-10：可重入锁（递归锁）

任意线程在获取到锁之后能够再次获取该锁而不会被锁所阻塞。可重入锁的作用是避免死锁。

通过组合自定义同步器来实现锁的获取与释放。

- 再次获取锁：识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取。获取锁后，进行计数自增，
- 释放锁：释放锁时，进行计数自减。

## 13-11：可重入锁使用场景

ReentrantLock、synchronized修饰的方法或代码段。

## 13-12：可重入锁如果加了两把，但是只释放了一把会出现什么问题？

程序卡死，线程不能出来，也就是说我们申请了几把锁，就需要释放几把锁。

## 13-13：如果只加了一把锁，释放两次会出现什么问题？

会报错，java.lang.IllegalMonitorStateException。


## 13-14：读写锁

通过ReentrantReadWriteLock类来实现。为了提高性能， Java 提供了读写锁，在读的地方使用读锁，在写的地方使用写锁，灵活控制，如果没有写锁的情况下，读是无阻塞的，在一定程度上提高了程序的执行效率。读写锁分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由 jvm 自己控制的。

读锁： 允许多个线程获取读锁，同时访问同一个资源。

写锁： 只允许一个线程获取写锁，不允许同时访问同一个资源。

## 13-15：公平锁

多个线程按照申请锁的顺序来获取锁。在并发环境中，每个线程会先查看此锁维护的等待队列，如果当前等待队列为空，则占有锁，如果等待队列不为空，则加入到等待队
列的末尾，按照FIFO的原则从队列中拿到线程，然后占有锁。

也就是如果一个线程组里，能保证每个线程都能拿到锁


## 13-16：非公平锁

线程尝试获取锁，如果获取不到，则再采用公平锁的方式。多个线程获取锁的顺序，不是按照先到先得的顺序，有可能后申请锁的线程比先申请的线程优先获取锁。

## 13-17：公平锁与非公平锁优缺点

优点： 非公平锁的性能高于公平锁。

缺点： 有可能造成线程饥饿（某个线程很长一段时间获取不到锁）

## 13-18：公平锁与非公平锁使用场景

synchronized是非公平锁，ReentrantLock通过构造函数指定该锁是公平的还是非公平的，默认是非公平的。

## 13-19：共享锁

a.当试图读取数据时，事务默认会为所依赖的数据资源请求共享锁。
b.持有共享锁时间：从事务得到共享锁到读操作完成。
c.多个事务可以在同一阶段用共享锁作用于同一数据资源。
d.在读取数据时，可以对如何处理锁定进行控制。后面隔离级别会讲到如何对锁定进行控制。

## 13-20：共享锁使用场景

ReentrantReadWriteLock

## 13-21：独占锁

只能有一个线程获取锁，以独占的方式持有锁。和悲观锁、互斥锁同义。

## 13-22：独占锁使用场景

synchronized，ReentrantLock

## 13-23：重量级锁

同上

## 13-24：重量级锁使用场景

synchronized

## 13-25：轻量级锁



## 13-26：轻量级锁优缺点

优点： 如果没有竞争，通过CAS操作成功避免了使用互斥量的开销。

缺点： 如果存在竞争，除了互斥量本身的开销外，还额外产生了CAS操作的开销，因此在有竞争的情况下，轻量级锁比传统的重量级锁更慢。

## 13-27：偏向锁

## 13-28：偏向锁优缺点

优点： 把整个同步都消除掉，连CAS操作都不去做了，优于轻量级锁。

缺点： 如果程序中大多数的锁都总是被多个不同的线程访问，那偏向锁就是多余的。

## 13-29：分段锁

它内部细分了若干个小的 HashMap，称之为段(Segment)。默认情况下一个 ConcurrentHashMap 被进一步细分为 16 个段，既就是锁的并发度。如果需要在
ConcurrentHashMap 添加一项key-value，并不是将整个 HashMap 加锁，而是首先根据 hashcode 得到该key-value应该存放在哪个段中，然后对该段加锁，并完成 put 操
作。在多线程环境中，如果多个线程同时进行put操作，只要被加入的key-value不存放在同一个段中，则线程间可以做到真正的并行。

ConcurrentHashMap 是一个 Segment 数组， Segment 通过继承ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每个 
Segment 是线程安全的，也就实现了全局的线程安全

## 13-30：互斥锁

也是x锁，该锁每一次只能被一个线程锁持有，加锁后任何线程试图再次加锁的线程会被阻塞，直到当前线程解锁，例子：如果 线程A 对deta1加上排它锁后，则其他线程不能再对data1 加任何类型的锁，获得互斥锁的线既能读取数据又能修改数据

## 13-31：同步锁

表示并发执行的多个线程，在同一时间内只允许一个线程访问共享数据。

## 13-32：死锁

如线程A持有资源x，线程B持有资源y，线程A等待线程B释放资源y，线程B等待线程A释放资源x，两个线程都不释放自己持有的资源，则两个线程都获取不到对方的资源，就
会造成死锁。

Java中的死锁不能自行打破，所以线程死锁后，线程不能进行响应。所以一定要注意程序的并发场景，避免造成死锁。


## 13-33：锁粗化

如果一系列的连续操作都对同一个对象反复加锁和解锁，甚至加锁操作都是出现在循环体体之中，就算真的没有线程竞争，频繁地进行互斥同步操作将会导致不必要的性能
损耗，所以就采取了一种方案：把加锁的范围扩展（粗化）到整个操作序列的外部，这样加锁解锁的频率就会大大降低，从而减少了性能损耗。

## 13-34：锁消除





1. 数据库锁

    * 分段锁
    * 行锁
    * 表锁

2. JVM为了提高锁的获取与释放而作的优化锁
　
   * 偏向锁
   * 轻量级锁
   * 重量级锁




# 15.并发容器

## 15-1：JDK 提供的并发容器总结

ConcurrentHashMap: 线程安全的 HashMap
CopyOnWriteArrayList: 线程安全的 List，在读多写少的场合性能非常好，远远好于 Vector.
ConcurrentLinkedQueue: 高效的并发队列，使用链表实现。可以看做一个线程安全的 LinkedList，这是一个非阻塞队列。
BlockingQueue: 这是一个接口，JDK 内部通过链表、数组等方式实现了这个接口。表示阻塞队列，非常适合用于作为数据共享的通道。
ConcurrentSkipListMap: 跳表的实现。这是一个 Map，使用跳表的数据结构进行快速查找。

## 15-2：CopyOnWriteArrayList 是如何做到的？
CopyOnWriteArrayList 类的所有可变操作（add，set 等等）都是通过创建底层数组的新副本来实现的。当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。

从 CopyOnWriteArrayList 的名字就能看出CopyOnWriteArrayList 是满足CopyOnWrite 的 ArrayList，所谓CopyOnWrite 也就是说：在计算机，如果你想要对一块内存进行修改时，我们不在原有内存块中进行写操作，而是将内存拷贝一份，在新的内存中进行写操作，写完之后呢，就将指向原来内存指针指向新的内存，原来的内存就可以被回收掉了。
